{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c66f45-4be3-4674-a870-3849c1048ddb",
   "metadata": {},
   "source": [
    "# GRPO with Coding Task and Tools\n",
    "\n",
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d9ca00-92a8-4bd3-9b2b-ab8856f5acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: setting HYPERACTOR_CODEC_MAX_FRAME_LENGTH since this needs to be set to enable large RPC calls via Monarch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-16 20:07:55 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the BSD-style license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchstore as ts\n",
    "from datasets import load_dataset\n",
    "from forge.actors._torchstore_utils import (\n",
    "    get_dcp_whole_state_dict_key,\n",
    "    get_param_prefix,\n",
    ")\n",
    "from forge.actors.generator import Generator as Policy\n",
    "from forge.actors.reference_model import ReferenceModel\n",
    "from forge.actors.replay_buffer import ReplayBuffer\n",
    "from forge.actors.trainer import RLTrainer\n",
    "from forge.cli.config import parse\n",
    "from forge.controller.actor import ForgeActor\n",
    "from forge.controller.provisioner import init_provisioner, shutdown\n",
    "from forge.data.rewards import MathReward, ThinkingReward\n",
    "from forge.observability.metric_actors import get_or_create_metric_logger\n",
    "from forge.observability.metrics import record_metric, Reduce\n",
    "from forge.observability.perf_tracker import Tracer\n",
    "\n",
    "from forge.types import LauncherConfig, ProvisionerConfig\n",
    "from forge.util.ops import compute_logprobs\n",
    "from monarch.actor import endpoint\n",
    "from omegaconf import DictConfig\n",
    "from vllm.transformers_utils.tokenizer import get_tokenizer\n",
    "\n",
    "import os\n",
    "os.environ[\"MONARCH_HOSTMESH_V1\"] = \"1\"\n",
    "os.environ[\"TORCHSTORE_RDMA_ENABLED\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4319f-e6c9-4f4b-9b92-c572de08f0b2",
   "metadata": {},
   "source": [
    "## Define Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a25e9d-e1dd-4ea7-a80c-383a2c04656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Episode:\n",
    "    # TODO: add adtional layer for multi-turn\n",
    "    episode_id: str\n",
    "    request: str\n",
    "    policy_version: int\n",
    "    pad_id: int\n",
    "    request_len: int\n",
    "    response_len: int\n",
    "    target: Any | None = None\n",
    "    # processed data\n",
    "    response: str | None = None\n",
    "    request_tokens: list[int] | None = None\n",
    "    response_tokens: list[int] | None = None\n",
    "    ref_logprobs: torch.Tensor | None = None\n",
    "    reward: float | None = None\n",
    "    advantage: float | None = None\n",
    "\n",
    "    @property\n",
    "    def request_tensor(self):\n",
    "        tensor = torch.tensor(self.request_tokens, dtype=torch.long)\n",
    "        if tensor.shape[0] < self.request_len:  # left pad\n",
    "            diff = self.request_len - tensor.shape[0]\n",
    "            tensor = F.pad(tensor, (diff, 0), value=self.pad_id)\n",
    "        return tensor\n",
    "\n",
    "    @property\n",
    "    def response_tensor(self):\n",
    "        tensor = torch.tensor(self.response_tokens, dtype=torch.long)\n",
    "        if tensor.shape[0] < self.response_len:  # right pad\n",
    "            diff = self.response_len - tensor.shape[0]\n",
    "            tensor = F.pad(tensor, (0, diff), value=self.pad_id)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Group:\n",
    "    group_id: str\n",
    "    episodes: list[Episode]\n",
    "\n",
    "    @classmethod\n",
    "    def new_group(\n",
    "        cls,\n",
    "        group_id: int,\n",
    "        group_size: int,\n",
    "        request: str,\n",
    "        policy_version: int,\n",
    "        pad_id: int,\n",
    "        request_len: int,\n",
    "        response_len: int,\n",
    "        target: Any = None,\n",
    "    ):\n",
    "        episodes = []\n",
    "        for _ in range(group_size):\n",
    "            episodes.append(\n",
    "                Episode(\n",
    "                    episode_id=str(uuid.uuid4()),\n",
    "                    request=request,\n",
    "                    policy_version=policy_version,\n",
    "                    pad_id=pad_id,\n",
    "                    request_len=request_len,\n",
    "                    response_len=response_len,\n",
    "                    target=target,\n",
    "                )\n",
    "            )\n",
    "        return cls(str(group_id), episodes)\n",
    "\n",
    "\n",
    "def collate(batches: list[list[Episode]]):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for batch in batches:\n",
    "        request = [e.request_tensor for e in batch]\n",
    "        request = torch.stack(request)  # [b x s]\n",
    "\n",
    "        response = [e.response_tensor for e in batch]\n",
    "        response = torch.stack(response)  # [b x s]\n",
    "\n",
    "        ref_logprobs = [e.ref_logprobs for e in batch]\n",
    "        ref_logprobs = torch.stack(ref_logprobs).squeeze()  # [b x s]\n",
    "\n",
    "        advantages = [e.advantage for e in batch]\n",
    "        advantages = torch.tensor(advantages).unsqueeze(-1)  # [b x 1]\n",
    "\n",
    "        pad_id = batch[0].pad_id\n",
    "        mask = response != pad_id\n",
    "\n",
    "        input = {\"tokens\": torch.cat([request, response], dim=1)}\n",
    "        target = {\n",
    "            \"response\": response,\n",
    "            \"ref_logprobs\": ref_logprobs,\n",
    "            \"advantages\": advantages,\n",
    "            \"padding_mask\": mask,\n",
    "        }\n",
    "        inputs.append(input)\n",
    "        targets.append(target)\n",
    "    return inputs, targets\n",
    "\n",
    "@dataclass\n",
    "class DatasetActor(ForgeActor):\n",
    "    \"\"\"Actor wrapper for HuggingFace dataset to provide async interface.\"\"\"\n",
    "\n",
    "    path: str = \"openai/gsm8k\"\n",
    "    revision: str = \"main\"\n",
    "    data_split: str = \"train\"\n",
    "    streaming: bool = True\n",
    "    model: str = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "    @endpoint\n",
    "    def setup(self):\n",
    "        self._tokenizer = get_tokenizer(self.model)\n",
    "\n",
    "        def gsm8k_transform(sample):\n",
    "            system_prompt = \"\"\"\n",
    "            Put all your scratchpad work between <think> and </think> tags.\n",
    "            Your final answer should be between <answer> and </answer> tags otherwise it will not be scored.\n",
    "            \"\"\"\n",
    "            request: str = sample[\"question\"]\n",
    "            as_chat = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": request},\n",
    "            ]\n",
    "            formatted_request = self._tokenizer.apply_chat_template(\n",
    "                as_chat,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True,\n",
    "            )\n",
    "            target: str = sample[\"answer\"]\n",
    "            formatted_target = target.split(\"#### \")[1]\n",
    "            return {\"request\": formatted_request, \"target\": formatted_target}\n",
    "\n",
    "        ds = load_dataset(\n",
    "            self.path, self.revision, split=self.data_split, streaming=self.streaming\n",
    "        )\n",
    "        ds = ds.map(gsm8k_transform)\n",
    "        ds = ds.shuffle()\n",
    "        self._iterator = iter(ds)\n",
    "\n",
    "    @endpoint\n",
    "    async def sample(self) -> dict[str, str] | None:\n",
    "        try:\n",
    "            sample = next(self._iterator)\n",
    "\n",
    "            # Record dataset metrics\n",
    "            record_metric(\"dataset/sample/count_samples_generated\", 1, Reduce.SUM)\n",
    "            record_metric(\n",
    "                \"dataset/sample/avg_sample_len\",\n",
    "                len(sample[\"request\"]),\n",
    "                Reduce.MEAN,\n",
    "            )\n",
    "\n",
    "            return sample\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "    @endpoint\n",
    "    async def pad_token(self):\n",
    "        return self._tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b3d1d-7eba-4464-b881-48c11ff6e0ef",
   "metadata": {},
   "source": [
    "## Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934aca32-0953-4945-9f99-e7b34804443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_grpo_loss(\n",
    "    logits: torch.Tensor,\n",
    "    response: torch.Tensor,\n",
    "    ref_logprobs: torch.Tensor,\n",
    "    advantages: torch.Tensor,\n",
    "    padding_mask: torch.Tensor,\n",
    "    beta: float = 0.1,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Example GRPO Loss Function for RLTrainer\n",
    "    \"\"\"\n",
    "    logprobs: torch.Tensor = compute_logprobs(logits, response)\n",
    "\n",
    "    # Note: This is also available in losses.grpo_loss via `SimpleGRPOLoss`\n",
    "    kl = torch.exp(ref_logprobs - logprobs) - (ref_logprobs - logprobs) - 1\n",
    "    per_token_policy_loss = torch.exp(logprobs - logprobs.detach()) * advantages\n",
    "    per_token_loss = -(per_token_policy_loss - beta * kl)\n",
    "    loss = (\n",
    "        ((per_token_loss * padding_mask).sum(dim=1))\n",
    "        / (padding_mask.sum(dim=1).clamp(min=1.0))\n",
    "    ).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f8bbe3-b7ac-4905-b197-f10990f9a104",
   "metadata": {},
   "source": [
    "## Define Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163e98bf-e0f5-4ec3-9690-9839e687f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RewardActor(ForgeActor):\n",
    "    \"\"\"Reward actor that uses a list of scoring functions.\"\"\"\n",
    "\n",
    "    reward_functions: list[Callable]\n",
    "\n",
    "    @endpoint\n",
    "    async def evaluate_response(self, prompt: str, response: str, target: str) -> float:\n",
    "        total_rewards = 0.0\n",
    "        for reward_fn in self.reward_functions:\n",
    "            reward = reward_fn(prompt, response, target)\n",
    "            total_rewards += reward\n",
    "\n",
    "            # Get a name for the reward function (works for classes, functions, lambdas)\n",
    "            reward_fn_name = getattr(\n",
    "                reward_fn, \"__name__\", reward_fn.__class__.__name__\n",
    "            )\n",
    "            # per function reward\n",
    "            record_metric(\n",
    "                f\"reward/evaluate_response/sum_{reward_fn_name}_reward\",\n",
    "                reward,\n",
    "                Reduce.SUM,\n",
    "            )\n",
    "            record_metric(\n",
    "                f\"reward/evaluate_response/avg_{reward_fn_name}_reward\",\n",
    "                reward,\n",
    "                Reduce.MEAN,\n",
    "            )\n",
    "            record_metric(\n",
    "                f\"reward/evaluate_response/std_{reward_fn_name}_reward\",\n",
    "                reward,\n",
    "                Reduce.STD,\n",
    "            )\n",
    "\n",
    "            # avg total reward\n",
    "            record_metric(\n",
    "                \"reward/evaluate_response/avg_total_reward\",\n",
    "                reward,\n",
    "                Reduce.MEAN,\n",
    "            )\n",
    "\n",
    "            # count fn calls\n",
    "            record_metric(\n",
    "                f\"reward/evaluate_response/count_{reward_fn_name}_calls\",\n",
    "                1,\n",
    "                Reduce.SUM,\n",
    "            )\n",
    "\n",
    "        avg_reward = total_rewards / len(self.reward_functions)\n",
    "        return avg_reward\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ComputeAdvantages(ForgeActor):\n",
    "    \"\"\"Compute advantages for GRPO using reward signals.\"\"\"\n",
    "\n",
    "    @endpoint\n",
    "    async def compute(self, group: Group) -> list[float]:\n",
    "        # TODO: add batch processing\n",
    "        rewards = torch.tensor([[e.reward for e in group.episodes]])\n",
    "        mean = rewards.mean(1, keepdim=True)\n",
    "        std = rewards.std(1, keepdim=True)\n",
    "        advantages = (rewards - mean) / (std + 1e-4)\n",
    "        return advantages.squeeze(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88523484-b414-41db-bd3f-0d8dbf881a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def drop_weights(version: int):\n",
    "    print(f\"Dropping weights @ version {version}\")\n",
    "    start_time = time.perf_counter()\n",
    "    prefix = get_param_prefix(version)\n",
    "    matching_keys = await ts.keys(prefix)\n",
    "    # TODO: once we have something like `get_meta()` in torchstore, we can just\n",
    "    # query the type of the object instead of relying on keys.\n",
    "    dcp_key = get_dcp_whole_state_dict_key(version)\n",
    "    if dcp_key in matching_keys:\n",
    "        dcp_handle = await ts.get(dcp_key)\n",
    "        dcp_handle.drop()\n",
    "    for key in matching_keys:\n",
    "        await ts.delete(key)\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    print(f\"Dropped weights @ version {version}, took {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc979b-7b06-4cff-a625-b664baf0d172",
   "metadata": {},
   "source": [
    "## !!!!!!! Custom Testing !!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "059926d5-5ed8-4be5-b5e9-79d1c6fa2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from actors.coder import SandboxedPythonCoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4fef3-180b-4b7e-8871-ecbe113cde72",
   "metadata": {},
   "source": [
    "## Setup Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1146a169-f07f-4e4e-a9f3-30e884839ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/torch/cuda/memory.py:491: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "[0]   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:11:48 INFO\u001b[0m Pushing weights for policy version 1\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:11:52 INFO\u001b[0m Completed weights push in 3.96 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueMesh({procs: 1}):\n",
       "  (({'procs': 0/1}, None),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await trainer.push_weights.call(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82c3e3e2-748e-4f55-a126-18815fb9d696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'policy_ver_0000000001'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_param_prefix(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e649f5e-1a31-4bcb-978d-eb52c3b10017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy_ver_0000000001'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = await ts.keys(get_param_prefix(1))\n",
    "set(k.split(\".\")[0] for k in keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c811974-cd6b-40ed-a179-4511a7a6c489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpbontrager\u001b[0m (\u001b[33mbontrager\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/home/pbontrager/forge/wandb/run-20251016_200800-vjwp42hc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bontrager/grpo-training/runs/vjwp42hc' target=\"_blank\">decent-thunder-63</a></strong> to <a href='https://wandb.ai/bontrager/grpo-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bontrager/grpo-training' target=\"_blank\">https://wandb.ai/bontrager/grpo-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bontrager/grpo-training/runs/vjwp42hc' target=\"_blank\">https://wandb.ai/bontrager/grpo-training/runs/vjwp42hc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning actor DatasetActor\n",
      "Launcher not provided, remote allocations will not work.\n",
      "Spawning service Generator\n",
      "Spawning actor RLTrainer\n",
      "Spawning actor ReplayBuffer\n",
      "Spawning actor ComputeAdvantages\n",
      "Spawning service ReferenceModel\n",
      "Spawning service RewardActor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:12 INFO\u001b[0m Compiling loss\n",
      "[0] INFO 10-16 20:08:14 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:14 INFO\u001b[0m Building 0-D device mesh with [], []\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:14 INFO\u001b[0m [GC] Initial GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:15 INFO\u001b[0m Total parameter count: dense 2,031,739,904, sparse 0, active 2,031,739,904\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:15 INFO\u001b[0m Applied selective activation checkpointing to the model\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:15 INFO\u001b[0m Checkpointing active. Checkpoints will be loaded from and saved to checkpoint\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:15 INFO\u001b[0m Mixed precision training is handled by AMP\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:15 INFO\u001b[0m loading from HF safetensors from --checkpoint.initial_load_path: /mnt/home/pbontrager/.cache/huggingface/hub/models--Qwen--Qwen3-1.7B/snapshots/70d244cc86ccca08cf5af4e1e306ecf908b1ad5e\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:15 INFO\u001b[0m Loading the checkpoint from /mnt/home/pbontrager/.cache/huggingface/hub/models--Qwen--Qwen3-1.7B/snapshots/70d244cc86ccca08cf5af4e1e306ecf908b1ad5e.\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:17 INFO\u001b[0m [GC] GC collection for checkpoint loading. took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 20:08:17 INFO\u001b[0m Finished loading the checkpoint in 2.09 seconds.\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:17 INFO\u001b[0m Building 0-D device mesh with [], []\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:17 INFO\u001b[0m [GC] Initial GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "[0]   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:19 INFO\u001b[0m Total parameter count: dense 2,031,739,904, sparse 0, active 2,031,739,904\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:19 INFO\u001b[0m Applied selective activation checkpointing to the model\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:19 INFO\u001b[0m Checkpointing active. Checkpoints will be loaded from and saved to checkpoint\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:19 INFO\u001b[0m Mixed precision training is handled by AMP\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:19 INFO\u001b[0m loading from HF safetensors from --checkpoint.initial_load_path: /mnt/home/pbontrager/.cache/huggingface/hub/models--Qwen--Qwen3-1.7B/snapshots/70d244cc86ccca08cf5af4e1e306ecf908b1ad5e\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:19 INFO\u001b[0m Loading the checkpoint from /mnt/home/pbontrager/.cache/huggingface/hub/models--Qwen--Qwen3-1.7B/snapshots/70d244cc86ccca08cf5af4e1e306ecf908b1ad5e.\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:20 INFO\u001b[0m [GC] GC collection for checkpoint loading. took 0.04 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 20:08:20 INFO\u001b[0m Finished loading the checkpoint in 0.87 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] `torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] INFO 10-16 20:08:25 [config.py:1604] Using max model len 40960\n",
      "[0] INFO 10-16 20:08:26 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
      "[0] INFO 10-16 20:08:30 [__init__.py:235] Automatically detected platform cuda.\n",
      "[0] WARNING 10-16 20:08:33 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] [W1016 20:08:35.327230881 ProcessGroupNCCL.cpp:941] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[0] [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[0] [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[0] [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[0] [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[0] INFO 10-16 20:08:35 [parallel_state.py:1102] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "[0] WARNING 10-16 20:08:35 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "[0] INFO 10-16 20:08:35 [gpu_model_runner.py:1843] Starting to load model Qwen/Qwen3-1.7B...\n",
      "[0] INFO 10-16 20:08:36 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "[0] INFO 10-16 20:08:36 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "[0] INFO 10-16 20:08:36 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.95it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  3.89it/s]\n",
      "[0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] INFO 10-16 20:08:37 [default_loader.py:262] Loading weights took 0.63 seconds\n",
      "[0] INFO 10-16 20:08:37 [gpu_model_runner.py:1892] Model loading took 3.2152 GiB and 1.116859 seconds\n",
      "[0] INFO 10-16 20:08:45 [backends.py:530] Using cache directory: /mnt/home/pbontrager/.cache/vllm/torch_compile_cache/7ab64a271d/rank_0_0/backbone for vLLM's torch.compile\n",
      "[0] INFO 10-16 20:08:45 [backends.py:541] Dynamo bytecode transform time: 7.57 s\n",
      "[0] INFO 10-16 20:08:50 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 4.502 s\n",
      "[0] INFO 10-16 20:09:03 [monitor.py:34] torch.compile takes 7.57 s in total\n",
      "[0] INFO 10-16 20:09:04 [gpu_worker.py:255] Available KV cache memory: 62.38 GiB\n",
      "[0] INFO 10-16 20:09:04 [kv_cache_utils.py:833] GPU KV cache size: 584,000 tokens\n",
      "[0] INFO 10-16 20:09:04 [kv_cache_utils.py:837] Maximum concurrency for 40,960 tokens per request: 14.26x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:01<00:00, 38.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] INFO 10-16 20:09:06 [gpu_model_runner.py:2485] Graph capturing finished in 2 secs, took 0.60 GiB\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from forge.cli.config import resolve_hf_hub_paths\n",
    "\n",
    "cfg = OmegaConf.load('apps/grpo/qwen3_1_7b.yaml')\n",
    "cfg = resolve_hf_hub_paths(cfg)\n",
    "OmegaConf.resolve(cfg)\n",
    "\n",
    "group_size = cfg.group_size # 8\n",
    "max_req_tokens = cfg.max_req_tokens # 512\n",
    "max_res_tokens = cfg.max_res_tokens # 512\n",
    "\n",
    "metric_logging_cfg = cfg.get(\"metric_logging\", {\"console\": {\"log_per_rank\": False}})\n",
    "mlogger = await get_or_create_metric_logger()\n",
    "await mlogger.init_backends.call_one(metric_logging_cfg)\n",
    "await ts.initialize(strategy=ts.ControllerStorageVolumes())\n",
    "\n",
    "dataloader, policy, trainer, replay_buffer, compute_advantages, ref_model, reward_actor = await asyncio.gather(\n",
    "    DatasetActor.options(**cfg.actors.dataset).as_actor(**cfg.dataset),\n",
    "    Policy.options(**cfg.services.policy).as_service(**cfg.policy),\n",
    "    RLTrainer.options(**cfg.actors.trainer).as_actor(\n",
    "        **cfg.trainer, loss=simple_grpo_loss\n",
    "    ),\n",
    "    ReplayBuffer.options(**cfg.actors.replay_buffer).as_actor(\n",
    "        **cfg.replay_buffer, collate=collate\n",
    "    ),\n",
    "    ComputeAdvantages.options(**cfg.actors.compute_advantages).as_actor(),\n",
    "    ReferenceModel.options(**cfg.services.ref_model).as_service(**cfg.ref_model),\n",
    "    RewardActor.options(**cfg.services.reward_actor).as_service(\n",
    "        reward_functions=[MathReward(), ThinkingReward()]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a305f-b1e2-4eac-803c-71bf3225fed7",
   "metadata": {},
   "source": [
    "## Rollout Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1c676fb-2cd6-4c2c-87d4-e1b8cd0b87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def continuous_rollouts():\n",
    "    rollout_count = 0\n",
    "    pad_id = await dataloader.pad_token.call_one()\n",
    "    while True:\n",
    "        t = Tracer(\"main_perf/continuous_rollouts\")\n",
    "        t.start()\n",
    "        sample = await dataloader.sample.call_one()\n",
    "        if sample is None:\n",
    "            print(\"Dataloader is empty, exiting continuous rollout\")\n",
    "            return\n",
    "\n",
    "        t.step(\"data_loading\")\n",
    "\n",
    "        prompt, target = sample[\"request\"], sample[\"target\"]\n",
    "        responses = await policy.generate.route(prompt)\n",
    "        # TODO: this shall be part of the responses metadata instead of a separate call\n",
    "        version = await policy.get_version.route()\n",
    "\n",
    "        t.step(\"policy_generation\")\n",
    "\n",
    "        assert (\n",
    "            len(responses) > 0\n",
    "        ), \"Sanity check: Responses should NEVER return empty\"\n",
    "        assert (\n",
    "            version := responses[0].generator_version\n",
    "        ) is not None, \"Response must indicate a version\"\n",
    "        group = Group.new_group(\n",
    "            group_id=rollout_count,\n",
    "            group_size=group_size,\n",
    "            request=prompt,\n",
    "            policy_version=version,\n",
    "            pad_id=pad_id,\n",
    "            request_len=max_req_tokens,\n",
    "            response_len=max_res_tokens,\n",
    "            target=target,\n",
    "        )\n",
    "\n",
    "        input_ids = torch.ones(\n",
    "            (group_size, max_req_tokens + max_res_tokens),\n",
    "            dtype=torch.long,\n",
    "            device=\"cuda\",\n",
    "        )\n",
    "        # Populate episode info and calculate rewards\n",
    "        for i, (episode, response) in enumerate(zip(group.episodes, responses)):\n",
    "            episode.request_tokens = response.prompt_ids\n",
    "            episode.response_tokens = response.token_ids\n",
    "            episode.response = response.text\n",
    "            input_ids[i, :max_req_tokens] = episode.request_tensor\n",
    "            input_ids[i, max_req_tokens:] = episode.response_tensor\n",
    "            episode.reward = await reward_actor.evaluate_response.route(\n",
    "                prompt=prompt, response=response.text, target=target\n",
    "            )\n",
    "\n",
    "        t.step(\"reward_evaluation\")\n",
    "\n",
    "        ref_logprobs = await ref_model.forward.route(\n",
    "            input_ids, max_req_tokens, return_logprobs=True\n",
    "        )\n",
    "        t.step(\"reference_model_calculate_logprobs\")\n",
    "\n",
    "        for i, episode in enumerate(group.episodes):\n",
    "            episode.ref_logprobs = ref_logprobs[i]\n",
    "        del ref_logprobs, input_ids\n",
    "        t.step(\"compute_logprobs\")\n",
    "\n",
    "        # Calculate advantages and add to replay buffer\n",
    "        advantages = await compute_advantages.compute.call_one(group)\n",
    "        for episode, advantage in zip(group.episodes, advantages):\n",
    "            episode.advantage = advantage\n",
    "            await replay_buffer.add.call_one(episode)\n",
    "\n",
    "        # Log metrics\n",
    "        rollout_count += 1\n",
    "        record_metric(\n",
    "            \"main/continuous_rollouts/count_rollout_iterations\", 1, Reduce.SUM\n",
    "        )\n",
    "        t.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c316dc-11b5-48ea-8b03-e1bb9d9d1f2b",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "916a0e79-aded-4ee3-b1a8-db0e772996c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def continuous_training():\n",
    "    training_step = 0\n",
    "    restart_tracer = True  # Flag to control when to restart tracer\n",
    "    # update_task = asyncio.sleep(0) philip\n",
    "    while True:\n",
    "        # Restart tracer when needed (initial start or after completing a training step)\n",
    "        # Otherwise, we cannot measure time waiting for buffer\n",
    "        if restart_tracer:\n",
    "            t = Tracer(\"main_perf/continuous_training\")\n",
    "            t.start()\n",
    "            restart_tracer = False\n",
    "\n",
    "        batch = await replay_buffer.sample.call_one(\n",
    "            curr_policy_version=training_step\n",
    "        )\n",
    "        if batch is None:\n",
    "            await asyncio.sleep(0.1)\n",
    "        else:\n",
    "            t.step(\"waiting_for_buffer\")\n",
    "\n",
    "            inputs, targets = batch\n",
    "            await trainer.train_step.call(inputs, targets)\n",
    "            training_step += 1\n",
    "            t.step(\"train_step\")\n",
    "\n",
    "            await trainer.push_weights.call(training_step)\n",
    "            t.step(\"push_weights\")\n",
    "\n",
    "            await policy.update_weights.fanout(training_step)\n",
    "            #await update_task philip\n",
    "            update_task = asyncio.create_task(policy.update_weights.fanout(training_step))\n",
    "            t.step(\"update_weights\")\n",
    "\n",
    "            if training_step >= 2:\n",
    "                await drop_weights(training_step - 1)\n",
    "                #asyncio.create_task(drop_weights(training_step - 1)) philip\n",
    "                t.step(\"drop_weights\")\n",
    "\n",
    "            t.stop()\n",
    "            restart_tracer = True\n",
    "\n",
    "            # Flush metrics every training step to WandB\n",
    "            await mlogger.flush.call_one(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4542863b-59c5-40bc-896c-6d8d44ada00f",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58194c13-b75e-405d-ab11-18cbe1874d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor = torch.tensor(self.request_tokens, dtype=torch.long)\n",
      "/tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor = torch.tensor(self.response_tokens, dtype=torch.long)\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/torch/cuda/memory.py:491: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "[0]   warnings.warn(\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/torch/cuda/memory.py:491: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "[0]   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:37:27 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /mnt/home/pbontrager/.conda/envs/forge/lib/python3.10/site-packages/torch/cuda/memory.py:491: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "[0]   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:27 INFO\u001b[0m Pushing weights for policy version 1\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:37:28 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:37:30 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:31 INFO\u001b[0m Completed weights push in 4.24 seconds\n",
      "WandbBackend: Logged 91 metrics at global_step 1\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 1 ===\n",
      "  buffer/add/count_episodes_added: 40.0\n",
      "  buffer/evict/avg_policy_age: 0.0\n",
      "  buffer/evict/max_policy_age: 0.0\n",
      "  buffer/evict/sum_episodes_evicted: 0.0\n",
      "  buffer/sample/avg_data_utilization: 1.9565217391304348\n",
      "  buffer/sample/count_sample_requests: 59.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 8.071606221087909e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.002548671793192625\n",
      "  dataset/sample/avg_sample_len: 442.5\n",
      "  dataset/sample/count_samples_generated: 6.0\n",
      "  generator/generate/avg_tokens_generated: 447.675\n",
      "  generator/generate/count_requests: 6.0\n",
      "  generator/generate/count_sequences_completed: 40.0\n",
      "  generator/generate/sum_tokens_generated: 17907.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9068234619140625\n",
      "  generator_perf/generate/generate/duration_max_s: 2.26005322265625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0014592064380645753\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.004644800186157227\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9084500539518892\n",
      "  generator_perf/generate/total_duration_max_s: 2.2649327748417853\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 5.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.321375697851181e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.069460555911064e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.08750521326437592\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.4328026147559285\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 2.028928933478892\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 2.8464168119244277\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.10845676669850945\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.24402931099757552\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.06586353862658142\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.3006198303773999\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.33981018345803\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 3.878805438056588\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 4.240066020749509\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 4.240066020749509\n",
      "  main_perf/continuous_training/total_duration_avg_s: 12.924357505049556\n",
      "  main_perf/continuous_training/total_duration_max_s: 12.924357505049556\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 2.5800360389985144\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 2.5800360389985144\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.2241845726966858e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.2241845726966858e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 6.104231452103704\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 6.104231452103704\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.01139256004244089\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.05635092128068209\n",
      "  reference_perf/forward/count_forward_passes: 5.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.048588470090180635\n",
      "  reference_perf/forward/forward/duration_max_s: 0.18010005494579673\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00045849643647670745\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0007151742465794086\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.3246734619140623\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.932007312774658\n",
      "  reference_perf/forward/to_device/duration_avg_s: 0.00010187402367591857\n",
      "  reference_perf/forward/to_device/duration_max_s: 0.00017369166016578674\n",
      "  reference_perf/forward/total_duration_avg_s: 0.06054403865709901\n",
      "  reference_perf/forward/total_duration_max_s: 0.2373447041027248\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.45750000000000013\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.7399999999999999\n",
      "  reward/evaluate_response/avg_total_reward: 0.5987500000000002\n",
      "  reward/evaluate_response/count_MathReward_calls: 40.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 40.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.44321975362115806\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.374699879903904\n",
      "  reward/evaluate_response/sum_MathReward_reward: 18.300000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 29.599999999999994\n",
      "  rl_trainer/avg_grpo_loss: -7.444620132446289e-05\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005016117356717587\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005016117356717587\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.000460267998278141\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.000460267998278141\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 4.237715627998114\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 4.237715627998114\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 4.236750987358391\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 4.236750987358391\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 2.5321178138256073\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 2.5321178138256073\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 7.631717681884766\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 24.05048131942749\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.025621843989938498\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.025621843989938498\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.014292172156274319\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.014292172156274319\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 2.572036670986563\n",
      "  rl_trainer_perf/step/total_duration_max_s: 2.572036670986563\n",
      "==============================\n",
      "\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:31 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:32 INFO\u001b[0m Pushing weights for policy version 2\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:37:32 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:35 INFO\u001b[0m Completed weights push in 3.20 seconds\n",
      "[0] INFO 10-16 19:37:37 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 1\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:37:37 INFO\u001b[0m Weight update completed (now v1)\n",
      "WandbBackend: Logged 96 metrics at global_step 2\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 2 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 0.6666666666666666\n",
      "  buffer/sample/count_sample_requests: 1.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.0007956749759614468\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007956749759614468\n",
      "  dataset/sample/avg_sample_len: 621.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 511.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4088.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.973047119140625\n",
      "  generator_perf/generate/generate/duration_max_s: 1.973047119140625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005902400016784668\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005902400016784668\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9736970071420072\n",
      "  generator_perf/generate/total_duration_max_s: 1.9736970071420072\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.078905865550041e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 3.078905865550041e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012723961845040321\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012723961845040321\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9788481038995087\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9788481038995087\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07429668726399541\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07429668726399541\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.00810964684933424\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00810964684933424\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1099403221160173\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1099403221160173\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.84777444601059e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.84777444601059e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 3.198764895554632\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 3.198764895554632\n",
      "  main_perf/continuous_training/total_duration_avg_s: 5.661172828171402\n",
      "  main_perf/continuous_training/total_duration_max_s: 5.661172828171402\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4695963612757623\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4695963612757623\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.9894723272882402\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.9894723272882402\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 0.0033312151208519936\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 0.0033312151208519936\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013749487698078156\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013749487698078156\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01297918800264597\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01297918800264597\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003446470946073532\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003446470946073532\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.937289774417877e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.937289774417877e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013542839791625738\n",
      "  reference_perf/forward/total_duration_max_s: 0.013542839791625738\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.8\n",
      "  reward/evaluate_response/avg_total_reward: 0.44999999999999996\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3464101615137753\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 6.4\n",
      "  rl_trainer/avg_grpo_loss: 263.8351745605469\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004827887751162052\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004827887751162052\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004823673516511917\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004823673516511917\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 3.1967099998146296\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 3.1967099998146296\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 3.19574186578393\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 3.19574186578393\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3469361709430814\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3469361709430814\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010546667035669088\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010546667035669088\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10868378216400743\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10868378216400743\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4661687081679702\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4661687081679702\n",
      "  worker_perf/update_weights/total_duration_avg_s: 4.904565112199634\n",
      "  worker_perf/update_weights/total_duration_max_s: 4.904565112199634\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 1, took 0.54 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:37:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:37:43 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:37:43 INFO\u001b[0m Weight update completed (now v2)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:37:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:45 INFO\u001b[0m Pushing weights for policy version 3\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:37:47 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:48 INFO\u001b[0m Completed weights push in 3.09 seconds\n",
      "Dropping weights @ version 2\n",
      "WandbBackend: Logged 96 metrics at global_step 3\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 3 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9831168831168831\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 32.0\n",
      "  buffer/sample/avg_data_utilization: 1.9662337662337661\n",
      "  buffer/sample/count_sample_requests: 76.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 8.448450458481123e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005777152255177498\n",
      "  dataset/sample/avg_sample_len: 490.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 509.4583333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12227.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.662465006510417\n",
      "  generator_perf/generate/generate/duration_max_s: 6.74124560546875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0008047466874122619\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0010708800554275512\n",
      "  generator_perf/generate/total_duration_avg_s: 4.663443438529968\n",
      "  generator_perf/generate/total_duration_max_s: 6.742207045480609\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.178960954149564e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.3822918087244034e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012863664887845516\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013811206445097923\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.668846658430994\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 6.748097182251513\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0743906373778979\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0745190130546689\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006832854977498452\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0071340398862957954\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.7989901298036175\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 6.878482781816274\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.991888999938965e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.991888999938965e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 3.0891503752209246\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 3.0891503752209246\n",
      "  main_perf/continuous_training/total_duration_avg_s: 11.153270978014916\n",
      "  main_perf/continuous_training/total_duration_max_s: 11.153270978014916\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4689445928670466\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4689445928670466\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.705484464764595e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.705484464764595e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.595152182970196\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.595152182970196\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013737271850307783\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014305906370282173\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013247830948481957\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01381271705031395\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003515520753959815\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00036635715514421463\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.907130445043246e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.148513734340668e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01381787626693646\n",
      "  reference_perf/forward/total_duration_max_s: 0.014396886806935072\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.10416666666666669\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.2666666666666667\n",
      "  reward/evaluate_response/avg_total_reward: 0.1854166666666666\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.19252525086913203\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.22110831935702668\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.5000000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 6.400000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.019737746566534042\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00050023989751935\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00050023989751935\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00046511413529515266\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00046511413529515266\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 3.086990188807249\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 3.086990188807249\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 3.086021885741502\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 3.086021885741502\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34500852692872286\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34500852692872286\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010644816793501377\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010644816793501377\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10977342212572694\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10977342212572694\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.465430345851928\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.465430345851928\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.445278965868056\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.445278965868056\n",
      "==============================\n",
      "\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:37:49 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "Dropped weights @ version 2, took 0.51 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:49 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:49 INFO\u001b[0m Pushing weights for policy version 4\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:37:52 INFO\u001b[0m Completed weights push in 3.00 seconds\n",
      "[0] INFO 10-16 19:37:52 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:37:52 INFO\u001b[0m Weight update completed (now v3)\n",
      "Dropping weights @ version 3\n",
      "WandbBackend: Logged 96 metrics at global_step 4\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 4 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8571428571428572\n",
      "  buffer/sample/count_sample_requests: 7.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.0001803584662931306\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006847120821475983\n",
      "  dataset/sample/avg_sample_len: 505.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 485.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3880.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.990470947265625\n",
      "  generator_perf/generate/generate/duration_max_s: 1.990470947265625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005744640231132507\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005744640231132507\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9912376672923564\n",
      "  generator_perf/generate/total_duration_max_s: 1.9912376672923564\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.475291982293129e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.475291982293129e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012415708042681217\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012415708042681217\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.997763654217124\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.997763654217124\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07488900795578957\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07488900795578957\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.010416633915156126\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.010416633915156126\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1312708579935133\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1312708579935133\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.922039806842804e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.922039806842804e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 3.0055684917606413\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 3.0055684917606413\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.123541404027492\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.123541404027492\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4685586290434003\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4685586290434003\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.039032198023051023\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.039032198023051023\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 0.6103748790919781\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 0.6103748790919781\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013779429718852043\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013779429718852043\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012986408080905676\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012986408080905676\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003409930504858494\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003409930504858494\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.67996534705162e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.67996534705162e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013544649817049503\n",
      "  reference_perf/forward/total_duration_max_s: 0.013544649817049503\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.32500000000000007\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.6000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.4625\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3897114317029973\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3999999999999999\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.6000000000000005\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.800000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.028004437685012817\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005138413980603218\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005138413980603218\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0005288277752697468\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0005288277752697468\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 3.003320634365082\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 3.003320634365082\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 3.0022717830725014\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 3.0022717830725014\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34581252932548523\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34581252932548523\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010610533878207207\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010610533878207207\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10885483399033546\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10885483399033546\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46528105111792684\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46528105111792684\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.682688263244927\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.682688263244927\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 3, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:37:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:37:58 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:37:58 INFO\u001b[0m Weight update completed (now v4)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:00 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:00 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:00 INFO\u001b[0m Pushing weights for policy version 5\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:02 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:03 INFO\u001b[0m Completed weights push in 2.52 seconds\n",
      "Dropping weights @ version 4\n",
      "WandbBackend: Logged 96 metrics at global_step 5\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 5 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9824797843665768\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9649595687331536\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.8939422455591125e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005676951259374619\n",
      "  dataset/sample/avg_sample_len: 439.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 480.5\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11532.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.163868367513021\n",
      "  generator_perf/generate/generate/duration_max_s: 5.50439794921875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006700373490651449\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007626240253448487\n",
      "  generator_perf/generate/total_duration_avg_s: 4.1646512155284485\n",
      "  generator_perf/generate/total_duration_max_s: 5.5052112612426285\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.278084720174471e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.4859014451503754e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001309928794701894\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0014250492677092552\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.169838573162754\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.510598839726299\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07456388883292675\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07469570403918624\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006940090097486973\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007964862044900656\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.299645044530432\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.640788597986102\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.675239324569702e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.675239324569702e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5255901720374823\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5255901720374823\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.374173434916884\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.374173434916884\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4673689790070057\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4673689790070057\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.6526784747838974e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.6526784747838974e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.38119111629203\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.38119111629203\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013811591391762099\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.000147226732224226\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.014873982251932224\n",
      "  reference_perf/forward/forward/duration_max_s: 0.018479468766599894\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00042746200536688167\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0004920600913465023\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 9.270462517937024e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 0.00010870303958654404\n",
      "  reference_perf/forward/total_duration_avg_s: 0.015534607227891684\n",
      "  reference_perf/forward/total_duration_max_s: 0.01922052586451173\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.3666666666666667\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.46666666666666673\n",
      "  reward/evaluate_response/avg_total_reward: 0.4166666666666667\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4496912521077347\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3771236166328253\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.8\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 11.200000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.03700073063373566\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004846770316362381\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004846770316362381\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048803677782416344\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048803677782416344\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5238443627022207\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5238443627022207\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.522868755273521\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.522868755273521\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34392492612823844\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34392492612823844\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010446812957525253\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010446812957525253\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10996929788962007\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10996929788962007\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46434333035722375\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46434333035722375\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.256495616864413\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.256495616864413\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 4, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:04 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:04 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:04 INFO\u001b[0m Pushing weights for policy version 6\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:07 INFO\u001b[0m Completed weights push in 2.54 seconds\n",
      "[0] INFO 10-16 19:38:07 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:38:07 INFO\u001b[0m Weight update completed (now v5)\n",
      "Dropping weights @ version 5\n",
      "WandbBackend: Logged 96 metrics at global_step 6\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 6 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.871212121212121\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00012379054290552935\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007347636856138706\n",
      "  dataset/sample/avg_sample_len: 463.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 460.5\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3684.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.950938720703125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.950938720703125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006014400124549865\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006014400124549865\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9517276487201451\n",
      "  generator_perf/generate/total_duration_max_s: 1.9517276487201451\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.6863220632076263e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.6863220632076263e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011366312392055988\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011366312392055988\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9568752851337194\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9568752851337194\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07464759796857834\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07464759796857834\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006834774743765593\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006834774743765593\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.086068364325911\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.086068364325911\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.979781806468964e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.979781806468964e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5412708721123636\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5412708721123636\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.377669614274055\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.377669614274055\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46787188621237874\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46787188621237874\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.244538351893425\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.244538351893425\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1239814860746264\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1239814860746264\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013621198013424873\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013621198013424873\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01307836314663291\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01307836314663291\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00035694288089871407\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00035694288089871407\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.810816168785095e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.810816168785095e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013652168214321136\n",
      "  reference_perf/forward/total_duration_max_s: 0.013652168214321136\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.7749999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.9\n",
      "  reward/evaluate_response/avg_total_reward: 0.8374999999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3897114317029975\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.26457513110645897\n",
      "  reward/evaluate_response/sum_MathReward_reward: 6.199999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 7.2\n",
      "  rl_trainer/avg_grpo_loss: 0.06768956035375595\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000542311929166317\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000542311929166317\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047868210822343826\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047868210822343826\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5389929520897567\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5389929520897567\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5379671058617532\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5379671058617532\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34550158493220806\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34550158493220806\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010415595956146717\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010415595956146717\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10877606412395835\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10877606412395835\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4646978541277349\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4646978541277349\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.461978105828166\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.461978105828166\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 5, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:09 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:38:12 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:38:12 INFO\u001b[0m Weight update completed (now v6)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:14 INFO\u001b[0m Pushing weights for policy version 7\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:16 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:17 INFO\u001b[0m Completed weights push in 2.56 seconds\n",
      "Dropping weights @ version 6\n",
      "WandbBackend: Logged 96 metrics at global_step 7\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 7 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 68.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.284167470081764e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.00060642184689641\n",
      "  dataset/sample/avg_sample_len: 474.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 418.25\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 10038.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 3.9185156656901037\n",
      "  generator_perf/generate/generate/duration_max_s: 5.0450673828125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007127359906832376\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000815455973148346\n",
      "  generator_perf/generate/total_duration_avg_s: 3.9193304603447525\n",
      "  generator_perf/generate/total_duration_max_s: 5.046073014780879\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.464457889397939e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.1179900765419006e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012206674243013065\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012752823531627655\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 3.924603696136425\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.051047674845904\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07434292851636808\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0745515301823616\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006886770017445087\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0071441130712628365\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.053981984344621\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.179003282915801\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 6.47595152258873e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 6.47595152258873e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.559258763678372\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.559258763678372\n",
      "  main_perf/continuous_training/total_duration_avg_s: 9.793483257759362\n",
      "  main_perf/continuous_training/total_duration_max_s: 9.793483257759362\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46287546027451754\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46287546027451754\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 3.8937199860811234e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 3.8937199860811234e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 6.771301436703652\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 6.771301436703652\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013363904630144438\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013790326192975044\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012982271456470093\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013063071761280298\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034508512665828067\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00035811495035886765\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.883583505948384e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.957406342029572e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013541993064184984\n",
      "  reference_perf/forward/total_duration_max_s: 0.013618877157568932\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.6999999999999998\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.8666666666666666\n",
      "  reward/evaluate_response/avg_total_reward: 0.7833333333333335\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.42426406871192884\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.29814239699997197\n",
      "  reward/evaluate_response/sum_MathReward_reward: 16.799999999999997\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 20.799999999999997\n",
      "  rl_trainer/avg_grpo_loss: 0.07369793206453323\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00047006597742438316\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00047006597742438316\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004809517413377762\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004809517413377762\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.557044609915465\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.557044609915465\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.556090689264238\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.556090689264238\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3407510588876903\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3407510588876903\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010368536226451397\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010368536226451397\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10822868999093771\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10822868999093771\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.45935122203081846\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.45935122203081846\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.234660088084638\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.234660088084638\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 6, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:18 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:18 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:19 INFO\u001b[0m Pushing weights for policy version 8\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:21 INFO\u001b[0m Completed weights push in 2.55 seconds\n",
      "[0] INFO 10-16 19:38:22 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:38:22 INFO\u001b[0m Weight update completed (now v7)\n",
      "Dropping weights @ version 7\n",
      "WandbBackend: Logged 96 metrics at global_step 8\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 8 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8717948717948718\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010701279657391402\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006678123027086258\n",
      "  dataset/sample/avg_sample_len: 432.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 2.0029825439453126\n",
      "  generator_perf/generate/generate/duration_max_s: 2.0029825439453126\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007676799893379211\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007676799893379211\n",
      "  generator_perf/generate/total_duration_avg_s: 2.003954863935709\n",
      "  generator_perf/generate/total_duration_max_s: 2.003954863935709\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.055917426943779e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.055917426943779e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011744890362024307\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011744890362024307\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 2.0091745969839394\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 2.0091745969839394\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07492484617978334\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07492484617978334\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007278849836438894\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007278849836438894\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.139891176018864\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.139891176018864\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.926230758428574e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.926230758428574e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.555366893298924\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.555366893298924\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.495327188167721\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.495327188167721\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4715256220661104\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4715256220661104\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.24525114381685853\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.24525114381685853\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2231765878386796\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2231765878386796\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001627691090106964\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001627691090106964\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01327545614913106\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01327545614913106\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00039606494829058647\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00039606494829058647\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.518993854522705e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.518993854522705e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013921557925641537\n",
      "  reference_perf/forward/total_duration_max_s: 0.013921557925641537\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5\n",
      "  reward/evaluate_response/avg_total_reward: 0.3\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207417\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.0\n",
      "  rl_trainer/avg_grpo_loss: 0.051367297768592834\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005054711364209652\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005054711364209652\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004884367808699608\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004884367808699608\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5532938637770712\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5532938637770712\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.552296544890851\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.552296544890851\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3475492037832737\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3475492037832737\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010548517107963562\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010548517107963562\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10972962994128466\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10972962994128466\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4678322081454098\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4678322081454098\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.486176047939807\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.486176047939807\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 7, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:23 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:38:27 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:38:27 INFO\u001b[0m Weight update completed (now v8)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:29 INFO\u001b[0m Pushing weights for policy version 9\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:31 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:32 INFO\u001b[0m Completed weights push in 2.60 seconds\n",
      "Dropping weights @ version 8\n",
      "WandbBackend: Logged 96 metrics at global_step 9\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 9 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 2.2452830188679247\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.555742265222823e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0008008363656699657\n",
      "  dataset/sample/avg_sample_len: 490.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 480.0833333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11522.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.102029134114583\n",
      "  generator_perf/generate/generate/duration_max_s: 5.2847724609375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005855466723442078\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006193600296974183\n",
      "  generator_perf/generate/total_duration_avg_s: 4.102730638122806\n",
      "  generator_perf/generate/total_duration_max_s: 5.2854627969414\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.7189883490403496e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.3833238780498505e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012206612154841423\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012636282481253147\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.107977476436645\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.291203196160495\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0744214605850478\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07469321880489588\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0068988849719365435\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0070434389635920525\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.237934737931937\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.420769827906042\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.949979484081268e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.949979484081268e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.597184816841036\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.597184816841036\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.34916475880891\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.34916475880891\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4656602693721652\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4656602693721652\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.7201993614435196e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.7201993614435196e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.286295492667705\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.286295492667705\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013326480984687805\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013603735715150833\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.015271431300789118\n",
      "  reference_perf/forward/forward/duration_max_s: 0.019897588063031435\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003441643590728442\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003465600311756134\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.639188940326373e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.758801802992821e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01582739595323801\n",
      "  reference_perf/forward/total_duration_max_s: 0.02045520395040512\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.40416666666666656\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.633333333333333\n",
      "  reward/evaluate_response/avg_total_reward: 0.5187499999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.463212664142748\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.39860869143671335\n",
      "  reward/evaluate_response/sum_MathReward_reward: 9.699999999999998\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 15.199999999999992\n",
      "  rl_trainer/avg_grpo_loss: 0.06481218338012695\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00042128004133701324\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00042128004133701324\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004895632155239582\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004895632155239582\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.595345098990947\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.595345098990947\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5944295478984714\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5944295478984714\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34284042194485664\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34284042194485664\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010376881342381239\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010376881342381239\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10961871594190598\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10961871594190598\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4628386711701751\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4628386711701751\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.217807427048683\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.217807427048683\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 8, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:33 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:33 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:33 INFO\u001b[0m Pushing weights for policy version 10\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:36 INFO\u001b[0m Completed weights push in 2.56 seconds\n",
      "[0] INFO 10-16 19:38:36 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 9[0] \u001b[34m[Generator-0/1] 2025-10-16 19:38:36 INFO\u001b[0m Weight update completed (now v9)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 10\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 10 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00017215621968110403\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0008265669457614422\n",
      "  dataset/sample/avg_sample_len: 446.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9747686767578125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9747686767578125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006173440217971802\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006173440217971802\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9755736687779426\n",
      "  generator_perf/generate/total_duration_max_s: 1.9755736687779426\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.242880433797836e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.242880433797836e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001302235759794712\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001302235759794712\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.981104742269963\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.981104742269963\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07435540994629264\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07435540994629264\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.00660277996212244\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00660277996212244\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1093581607565284\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1093581607565284\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.839152097702026e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.839152097702026e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5669438131153584\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5669438131153584\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.527719452045858\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.527719452045858\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4701364398933947\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4701364398933947\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.3735705427825451\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.3735705427825451\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1170617709867656\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1170617709867656\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001357230357825756\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001357230357825756\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01288688089698553\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01288688089698553\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003544902428984642\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003544902428984642\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.534213364124298e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.534213364124298e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013454716186970472\n",
      "  reference_perf/forward/total_duration_max_s: 0.013454716186970472\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.4\n",
      "  reward/evaluate_response/avg_total_reward: 0.25\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.34641016151377546\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 3.2\n",
      "  rl_trainer/avg_grpo_loss: 0.044586844742298126\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00048704538494348526\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00048704538494348526\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004896516911685467\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004896516911685467\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.564414309337735\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.564414309337735\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.563432584051043\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.563432584051043\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34660047199577093\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34660047199577093\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010584888979792595\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010584888979792595\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10990826832130551\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10990826832130551\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4670960041694343\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4670960041694343\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5579734398052096\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5579734398052096\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 9, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:38 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:38:42 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:38:42 INFO\u001b[0m Weight update completed (now v10)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:44 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:44 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:44 INFO\u001b[0m Pushing weights for policy version 11\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:47 INFO\u001b[0m Completed weights push in 2.54 seconds\n",
      "Dropping weights @ version 10\n",
      "WandbBackend: Logged 96 metrics at global_step 11\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 11 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.418978820924889e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005802600644528866\n",
      "  dataset/sample/avg_sample_len: 498.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 463.2083333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11117.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.042526204427084\n",
      "  generator_perf/generate/generate/duration_max_s: 5.3868505859375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006434346636136373\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007130879759788513\n",
      "  generator_perf/generate/total_duration_avg_s: 4.043286460421979\n",
      "  generator_perf/generate/total_duration_max_s: 5.387513081952929\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.201894626021385e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.378015339374542e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012081909614304702\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012471908703446388\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.048644988021503\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.393478637095541\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07471688309063514\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07511140732094646\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006833083927631378\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007258614990860224\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.1785643074351055\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.522652002982795\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.59328293800354e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.59328293800354e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.543434966355562\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.543434966355562\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.292398780118674\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.292398780118674\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46983757382258773\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46983757382258773\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.2067688405513763e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.2067688405513763e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.279097800143063\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.279097800143063\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013846190025409064\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001476956531405449\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01318393942589561\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013691358268260956\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00048743638520439464\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0007819170132279396\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 9.28641917804877e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 0.00012648990377783775\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013904953375458717\n",
      "  reference_perf/forward/total_duration_max_s: 0.014749879017472267\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.3666666666666667\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5333333333333333\n",
      "  reward/evaluate_response/avg_total_reward: 0.45\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4496912521077347\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.39440531887330776\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.8\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 12.8\n",
      "  rl_trainer/avg_grpo_loss: 0.02665487676858902\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004634028300642967\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004634028300642967\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048313289880752563\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048313289880752563\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.541537689976394\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.541537689976394\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.540588616859168\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.540588616859168\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3473138860426843\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3473138860426843\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010495065245777369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010495065245777369\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10913696186617017\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10913696186617017\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46694799000397325\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46694799000397325\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2266293056309223\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2266293056309223\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 10, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:47 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:48 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:48 INFO\u001b[0m Pushing weights for policy version 12\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:50 INFO\u001b[0m Completed weights push in 2.38 seconds\n",
      "[0] INFO 10-16 19:38:51 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 11[0] \u001b[34m[Generator-0/1] 2025-10-16 19:38:51 INFO\u001b[0m Weight update completed (now v11)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 12\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 12 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9\n",
      "  buffer/sample/count_sample_requests: 10.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00013622748665511608\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007180990651249886\n",
      "  dataset/sample/avg_sample_len: 723.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 497.875\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3983.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9663033447265625\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9663033447265625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006225280165672302\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006225280165672302\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9671213927417994\n",
      "  generator_perf/generate/total_duration_max_s: 1.9671213927417994\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.468485713005066e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.468485713005066e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011917180381715298\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011917180381715298\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.972477005328983\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.972477005328983\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07457886403426528\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07457886403426528\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006961036007851362\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006961036007851362\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1023573693819344\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1023573693819344\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.366040229797363e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.366040229797363e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.384385408833623\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.384385408833623\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.335415815003216\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.335415815003216\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.47072217892855406\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.47072217892855406\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5656805508770049\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5656805508770049\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 0.914621181320399\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 0.914621181320399\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013462314382195473\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013462314382195473\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012941821943968534\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012941821943968534\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034722406417131424\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034722406417131424\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 9.76361334323883e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.76361334323883e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013523595873266459\n",
      "  reference_perf/forward/total_duration_max_s: 0.013523595873266459\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.7000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.4\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207416\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 5.6000000000000005\n",
      "  rl_trainer/avg_grpo_loss: 0.04272481054067612\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005070078186690807\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005070078186690807\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004937448538839817\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004937448538839817\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.382258677855134\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.382258677855134\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.3812544783577323\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.3812544783577323\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34766700211912394\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34766700211912394\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010593263898044825\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010593263898044825\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.109347112942487\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.109347112942487\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46761264791712165\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46761264791712165\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.569477278739214\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.569477278739214\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 11, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:53 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:38:56 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:38:56 INFO\u001b[0m Weight update completed (now v12)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:38:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:38:59 INFO\u001b[0m Pushing weights for policy version 13\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:00 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:01 INFO\u001b[0m Completed weights push in 2.39 seconds\n",
      "Dropping weights @ version 12\n",
      "WandbBackend: Logged 96 metrics at global_step 13\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 13 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9867924528301886\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9735849056603771\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 7.429588711946397e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005884449928998947\n",
      "  dataset/sample/avg_sample_len: 510.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 510.7916666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12259.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.151458902994791\n",
      "  generator_perf/generate/generate/duration_max_s: 5.40499951171875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006911999980608622\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0008517119884490967\n",
      "  generator_perf/generate/total_duration_avg_s: 4.152251233660927\n",
      "  generator_perf/generate/total_duration_max_s: 5.405905559707433\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.497457752625147e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.124881863594055e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012269490398466587\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012801550328731537\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.157457300306608\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.411569856107235\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07432730418319504\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0746759008616209\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006642342700312535\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006757244002074003\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.286419629119337\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.541072111111134\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.2209943532943726e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.2209943532943726e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.3955830936320126\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.3955830936320126\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.248407881706953\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.248407881706953\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4685090151615441\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4685090151615441\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.659337431192398e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.659337431192398e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.384292081929743\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.384292081929743\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013422841827074686\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013819709420204163\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012934693290541569\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012975719291716814\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034091947600245476\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003472953103482723\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.549875105420749e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.863761857151985e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013487354076157013\n",
      "  reference_perf/forward/total_duration_max_s: 0.01352410577237606\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.049999999999999996\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.4666666666666664\n",
      "  reward/evaluate_response/avg_total_reward: 0.2583333333333332\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.050000000000000024\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3771236166328253\n",
      "  reward/evaluate_response/sum_MathReward_reward: 1.2\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 11.199999999999994\n",
      "  rl_trainer/avg_grpo_loss: 0.04655027389526367\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000437240581959486\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000437240581959486\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004618610255420208\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004618610255420208\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.3936267816461623\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.3936267816461623\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.3927243440411985\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.3927243440411985\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3460405427031219\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3460405427031219\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010536410380154848\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010536410380154848\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10902973171323538\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10902973171323538\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4656086261384189\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4656086261384189\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2600204600021243\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2600204600021243\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 12, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:02 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:03 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:03 INFO\u001b[0m Pushing weights for policy version 14\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:06 INFO\u001b[0m Completed weights push in 2.50 seconds\n",
      "[0] INFO 10-16 19:39:06 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:39:06 INFO\u001b[0m Weight update completed (now v13)\n",
      "Dropping weights @ version 13\n",
      "WandbBackend: Logged 96 metrics at global_step 14\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 14 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8896103896103895\n",
      "  buffer/sample/count_sample_requests: 14.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011975890291588647\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006601158529520035\n",
      "  dataset/sample/avg_sample_len: 514.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.953159912109375\n",
      "  generator_perf/generate/generate/duration_max_s: 1.953159912109375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006086400151252746\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006086400151252746\n",
      "  generator_perf/generate/total_duration_avg_s: 1.953958504125476\n",
      "  generator_perf/generate/total_duration_max_s: 1.953958504125476\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.8554036766290665e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.8554036766290665e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012547848746180534\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012547848746180534\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.959150436334312\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.959150436334312\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07441935176029801\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07441935176029801\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007051929831504822\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007051929831504822\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.0886954511515796\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.0886954511515796\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.958827048540115e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.958827048540115e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5014658509753644\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5014658509753644\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.536090076901019\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.536090076901019\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46945167426019907\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46945167426019907\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.24488168209791183\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.24488168209791183\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.3202836099080741\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.3202836099080741\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001336168497800827\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001336168497800827\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012978334911167622\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012978334911167622\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003155730664730072\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003155730664730072\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 6.590923294425011e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 6.590923294425011e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013495724182575941\n",
      "  reference_perf/forward/total_duration_max_s: 0.013495724182575941\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.15000000000000005\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.033165328204631805\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00047243526205420494\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00047243526205420494\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.000490949023514986\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.000490949023514986\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4993040710687637\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4993040710687637\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4983380530029535\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4983380530029535\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.345462862867862\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.345462862867862\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010498355142772198\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010498355142772198\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11017530178651214\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11017530178651214\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46613891795277596\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46613891795277596\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.424748821184039\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.424748821184039\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 13, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:08 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:39:11 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:39:11 INFO\u001b[0m Weight update completed (now v14)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:14 INFO\u001b[0m Pushing weights for policy version 15\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:15 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:16 INFO\u001b[0m Completed weights push in 2.52 seconds\n",
      "Dropping weights @ version 14\n",
      "WandbBackend: Logged 96 metrics at global_step 15\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 15 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.536588914794465e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006006867624819279\n",
      "  dataset/sample/avg_sample_len: 411.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 503.375\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12081.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.079046142578125\n",
      "  generator_perf/generate/generate/duration_max_s: 5.2446201171875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006453759868939717\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007094079852104187\n",
      "  generator_perf/generate/total_duration_avg_s: 4.079826099899908\n",
      "  generator_perf/generate/total_duration_max_s: 5.245391093172133\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.9250279466311135e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.482882261276245e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012150223677357037\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012688720598816872\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.085118830359231\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.250844051130116\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07423485536128283\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07444846304133534\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006934430915862322\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007338335737586021\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.214886426615219\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.379287154879421\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.437286406755447e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.437286406755447e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5225285049527884\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5225285049527884\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.268274337984622\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.268274337984622\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46859611570835114\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46859611570835114\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.8971972167491913e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.8971972167491913e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.277124297339469\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.277124297339469\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013358409826954207\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013656681403517723\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013022637149939934\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013040369376540184\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034005334600806236\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003410889767110348\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.78643103937308e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.018873631954193e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013576485216617584\n",
      "  reference_perf/forward/total_duration_max_s: 0.013595039024949074\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.20416666666666652\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.4333333333333331\n",
      "  reward/evaluate_response/avg_total_reward: 0.3187499999999998\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3020474116573239\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.36362373715452406\n",
      "  reward/evaluate_response/sum_MathReward_reward: 4.899999999999997\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 10.399999999999995\n",
      "  rl_trainer/avg_grpo_loss: 0.05840887874364853\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004552900791168213\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004552900791168213\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004716329276561737\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004716329276561737\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.52077560313046\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.52077560313046\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5198440542444587\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5198440542444587\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3447282211855054\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3447282211855054\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01068958267569542\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01068958267569542\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11029771296307445\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11029771296307445\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46571818785741925\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46571818785741925\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2208826784044504\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2208826784044504\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 14, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:17 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:17 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:18 INFO\u001b[0m Pushing weights for policy version 16\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:20 INFO\u001b[0m Completed weights push in 2.47 seconds\n",
      "[0] INFO 10-16 19:39:21 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 15\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:39:21 INFO\u001b[0m Weight update completed (now v15)\n",
      "WandbBackend: Logged 96 metrics at global_step 16\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 16 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9230769230769231\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00013141817628191068\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006813881918787956\n",
      "  dataset/sample/avg_sample_len: 520.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9648590087890625\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9648590087890625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006459839940071106\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006459839940071106\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9656997767835855\n",
      "  generator_perf/generate/total_duration_max_s: 1.9656997767835855\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.810001701116562e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.810001701116562e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001302315853536129\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001302315853536129\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9709897488355637\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9709897488355637\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07483591511845589\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07483591511845589\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0071466402150690556\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0071466402150690556\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.100987853948027\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.100987853948027\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.522036761045456e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.522036761045456e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.47522585792467\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.47522585792467\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.56389893591404\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.56389893591404\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4705085209570825\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4705085209570825\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.39622001396492124\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.39622001396492124\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2219378878362477\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2219378878362477\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00016744760796427727\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00016744760796427727\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01321101700887084\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01321101700887084\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00039830803871154785\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00039830803871154785\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.476711809635162e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.476711809635162e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013863636180758476\n",
      "  reference_perf/forward/total_duration_max_s: 0.013863636180758476\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.8\n",
      "  reward/evaluate_response/avg_total_reward: 0.44999999999999996\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3464101615137753\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 6.4\n",
      "  rl_trainer/avg_grpo_loss: 0.08770208060741425\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004953830502927303\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004953830502927303\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004906328395009041\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004906328395009041\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.473062666133046\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.473062666133046\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4720734963193536\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4720734963193536\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34762588888406754\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34762588888406754\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010479509830474854\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010479509830474854\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10930669400840998\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10930669400840998\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.467414537910372\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.467414537910372\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.532112719025463\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.532112719025463\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 15, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:23 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:39:26 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:39:26 INFO\u001b[0m Weight update completed (now v16)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:28 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:28 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:28 INFO\u001b[0m Pushing weights for policy version 17\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:30 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:31 INFO\u001b[0m Completed weights push in 2.52 seconds\n",
      "Dropping weights @ version 16\n",
      "WandbBackend: Logged 96 metrics at global_step 17\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 17 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.99\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.98\n",
      "  buffer/sample/count_sample_requests: 71.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 7.049547193545691e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006145690567791462\n",
      "  dataset/sample/avg_sample_len: 568.3333333333334\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 474.3333333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11384.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.041859700520834\n",
      "  generator_perf/generate/generate/duration_max_s: 5.3499248046875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007007573246955871\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000742143988609314\n",
      "  generator_perf/generate/total_duration_avg_s: 4.042670985843986\n",
      "  generator_perf/generate/total_duration_max_s: 5.350647524680943\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.5408573846022286e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.78220172226429e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012661394042273362\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013086511753499508\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.047694082682331\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.355838602874428\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07423559033001463\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07426955038681626\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007008667724827926\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007264949847012758\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.176558318392684\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.484871739987284\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.017034709453583e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.017034709453583e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5195737588219345\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5195737588219345\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.06613626005128\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.06613626005128\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46559913316741586\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46559913316741586\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.6269274055957794e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.6269274055957794e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.080939949024469\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.080939949024469\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013334117829799652\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013740314170718193\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012951075875510773\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013057013973593712\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033376024415095645\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003364109434187412\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.671179870764415e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.852725684642792e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.0134971272200346\n",
      "  reference_perf/forward/total_duration_max_s: 0.013599792029708624\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.3708333333333332\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.7333333333333334\n",
      "  reward/evaluate_response/avg_total_reward: 0.5520833333333336\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.44672807413707755\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.37712361663282523\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.899999999999997\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 17.6\n",
      "  rl_trainer/avg_grpo_loss: 0.06553943455219269\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000414412934333086\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000414412934333086\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.000480791088193655\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.000480791088193655\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5174408992752433\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5174408992752433\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5165407001040876\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5165407001040876\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3433175911195576\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3433175911195576\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01049635699018836\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01049635699018836\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10865074722096324\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10865074722096324\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4624669919721782\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4624669919721782\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.219014232046902\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.219014232046902\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 16, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:32 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:32 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:32 INFO\u001b[0m Pushing weights for policy version 18\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:35 INFO\u001b[0m Completed weights push in 2.62 seconds\n",
      "[0] INFO 10-16 19:39:35 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:39:35 INFO\u001b[0m Weight update completed (now v17)\n",
      "Dropping weights @ version 17\n",
      "WandbBackend: Logged 96 metrics at global_step 18\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 18 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.881118881118881\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.0001103996943968993\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006906343623995781\n",
      "  dataset/sample/avg_sample_len: 667.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.96530517578125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.96530517578125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006554560065269471\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006554560065269471\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9661505517810582\n",
      "  generator_perf/generate/total_duration_max_s: 1.9661505517810582\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.360266029834747e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.360266029834747e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012119030579924583\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012119030579924583\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9717895747162402\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9717895747162402\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07445366214960814\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07445366214960814\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006691912189126015\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006691912189126015\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.100531762931496\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.100531762931496\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.730187356472015e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.730187356472015e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.6183591899462044\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.6183591899462044\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.554619707167149\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.554619707167149\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4699425366707146\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4699425366707146\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.24522425699979067\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.24522425699979067\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2210868052206933\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2210868052206933\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013564620167016983\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013564620167016983\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012955567799508572\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012955567799508572\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034206220880150795\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034206220880150795\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.67149031162262e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.67149031162262e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01351260719820857\n",
      "  reference_perf/forward/total_duration_max_s: 0.01351260719820857\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.08118124306201935\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004929089918732643\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004929089918732643\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.000500040128827095\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.000500040128827095\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6162695889361203\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6162695889361203\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.6152736051008105\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.6152736051008105\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3465014020912349\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3465014020912349\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010413566138595343\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010413566138595343\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10975982574746013\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10975982574746013\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46667803125455976\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46667803125455976\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.541893137153238\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.541893137153238\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 17, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:37 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:39:41 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:39:41 INFO\u001b[0m Weight update completed (now v18)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:42 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:43 INFO\u001b[0m Pushing weights for policy version 19\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:46 INFO\u001b[0m Completed weights push in 2.54 seconds\n",
      "Dropping weights @ version 18\n",
      "WandbBackend: Logged 96 metrics at global_step 19\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 19 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.61438241703053e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005676639266312122\n",
      "  dataset/sample/avg_sample_len: 516.3333333333334\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 485.5416666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11653.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.113285522460938\n",
      "  generator_perf/generate/generate/duration_max_s: 5.36686181640625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007415146629015604\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0008192319869995118\n",
      "  generator_perf/generate/total_duration_avg_s: 4.114129053124537\n",
      "  generator_perf/generate/total_duration_max_s: 5.367731480393559\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.498932346701622e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.957104101777077e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012362906709313393\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012416769750416279\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.119150116263579\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.3730902178213\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07422577356919646\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07468747301027179\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006866196791330974\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007215644232928753\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.248148204293102\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.503008863888681\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.178844392299652e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.178844392299652e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.543528934009373\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.543528934009373\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.292910741642118\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.292910741642118\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46956502785906196\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46956502785906196\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.4051329344511032e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.4051329344511032e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.279797062743455\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.279797062743455\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.000132467287282149\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.000137201976031065\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012984648967782656\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01300076488405466\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003456765164931615\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00036501744762063026\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.00909474492073e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.145906031131744e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013544950634241104\n",
      "  reference_perf/forward/total_duration_max_s: 0.01354847103357315\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.30416666666666664\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.46666666666666673\n",
      "  reward/evaluate_response/avg_total_reward: 0.3854166666666667\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4476598100740735\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3771236166328253\n",
      "  reward/evaluate_response/sum_MathReward_reward: 7.3\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 11.200000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.018159188330173492\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004890891723334789\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004890891723334789\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004793228581547737\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004793228581547737\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5416823350824416\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5416823350824416\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.540710383094847\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.540710383094847\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34597709216177464\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34597709216177464\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010573281906545162\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010573281906545162\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11024518311023712\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11024518311023712\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46679812390357256\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46679812390357256\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2142348708584905\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2142348708584905\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 18, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:47 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:47 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:47 INFO\u001b[0m Pushing weights for policy version 20\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:50 INFO\u001b[0m Completed weights push in 2.38 seconds\n",
      "[0] INFO 10-16 19:39:50 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 19[0] \u001b[34m[Generator-0/1] 2025-10-16 19:39:50 INFO\u001b[0m Weight update completed (now v19)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 20\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 20 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00013293190083156028\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007746540941298008\n",
      "  dataset/sample/avg_sample_len: 418.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 481.625\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3853.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9512855224609376\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9512855224609376\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005849279761314392\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005849279761314392\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9520508344322443\n",
      "  generator_perf/generate/total_duration_max_s: 1.9520508344322443\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.20758330821991e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.20758330821991e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012377109378576279\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012377109378576279\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9573358204215765\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9573358204215765\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07450199918821454\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07450199918821454\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.00668472982943058\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00668472982943058\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.0869837049394846\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.0869837049394846\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.841014742851257e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.841014742851257e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.380290988832712\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.380290988832712\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.5312735410407186\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.5312735410407186\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4664693637751043\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4664693637751043\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5691193114034832\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5691193114034832\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1153869964182377\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1153869964182377\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001350250095129013\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001350250095129013\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01283495919778943\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01283495919778943\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003314530476927757\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003314530476927757\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.562898099422455e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.562898099422455e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01337971305474639\n",
      "  reference_perf/forward/total_duration_max_s: 0.01337971305474639\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.43750000000000006\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.46874999999999994\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4357106264483342\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207416\n",
      "  reward/evaluate_response/sum_MathReward_reward: 3.5000000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.000000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.05476246774196625\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000496904831379652\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000496904831379652\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.000478456262499094\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.000478456262499094\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.3780763070099056\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.3780763070099056\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.377096028998494\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.377096028998494\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3431373219937086\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3431373219937086\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010576680768281221\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010576680768281221\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1091499300673604\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1091499300673604\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46286704298108816\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46286704298108816\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5548127768561244\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5548127768561244\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 19, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:52 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:39:55 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:39:55 INFO\u001b[0m Weight update completed (now v20)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:57 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:39:58 INFO\u001b[0m Pushing weights for policy version 21\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:39:59 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:01 INFO\u001b[0m Completed weights push in 2.52 seconds\n",
      "Dropping weights @ version 20\n",
      "WandbBackend: Logged 96 metrics at global_step 21\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 21 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9854202401372213\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9708404802744426\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.478971398964122e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005615358240902424\n",
      "  dataset/sample/avg_sample_len: 557.6666666666666\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 510.25\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12246.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.144960367838542\n",
      "  generator_perf/generate/generate/duration_max_s: 5.38667578125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006699519952138265\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007503359913825989\n",
      "  generator_perf/generate/total_duration_avg_s: 4.145751258502404\n",
      "  generator_perf/generate/total_duration_max_s: 5.387524293243885\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.2728382696708046e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.594074562191963e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012066620402038097\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012423931621015072\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.150967760321994\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.393213539849967\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07463756188129385\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07483989698812366\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007024512471010287\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0072183022275567055\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.2809264226816595\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.523838242981583\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.292000085115433e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.292000085115433e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5206260322593153\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5206260322593153\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.369461722206324\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.369461722206324\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46791186975315213\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46791186975315213\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.021901309490204e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.021901309490204e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.380896971095353\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.380896971095353\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001401871753235658\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014984887093305588\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013406792189925909\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01389235071837902\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003775469958782196\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00044499989598989487\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.297773698965709e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.369896724820137e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.014009725457678238\n",
      "  reference_perf/forward/total_duration_max_s: 0.01445769239217043\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.07500000000000001\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.3333333333333334\n",
      "  reward/evaluate_response/avg_total_reward: 0.20416666666666652\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.19843134832984433\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.2981423969999719\n",
      "  reward/evaluate_response/sum_MathReward_reward: 1.8000000000000003\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.000000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.04439495503902435\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004198392853140831\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004198392853140831\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004758038558065891\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004758038558065891\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5187898613512516\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5187898613512516\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5178910098038614\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5178910098038614\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3448308790102601\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3448308790102601\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010638902895152569\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010638902895152569\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10922070406377316\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10922070406377316\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4646929460577667\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4646929460577667\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.266077980864793\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.266077980864793\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 20, took 0.48 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:02 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:02 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:02 INFO\u001b[0m Pushing weights for policy version 22\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:05 INFO\u001b[0m Completed weights push in 2.51 seconds\n",
      "[0] INFO 10-16 19:40:05 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 21[0] \u001b[34m[Generator-0/1] 2025-10-16 19:40:05 INFO\u001b[0m Weight update completed (now v21)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 22\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 22 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.905982905982906\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011028868791002494\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006813290528953075\n",
      "  dataset/sample/avg_sample_len: 453.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.989188232421875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.989188232421875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007058240175247193\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007058240175247193\n",
      "  generator_perf/generate/total_duration_avg_s: 1.990078024432063\n",
      "  generator_perf/generate/total_duration_max_s: 1.990078024432063\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.356773570179939e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.356773570179939e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012132269330322742\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012132269330322742\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9952134350314736\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9952134350314736\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07452160026878119\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07452160026878119\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0066741700284183025\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0066741700284183025\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1242464049719274\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1242464049719274\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.162321031093597e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.162321031093597e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5090809972025454\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5090809972025454\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.586802841164172\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.586802841164172\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4684952520765364\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4684952520765364\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.38672306668013334\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.38672306668013334\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2224961388856173\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2224961388856173\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013507530093193054\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013507530093193054\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012827627826482058\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012827627826482058\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033786287531256676\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033786287531256676\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.141621947288513e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.141621947288513e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013384606223553419\n",
      "  reference_perf/forward/total_duration_max_s: 0.013384606223553419\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.037500000000000006\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.3\n",
      "  reward/evaluate_response/avg_total_reward: 0.16875\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.04841229182759271\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.2645751311064591\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.30000000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 2.4\n",
      "  rl_trainer/avg_grpo_loss: 7.3193440437316895\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005471319891512394\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005471319891512394\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004912707954645157\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004912707954645157\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.507022029720247\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.507022029720247\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5059785558842123\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5059785558842123\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3451086007989943\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3451086007989943\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010549015365540981\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010549015365540981\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10937501164153218\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10937501164153218\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4650363312102854\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4650363312102854\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.563739022705704\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.563739022705704\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 21, took 0.48 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:07 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:40:10 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:40:10 INFO\u001b[0m Weight update completed (now v22)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:12 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:13 INFO\u001b[0m Pushing weights for policy version 23\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:16 INFO\u001b[0m Completed weights push in 2.55 seconds\n",
      "Dropping weights @ version 22\n",
      "WandbBackend: Logged 96 metrics at global_step 23\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 23 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9811320754716981\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 7.259831260386352e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005564410239458084\n",
      "  dataset/sample/avg_sample_len: 550.3333333333334\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.154927408854167\n",
      "  generator_perf/generate/generate/duration_max_s: 5.40333203125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006701440016428629\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006967999935150146\n",
      "  generator_perf/generate/total_duration_avg_s: 4.155691088855266\n",
      "  generator_perf/generate/total_duration_max_s: 5.404051679249853\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.554904833436012e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.024392157793045e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012345113791525364\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012954659759998322\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.16065332883348\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.40919786086306\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07435640739277005\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07447528000921011\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0067682876251637936\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006925784982740879\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.290190342968951\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.538273854646832\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.370696842670441e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.370696842670441e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5514199528843164\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5514199528843164\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.406513640191406\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.406513640191406\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46882714005187154\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46882714005187154\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.3429205864667892e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.3429205864667892e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.386247192043811\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.386247192043811\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013631007944544157\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001398199237883091\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013518628664314747\n",
      "  reference_perf/forward/forward/duration_max_s: 0.014273167122155428\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003445528758068879\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00035266391932964325\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.426761875549953e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.875085040926933e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.014086085216452679\n",
      "  reference_perf/forward/total_duration_max_s: 0.014845019206404686\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.10000000000000003\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.3333333333333334\n",
      "  reward/evaluate_response/avg_total_reward: 0.21666666666666654\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.2981423969999719\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.400000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.000000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.030295293778181076\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004299911670386791\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004299911670386791\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00045838067308068275\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00045838067308068275\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5496055772528052\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5496055772528052\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.548714267089963\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.548714267089963\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34564872924238443\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34564872924238443\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010557897854596376\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010557897854596376\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10970001015812159\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10970001015812159\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4659086731262505\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4659086731262505\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.261660119984299\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.261660119984299\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 22, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:17 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:17 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:17 INFO\u001b[0m Pushing weights for policy version 24\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:20 INFO\u001b[0m Completed weights push in 2.60 seconds\n",
      "[0] INFO 10-16 19:40:20 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 23[0] \u001b[34m[Generator-0/1] 2025-10-16 19:40:20 INFO\u001b[0m Weight update completed (now v23)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 24\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 24 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00014699262101203203\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007410873658955097\n",
      "  dataset/sample/avg_sample_len: 391.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 479.125\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3833.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.957073974609375\n",
      "  generator_perf/generate/generate/duration_max_s: 1.957073974609375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007329919934272766\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007329919934272766\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9579875106066464\n",
      "  generator_perf/generate/total_duration_max_s: 1.9579875106066464\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.491722211241722e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.491722211241722e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012006526812911034\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012006526812911034\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9635282051749527\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9635282051749527\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07429776480421424\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07429776480421424\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006763745099306107\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006763745099306107\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.092635635752231\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.092635635752231\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.809815436601639e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.809815436601639e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.597621307708323\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.597621307708323\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.4289127960801125\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.4289127960801125\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4697354049421847\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4697354049421847\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.24548185616731644\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.24548185616731644\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1160672302357852\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1160672302357852\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013648578897118568\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013648578897118568\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013010636903345585\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013010636903345585\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003357040695846081\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003357040695846081\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.573002949357033e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.573002949357033e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01356081385165453\n",
      "  reference_perf/forward/total_duration_max_s: 0.01356081385165453\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.43750000000000006\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 0.7187499999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4357106264483342\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 3.5000000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.06987178325653076\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004994752816855907\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004994752816855907\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004684128798544407\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004684128798544407\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.595293075311929\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.595293075311929\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5943221068009734\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5943221068009734\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3471329528838396\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3471329528838396\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010590753052383661\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010590753052383661\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10897686565294862\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10897686565294862\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4667028486728668\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4667028486728668\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.456108027137816\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.456108027137816\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 23, took 0.46 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:22 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:40:25 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:40:25 INFO\u001b[0m Weight update completed (now v24)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:27 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:27 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:28 INFO\u001b[0m Pushing weights for policy version 25\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:30 INFO\u001b[0m Completed weights push in 2.61 seconds\n",
      "Dropping weights @ version 24\n",
      "WandbBackend: Logged 96 metrics at global_step 25\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 25 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.512901426790511e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.000586808193475008\n",
      "  dataset/sample/avg_sample_len: 475.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 496.5833333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11918.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.103422648111979\n",
      "  generator_perf/generate/generate/duration_max_s: 5.27110302734375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006078826586405436\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006684160232543945\n",
      "  generator_perf/generate/total_duration_avg_s: 4.104128664102405\n",
      "  generator_perf/generate/total_duration_max_s: 5.271691283319146\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.614556044340134e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.0028244256973267e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001222456805408001\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012385603040456772\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.1092322746602195\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.277440418954939\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0745764773649474\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07479849085211754\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007758858613669872\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007958891801536083\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.240459800697863\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.4094348177313805\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.61190938949585e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.61190938949585e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.609036992304027\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.609036992304027\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.35664353473112\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.35664353473112\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4663595398887992\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4663595398887992\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.9082799553871155e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.9082799553871155e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.281220975797623\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.281220975797623\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001411375900109609\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00015873368829488754\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01332706461350123\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013746900018304586\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003566623975833257\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003960062749683857\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.935597871740659e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.470891043543816e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013906332664191723\n",
      "  reference_perf/forward/total_duration_max_s: 0.014303583651781082\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.3166666666666666\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.7999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.5583333333333335\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3954603505901557\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3464101615137756\n",
      "  reward/evaluate_response/sum_MathReward_reward: 7.599999999999998\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 19.199999999999996\n",
      "  rl_trainer/avg_grpo_loss: 0.06432373821735382\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004239371046423912\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004239371046423912\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047407159581780434\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047407159581780434\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6070945779792964\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6070945779792964\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.6061937562189996\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.6061937562189996\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3436847631819546\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3436847631819546\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010417470708489418\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010417470708489418\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10895403707399964\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10895403707399964\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4630587659776211\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4630587659776211\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.261167470831424\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.261167470831424\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 24, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:31 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:32 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:32 INFO\u001b[0m Pushing weights for policy version 26\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:34 INFO\u001b[0m Completed weights push in 2.40 seconds\n",
      "[0] INFO 10-16 19:40:35 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 25[0] \u001b[34m[Generator-0/1] 2025-10-16 19:40:35 INFO\u001b[0m Weight update completed (now v25)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 26\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 26 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.0001174025625611345\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007265289314091206\n",
      "  dataset/sample/avg_sample_len: 494.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 485.75\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3886.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9484193115234374\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9484193115234374\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006202880144119263\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006202880144119263\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9492267355322839\n",
      "  generator_perf/generate/total_duration_max_s: 1.9492267355322839\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.88269904255867e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.88269904255867e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012330571189522743\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012330571189522743\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.954219811130315\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.954219811130315\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07448005815967917\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07448005815967917\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007218808867037296\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007218808867037296\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.0849221544340253\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.0849221544340253\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.042646080255508e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.042646080255508e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.405090358108282\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.405090358108282\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.530859271064401\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.530859271064401\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46861692424863577\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46861692424863577\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5432588709518313\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5432588709518313\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1138859107159078\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1138859107159078\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013515399768948555\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013515399768948555\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013056725263595581\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013056725263595581\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033949408680200577\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033949408680200577\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.820874452590942e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.820874452590942e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01361186895519495\n",
      "  reference_perf/forward/total_duration_max_s: 0.01361186895519495\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.55\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.7000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.625\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.44999999999999996\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207416\n",
      "  reward/evaluate_response/sum_MathReward_reward: 4.4\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 5.6000000000000005\n",
      "  rl_trainer/avg_grpo_loss: 0.04798661544919014\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005455468781292439\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005455468781292439\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004949471913278103\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004949471913278103\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4029888878576458\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4029888878576458\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.401945624034852\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.401945624034852\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3453865759074688\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3453865759074688\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01048119505867362\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01048119505867362\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1095027020201087\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1095027020201087\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4653747137635946\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4653747137635946\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5568264382891357\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5568264382891357\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 25, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:37 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:40:40 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:40:40 INFO\u001b[0m Weight update completed (now v26)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:42 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:42 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:42 INFO\u001b[0m Pushing weights for policy version 27\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:44 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:45 INFO\u001b[0m Completed weights push in 2.54 seconds\n",
      "Dropping weights @ version 26\n",
      "WandbBackend: Logged 96 metrics at global_step 27\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 27 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.99\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.98\n",
      "  buffer/sample/count_sample_requests: 71.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.5491484859040085e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005910187028348446\n",
      "  dataset/sample/avg_sample_len: 483.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 474.5416666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11389.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.049943684895833\n",
      "  generator_perf/generate/generate/duration_max_s: 5.38538818359375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006056320071220399\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006961920261383057\n",
      "  generator_perf/generate/total_duration_avg_s: 4.050664698239416\n",
      "  generator_perf/generate/total_duration_max_s: 5.386103479608893\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.4133514165878296e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.8282166719436646e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011727763339877129\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012166090309619904\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.056212798692286\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.392470970284194\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07434678729623556\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07462662272155285\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007694953276465337\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.008420544676482677\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.189055359611909\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.523671264760196\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.536937922239304e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.536937922239304e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5386825101450086\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5386825101450086\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.079136983957142\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.079136983957142\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4677431620657444\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4677431620657444\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.3502856492996216e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.3502856492996216e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.072681029792875\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.072681029792875\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013261955852309862\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013622688129544258\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012955099499473969\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013020175974816084\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033469342937072116\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033694319427013397\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.02048792441686e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.097803220152855e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01350455436234673\n",
      "  reference_perf/forward/total_duration_max_s: 0.013571536168456078\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.3708333333333332\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.6666666666666666\n",
      "  reward/evaluate_response/avg_total_reward: 0.5187500000000002\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.44672807413707755\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.39440531887330776\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.899999999999997\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 15.999999999999998\n",
      "  rl_trainer/avg_grpo_loss: 0.05524798482656479\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00041574612259864807\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00041574612259864807\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00045280903577804565\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00045280903577804565\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5367946731857955\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5367946731857955\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.535923514980823\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.535923514980823\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3458343707025051\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3458343707025051\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01048473920673132\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01048473920673132\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10864376788958907\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10864376788958907\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46496503381058574\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46496503381058574\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2716422891244292\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2716422891244292\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 26, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:46 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:46 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:47 INFO\u001b[0m Pushing weights for policy version 28\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:49 INFO\u001b[0m Completed weights push in 2.51 seconds\n",
      "[0] INFO 10-16 19:40:49 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:40:49 INFO\u001b[0m Weight update completed (now v27)\n",
      "Dropping weights @ version 27\n",
      "WandbBackend: Logged 96 metrics at global_step 28\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 28 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.881118881118881\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.0001129469690987697\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006977841258049011\n",
      "  dataset/sample/avg_sample_len: 483.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9612373046875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9612373046875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005986239910125733\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005986239910125733\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9620199606716633\n",
      "  generator_perf/generate/total_duration_max_s: 1.9620199606716633\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.773082375526428e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.773082375526428e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011488460004329681\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011488460004329681\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9676866736263037\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9676866736263037\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07447674125432968\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07447674125432968\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007193305063992739\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007193305063992739\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.097904419992119\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.097904419992119\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.8209913074970245e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.8209913074970245e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.516372221056372\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.516372221056372\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.45235499786213\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.45235499786213\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4691207171417773\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4691207171417773\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.24744837591424584\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.24744837591424584\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.219406590797007\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.219406590797007\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013618683442473412\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013618683442473412\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012949157040566206\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012949157040566206\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00035753799602389336\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00035753799602389336\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.674191147089005e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.674191147089005e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.0135216168127954\n",
      "  reference_perf/forward/total_duration_max_s: 0.0135216168127954\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.03116966038942337\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005224980413913727\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005224980413913727\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047349603846669197\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047349603846669197\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.513988913036883\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.513988913036883\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5129886558279395\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5129886558279395\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3444003127515316\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3444003127515316\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010650762356817722\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010650762356817722\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11101453378796577\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11101453378796577\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4660685178823769\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4660685178823769\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.443660923279822\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.443660923279822\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 27, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:51 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:40:55 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:40:55 INFO\u001b[0m Weight update completed (now v28)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:57 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:57 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:40:57 INFO\u001b[0m Pushing weights for policy version 29\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:40:59 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:00 INFO\u001b[0m Completed weights push in 2.63 seconds\n",
      "Dropping weights @ version 28\n",
      "WandbBackend: Logged 96 metrics at global_step 29\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 29 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.497012848723424e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005960268899798393\n",
      "  dataset/sample/avg_sample_len: 467.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 486.9166666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11686.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.102209757486979\n",
      "  generator_perf/generate/generate/duration_max_s: 5.25573583984375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006095466613769531\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006842560172080994\n",
      "  generator_perf/generate/total_duration_avg_s: 4.1029182268170015\n",
      "  generator_perf/generate/total_duration_max_s: 5.256481375861913\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.8096060355504356e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.870304837822914e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011973613873124123\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012100650928914547\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.108164439133058\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.262040303088725\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07429611124098301\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07461784780025482\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007318034923324983\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007410960737615824\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.238191147179653\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.392948226071894\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.184897989034653e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.184897989034653e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.631899361964315\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.631899361964315\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.38160050008446\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.38160050008446\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4696304830722511\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4696304830722511\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.7690006643533707e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.7690006643533707e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.280046810861677\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.280046810861677\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013435538858175278\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013761082664132118\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012916870415210724\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012963713146746159\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003383527509868145\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003407709300518036\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.768580690026283e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.114520460367203e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01346931653097272\n",
      "  reference_perf/forward/total_duration_max_s: 0.013512492645531893\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.3541666666666665\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5666666666666664\n",
      "  reward/evaluate_response/avg_total_reward: 0.46041666666666686\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.41531029229828736\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.39860869143671324\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.499999999999996\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 13.599999999999994\n",
      "  rl_trainer/avg_grpo_loss: 0.042404837906360626\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004393532872200012\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004393532872200012\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004574339836835861\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004574339836835861\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.630009633023292\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.630009633023292\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.629109744913876\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.629109744913876\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3466060352511704\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3466060352511704\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010516901966184378\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010516901966184378\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1089894138276577\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1089894138276577\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4661166602745652\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4661166602745652\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2634713570587337\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2634713570587337\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 28, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:01 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:01 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:02 INFO\u001b[0m Pushing weights for policy version 30\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:04 INFO\u001b[0m Completed weights push in 2.58 seconds\n",
      "[0] INFO 10-16 19:41:04 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:41:04 INFO\u001b[0m Weight update completed (now v29)\n",
      "Dropping weights @ version 29\n",
      "WandbBackend: Logged 96 metrics at global_step 30\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 30 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.905982905982906\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00012108314639100662\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006692903116345406\n",
      "  dataset/sample/avg_sample_len: 433.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 2.01162109375\n",
      "  generator_perf/generate/generate/duration_max_s: 2.01162109375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000643231987953186\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000643231987953186\n",
      "  generator_perf/generate/total_duration_avg_s: 2.012451749742031\n",
      "  generator_perf/generate/total_duration_max_s: 2.012451749742031\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 6.804009899497032e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 6.804009899497032e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001229213085025549\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001229213085025549\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 2.01765852002427\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 2.01765852002427\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0749141899868846\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0749141899868846\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007472219876945019\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007472219876945019\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1543966657482088\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1543966657482088\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.798173904418945e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.798173904418945e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5831657531671226\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5831657531671226\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.528468433301896\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.528468433301896\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4722333028912544\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4722333028912544\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.2472661859355867\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.2472661859355867\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2257962450385094\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2257962450385094\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014121085405349731\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014121085405349731\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012893914245069027\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012893914245069027\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033392012119293213\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033392012119293213\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.71908089518547e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.71908089518547e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01344832731410861\n",
      "  reference_perf/forward/total_duration_max_s: 0.01344832731410861\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.049931250512599945\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000555011909455061\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000555011909455061\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004886290989816189\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004886290989816189\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5809087022207677\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5809087022207677\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.579861642792821\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.579861642792821\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3482156516984105\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3482156516984105\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010564618278294802\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010564618278294802\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11013642884790897\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11013642884790897\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4689192986115813\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4689192986115813\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5083476388826966\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5083476388826966\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 29, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:06 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:41:10 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:41:10 INFO\u001b[0m Weight update completed (now v30)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:12 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:12 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:12 INFO\u001b[0m Pushing weights for policy version 31\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:15 INFO\u001b[0m Completed weights push in 2.60 seconds\n",
      "Dropping weights @ version 30\n",
      "WandbBackend: Logged 96 metrics at global_step 31\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 31 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 2.2452830188679247\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.616685845672268e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006094980053603649\n",
      "  dataset/sample/avg_sample_len: 541.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 452.0833333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 10850.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.106092651367187\n",
      "  generator_perf/generate/generate/duration_max_s: 5.30280029296875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006047679980595907\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006512320041656494\n",
      "  generator_perf/generate/total_duration_avg_s: 4.1067909446979565\n",
      "  generator_perf/generate/total_duration_max_s: 5.3034738609604535\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.748604406913122e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.893215373158455e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012330515310168266\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001245254185050726\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.111820660997182\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.308934201020747\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07438773739462097\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07449537329375744\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007640587942053874\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007860418874770403\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.241937752813101\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.440049733035266\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.340894520282745e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.340894520282745e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.603458685334772\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.603458685334772\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.349738277029246\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.349738277029246\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46417000191286206\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46417000191286206\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.8728896975517273e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.8728896975517273e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.282084709964693\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.282084709964693\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013785545403758684\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014413334429264069\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013109164622922739\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013253415003418922\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00037271079296867055\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00044471677392721176\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.212712903817494e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.973898366093636e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013703982345759869\n",
      "  reference_perf/forward/total_duration_max_s: 0.01393417315557599\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.6249999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.9666666666666667\n",
      "  reward/evaluate_response/avg_total_reward: 0.7958333333333335\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4437059837324712\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.15986105077709065\n",
      "  reward/evaluate_response/sum_MathReward_reward: 14.999999999999998\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 23.2\n",
      "  rl_trainer/avg_grpo_loss: 0.04362966865301132\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004321807064116001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004321807064116001\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00046341726556420326\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00046341726556420326\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6014621909707785\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6014621909707785\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.600563429761678\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.600563429761678\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34156277123838663\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34156277123838663\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010567690711468458\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010567690711468458\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10928220907226205\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10928220907226205\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46141523122787476\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46141523122787476\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2443110798485577\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2443110798485577\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 30, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:16 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:16 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:16 INFO\u001b[0m Pushing weights for policy version 32\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:19 INFO\u001b[0m Completed weights push in 2.51 seconds\n",
      "[0] INFO 10-16 19:41:19 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 31[0] \u001b[34m[Generator-0/1] 2025-10-16 19:41:19 INFO\u001b[0m Weight update completed (now v31)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 32\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 32 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011051702313125134\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006664539687335491\n",
      "  dataset/sample/avg_sample_len: 769.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9762449951171874\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9762449951171874\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007161279916763306\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007161279916763306\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9771424671113491\n",
      "  generator_perf/generate/total_duration_max_s: 1.9771424671113491\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.6164804846048355e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.6164804846048355e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011974787339568138\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011974787339568138\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.982601880095899\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.982601880095899\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0745052732527256\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0745052732527256\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007454040925949812\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007454040925949812\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1133231138810515\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1133231138810515\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.82611358165741e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.82611358165741e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5168037111870944\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5168037111870944\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.521323682740331\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.521323682740331\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4688577838242054\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4688577838242054\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4220731626264751\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4220731626264751\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1135820890776813\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1135820890776813\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.000136468093842268\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.000136468093842268\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013138561975210905\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013138561975210905\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003367234021425247\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003367234021425247\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.651280611753464e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.651280611753464e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01369032496586442\n",
      "  reference_perf/forward/total_duration_max_s: 0.01369032496586442\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0125\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.10625\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.033071891388307385\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.1\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.04569457471370697\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005237841978669167\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005237841978669167\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0005392320454120636\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0005392320454120636\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.514346712268889\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.514346712268889\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5132789639756083\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5132789639756083\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34536886820569634\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34536886820569634\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010500597767531872\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010500597767531872\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1097593572922051\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1097593572922051\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46563255228102207\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46563255228102207\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.554945867974311\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.554945867974311\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 31, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:21 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:41:24 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:41:24 INFO\u001b[0m Weight update completed (now v32)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:27 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:27 INFO\u001b[0m Pushing weights for policy version 33\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:30 INFO\u001b[0m Completed weights push in 2.57 seconds\n",
      "Dropping weights @ version 32\n",
      "WandbBackend: Logged 96 metrics at global_step 33\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 33 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.39605365428206e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006032041274011135\n",
      "  dataset/sample/avg_sample_len: 468.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 511.125\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12267.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.131128662109375\n",
      "  generator_perf/generate/generate/duration_max_s: 5.377474609375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.00070632533232371\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0008712959885597229\n",
      "  generator_perf/generate/total_duration_avg_s: 4.131948843441903\n",
      "  generator_perf/generate/total_duration_max_s: 5.378391185361892\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.030220831433932e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.826020449399948e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012129610404372215\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012587509118020535\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.137136985082179\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.38402304193005\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07440551587690909\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0745664220303297\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007317908263454835\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.008005333133041859\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.267065972400208\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.514617947861552\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.399102181196213e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.399102181196213e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.566709376871586\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.566709376871586\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.309629363007843\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.309629363007843\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46919395215809345\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46919395215809345\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.774309203028679e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.774309203028679e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.273701786994934\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.273701786994934\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013469671830534935\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001367870718240738\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013547494697074095\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013883693143725395\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003466499038040638\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.000362553633749485\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.79122735063235e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.926905527710915e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.014108922642966112\n",
      "  reference_perf/forward/total_duration_max_s: 0.014430683106184006\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.10000000000000002\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.36666666666666664\n",
      "  reward/evaluate_response/avg_total_reward: 0.2333333333333331\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.19364916731037085\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3248931448269655\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.4000000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.799999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.04387364536523819\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00044628512114286423\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00044628512114286423\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004820702597498894\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004820702597498894\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5649794042110443\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5649794042110443\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.564047845080495\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.564047845080495\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.346103569958359\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.346103569958359\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010631273966282606\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010631273966282606\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10971599910408258\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10971599910408258\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46645303070545197\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46645303070545197\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2306650429964066\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2306650429964066\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 32, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:31 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:31 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:31 INFO\u001b[0m Pushing weights for policy version 34\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:34 INFO\u001b[0m Completed weights push in 2.57 seconds\n",
      "[0] INFO 10-16 19:41:34 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:41:34 INFO\u001b[0m Weight update completed (now v33)\n",
      "Dropping weights @ version 33\n",
      "WandbBackend: Logged 96 metrics at global_step 34\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 34 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.863905325443787\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011480126816492814\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007470441050827503\n",
      "  dataset/sample/avg_sample_len: 785.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 454.875\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3639.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.943769775390625\n",
      "  generator_perf/generate/generate/duration_max_s: 1.943769775390625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0004870719909667969\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0004870719909667969\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9444404633790255\n",
      "  generator_perf/generate/total_duration_max_s: 1.9444404633790255\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.804421380162239e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.804421380162239e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012001730501651764\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012001730501651764\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9499203185550869\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9499203185550869\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07454464118927717\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07454464118927717\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007784917019307613\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007784917019307613\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.0808105189353228\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.0808105189353228\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.195848643779755e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.195848643779755e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.571117323823273\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.571117323823273\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.507254080381244\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.507254080381244\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.47057875199243426\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.47057875199243426\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.24581615393981338\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.24581615393981338\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2197343683801591\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2197343683801591\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013671210035681725\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013671210035681725\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013355647213757038\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013355647213757038\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033192476257681847\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033192476257681847\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.659196853637695e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.659196853637695e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013902798760682344\n",
      "  reference_perf/forward/total_duration_max_s: 0.013902798760682344\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.6624999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.9\n",
      "  reward/evaluate_response/avg_total_reward: 0.7812499999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4357106264483345\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.26457513110645897\n",
      "  reward/evaluate_response/sum_MathReward_reward: 5.299999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 7.2\n",
      "  rl_trainer/avg_grpo_loss: 0.050516873598098755\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004953262396156788\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004953262396156788\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004899380728602409\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004899380728602409\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.568682436365634\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.568682436365634\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.567692393902689\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.567692393902689\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.347779240924865\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.347779240924865\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010451632086187601\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010451632086187601\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10906219156458974\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10906219156458974\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.467296386603266\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.467296386603266\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5072081531398\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5072081531398\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 33, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:36 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:41:39 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:41:39 INFO\u001b[0m Weight update completed (now v34)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:41 INFO\u001b[0m Pushing weights for policy version 35\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:44 INFO\u001b[0m Completed weights push in 2.57 seconds\n",
      "Dropping weights @ version 34\n",
      "WandbBackend: Logged 96 metrics at global_step 35\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 35 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9895833333333334\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9791666666666667\n",
      "  buffer/sample/count_sample_requests: 69.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.113672923998556e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006203129887580872\n",
      "  dataset/sample/avg_sample_len: 437.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 442.9583333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 10631.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 3.9984794921874998\n",
      "  generator_perf/generate/generate/duration_max_s: 5.32490185546875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000670143981774648\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0008407679796218872\n",
      "  generator_perf/generate/total_duration_avg_s: 3.999270820168157\n",
      "  generator_perf/generate/total_duration_max_s: 5.325793727450073\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.1404739022254944e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 6.013503298163414e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012237161087493102\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001234671100974083\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.004805568916102\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.3316774680279195\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07424779189750552\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07458113878965378\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007655791783084472\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00774155929684639\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.1350085286734\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.46270957402885\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.4298358261585236e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.4298358261585236e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5694762808270752\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5694762808270752\n",
      "  main_perf/continuous_training/total_duration_avg_s: 9.90833321493119\n",
      "  main_perf/continuous_training/total_duration_max_s: 9.90833321493119\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4671285510994494\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4671285510994494\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.0381994545459747e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.0381994545459747e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 6.871701071970165\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 6.871701071970165\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013450967768828073\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013690395280718803\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013143537721286217\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013201260939240456\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033690764879186946\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034295301884412766\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.117578302820523e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.238432928919792e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013698137986163298\n",
      "  reference_perf/forward/total_duration_max_s: 0.0137575538828969\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.4374999999999998\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.6666666666666664\n",
      "  reward/evaluate_response/avg_total_reward: 0.5520833333333335\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.43571062644833447\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3944053188733079\n",
      "  reward/evaluate_response/sum_MathReward_reward: 10.499999999999995\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 15.999999999999995\n",
      "  rl_trainer/avg_grpo_loss: 0.06948202848434448\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004189908504486084\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004189908504486084\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048650382086634636\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048650382086634636\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5674548191018403\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5674548191018403\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.566546158399433\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.566546158399433\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34419087786227465\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34419087786227465\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010587919037789106\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010587919037789106\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10943712526932359\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10943712526932359\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.464218168053776\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.464218168053776\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.227842604275793\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.227842604275793\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 34, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:46 INFO\u001b[0m Pushing weights for policy version 36\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:48 INFO\u001b[0m Completed weights push in 2.52 seconds\n",
      "[0] INFO 10-16 19:41:49 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:41:49 INFO\u001b[0m Weight update completed (now v35)\n",
      "Dropping weights @ version 35\n",
      "WandbBackend: Logged 96 metrics at global_step 36\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 36 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.881118881118881\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011150223704484793\n",
      "  buffer_perf/sample/total_duration_max_s: 0.000699714757502079\n",
      "  dataset/sample/avg_sample_len: 459.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 399.875\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3199.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9023267822265626\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9023267822265626\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005463359951972961\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005463359951972961\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9031351342201233\n",
      "  generator_perf/generate/total_duration_max_s: 1.9031351342201233\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.6055298298597336e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.6055298298597336e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001179507002234459\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001179507002234459\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.908891533035785\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.908891533035785\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07458820985630155\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07458820985630155\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007679644972085953\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007679644972085953\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.038743759971112\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.038743759971112\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.739966243505478e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.739966243505478e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.525169755797833\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.525169755797833\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.622807941865176\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.622807941865176\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4676841590553522\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4676841590553522\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4120651730336249\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4120651730336249\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2178817638196051\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2178817638196051\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001371302641928196\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001371302641928196\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013255584053695202\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013255584053695202\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034384336322546005\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034384336322546005\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.28825868666172e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.28825868666172e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013821541331708431\n",
      "  reference_perf/forward/total_duration_max_s: 0.013821541331708431\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.8875\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 0.94375\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.2976470224947665\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 7.1\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.06590071320533752\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004819757305085659\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004819757305085659\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047768326476216316\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047768326476216316\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5230341949500144\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5230341949500144\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.522071257699281\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.522071257699281\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34542729379609227\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34542729379609227\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010446109808981419\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010446109808981419\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10865481616929173\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10865481616929173\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4645306668244302\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4645306668244302\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.613976001739502\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.613976001739502\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 35, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:51 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:41:54 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:41:54 INFO\u001b[0m Weight update completed (now v36)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:57 INFO\u001b[0m Pushing weights for policy version 37\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:41:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:41:59 INFO\u001b[0m Completed weights push in 2.48 seconds\n",
      "Dropping weights @ version 36WandbBackend: Logged 96 metrics at global_step 37\n",
      "\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 37 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9937106918238992\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.61091589545076e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005783890374004841\n",
      "  dataset/sample/avg_sample_len: 597.3333333333334\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 506.625\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12159.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.187929402669272\n",
      "  generator_perf/generate/generate/duration_max_s: 5.4940283203125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006607146660486857\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006960639953613281\n",
      "  generator_perf/generate/total_duration_avg_s: 4.188714469332248\n",
      "  generator_perf/generate/total_duration_max_s: 5.494820064291358\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.1878471771876015e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.96451573073864e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001192388590425253\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012496081180870533\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.193679710694899\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.499871601816267\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07461471250280738\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07466521067544818\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007486988479892413\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00768988998606801\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.325037493060033\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.629956366028637\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.61796298623085e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.61796298623085e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.47813927102834\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.47813927102834\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.330755351111293\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.330755351111293\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4659715420566499\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4659715420566499\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.0342878997325897e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.0342878997325897e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.386617891024798\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.386617891024798\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001424263852337996\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00015904288738965988\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013300284743309021\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013512871228158474\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003643813543021679\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0004170420579612255\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.375290781259537e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.902093395590782e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01389303601657351\n",
      "  reference_perf/forward/total_duration_max_s: 0.014066913165152073\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0375\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5333333333333331\n",
      "  reward/evaluate_response/avg_total_reward: 0.2854166666666665\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.04841229182759273\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.39440531887330765\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.8999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 12.799999999999994\n",
      "  rl_trainer/avg_grpo_loss: 0.06601501256227493\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004364028573036194\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004364028573036194\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047729117795825005\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047729117795825005\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4762892429716885\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4762892429716885\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4753710636869073\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4753710636869073\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34374171029776335\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34374171029776335\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010533650871366262\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010533650871366262\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10882685985416174\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10882685985416174\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46310428297147155\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46310428297147155\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2589243627153337\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2589243627153337\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 36, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:00 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:00 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:01 INFO\u001b[0m Pushing weights for policy version 38\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:03 INFO\u001b[0m Completed weights push in 2.59 seconds\n",
      "[0] INFO 10-16 19:42:04 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 37[0] \u001b[34m[Generator-0/1] 2025-10-16 19:42:04 INFO\u001b[0m Weight update completed (now v37)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 38\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 38 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9126984126984128\n",
      "  buffer/sample/count_sample_requests: 14.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010931069430496012\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007015308365225792\n",
      "  dataset/sample/avg_sample_len: 519.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 481.5\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3852.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.975718505859375\n",
      "  generator_perf/generate/generate/duration_max_s: 1.975718505859375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007239360213279724\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007239360213279724\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9766231778860093\n",
      "  generator_perf/generate/total_duration_max_s: 1.9766231778860093\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.528788849711418e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.528788849711418e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011897911317646503\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011897911317646503\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.98223329288885\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.98223329288885\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07451920909807086\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07451920909807086\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0070225149393081665\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0070225149393081665\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.11207594582811\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.11207594582811\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.794689059257507e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.794689059257507e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.590741658117622\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.590741658117622\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.631972618866712\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.631972618866712\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4677527598105371\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4677527598105371\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.2481375802308321\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.2481375802308321\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.3253326187841594\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.3253326187841594\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013895565643906593\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013895565643906593\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01286134822294116\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01286134822294116\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033875182271003723\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033875182271003723\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.032610639929771e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.032610639929771e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013421400915831327\n",
      "  reference_perf/forward/total_duration_max_s: 0.013421400915831327\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.425\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.7\n",
      "  reward/evaluate_response/avg_total_reward: 0.5625\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.44651427748729383\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207418\n",
      "  reward/evaluate_response/sum_MathReward_reward: 3.4\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 5.6\n",
      "  rl_trainer/avg_grpo_loss: 0.03704196214675903\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005829748697578907\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005829748697578907\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004966561682522297\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004966561682522297\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5885715638287365\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5885715638287365\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.587488838005811\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.587488838005811\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34449868835508823\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34449868835508823\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010662348009645939\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010662348009645939\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10920920688658953\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10920920688658953\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4643737021833658\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4643737021833658\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5071621239185333\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5071621239185333\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 37, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:06 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:42:09 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:42:09 INFO\u001b[0m Weight update completed (now v38)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:11 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:11 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:11 INFO\u001b[0m Pushing weights for policy version 39\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:14 INFO\u001b[0m Completed weights push in 2.50 seconds\n",
      "Dropping weights @ version 38\n",
      "WandbBackend: Logged 96 metrics at global_step 39\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 39 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.097625966553819e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0008116178214550018\n",
      "  dataset/sample/avg_sample_len: 576.6666666666666\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.110630940755208\n",
      "  generator_perf/generate/generate/duration_max_s: 5.33285205078125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006514986753463746\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006842880249023438\n",
      "  generator_perf/generate/total_duration_avg_s: 4.111375804763287\n",
      "  generator_perf/generate/total_duration_max_s: 5.333579570807516\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.017042617003123e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.6338030844926834e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012152865529060364\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012466167099773884\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.116552532029648\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.3395947171375155\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07428009280314048\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07439242862164974\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006980322456608216\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007117275148630142\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.246074564134081\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.468769682571292\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.212837666273117e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.212837666273117e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5008081612177193\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5008081612177193\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.242329224012792\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.242329224012792\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4654843779280782\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4654843779280782\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.698685809969902e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.698685809969902e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.276013405993581\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.276013405993581\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001325689566632112\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001361318863928318\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013249045237898827\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013617516960948706\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033611726636687916\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003385157324373722\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.900316268205643e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.996521890163422e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013798869059731564\n",
      "  reference_perf/forward/total_duration_max_s: 0.014167771209031343\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.05833333333333334\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.20000000000000007\n",
      "  reward/evaluate_response/avg_total_reward: 0.12916666666666674\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.049300664859163484\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 1.4000000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.800000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.04916682839393616\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004500248469412327\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004500248469412327\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048737600445747375\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048737600445747375\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4989427980035543\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4989427980035543\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4980026744306087\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4980026744306087\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34348376700654626\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34348376700654626\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010553139727562666\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010553139727562666\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1085888110101223\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1085888110101223\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46262813080102205\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46262813080102205\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2148699411191046\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2148699411191046\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 38, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:15 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:15 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:16 INFO\u001b[0m Pushing weights for policy version 40\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:18 INFO\u001b[0m Completed weights push in 2.67 seconds\n",
      "[0] INFO 10-16 19:42:19 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 39[0] \u001b[34m[Generator-0/1] 2025-10-16 19:42:19 INFO\u001b[0m Weight update completed (now v39)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 40\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 40 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9230769230769231\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011279405309603765\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006868317723274231\n",
      "  dataset/sample/avg_sample_len: 645.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.96069970703125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.96069970703125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005875840187072754\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005875840187072754\n",
      "  generator_perf/generate/total_duration_avg_s: 1.961480795055628\n",
      "  generator_perf/generate/total_duration_max_s: 1.961480795055628\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.592305049300194e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.592305049300194e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011762403883039951\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011762403883039951\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9663859349675477\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9663859349675477\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0743894032202661\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0743894032202661\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0067712897434830666\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0067712897434830666\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.095321615226567\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.095321615226567\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.773959517478943e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.773959517478943e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.673290500883013\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.673290500883013\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.829789761919528\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.829789761919528\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4718185248784721\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4718185248784721\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4707733001559973\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4707733001559973\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2139007258228958\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2139007258228958\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014014123007655144\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014014123007655144\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013148387894034386\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013148387894034386\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033842679113149643\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033842679113149643\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.915729656815529e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.915729656815529e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013708028942346573\n",
      "  reference_perf/forward/total_duration_max_s: 0.013708028942346573\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.15000000000000005\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.0547083355486393\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00048139970749616623\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00048139970749616623\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048472732305526733\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048472732305526733\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.671148785855621\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.671148785855621\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.670179655775428\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.670179655775428\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3473029318265617\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3473029318265617\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01073561329394579\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01073561329394579\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11080187791958451\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11080187791958451\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46884325984865427\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46884325984865427\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.7634987221099436\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.7634987221099436\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 39, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:21 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:42:24 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:42:24 INFO\u001b[0m Weight update completed (now v40)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:27 INFO\u001b[0m Pushing weights for policy version 41\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:28 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:29 INFO\u001b[0m Completed weights push in 2.59 seconds\n",
      "Dropping weights @ version 40\n",
      "WandbBackend: Logged 96 metrics at global_step 41\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 41 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9817610062893082\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9635220125786164\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.440962111023632e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006024409085512161\n",
      "  dataset/sample/avg_sample_len: 627.6666666666666\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 504.5416666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12109.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.2133328857421875\n",
      "  generator_perf/generate/generate/duration_max_s: 5.57844873046875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007767360011736553\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0008980479836463929\n",
      "  generator_perf/generate/total_duration_avg_s: 4.214218976409485\n",
      "  generator_perf/generate/total_duration_max_s: 5.5793126024901865\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.1735824197530746e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.9235841035842896e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012759799137711525\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0014920663088560104\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.219401464331895\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.585043027065694\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07433371944352984\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07446939218789339\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007468055312832196\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007666027173399925\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.349365587656696\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.714908172376454\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.542060196399689e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.542060196399689e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5932764280587435\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5932764280587435\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.454070764128119\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.454070764128119\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46891706297174096\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46891706297174096\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.881783828139305e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.881783828139305e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.391851765103638\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.391851765103638\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013441499322652817\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001368960365653038\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012980982040365538\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01315215602517128\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003364395039776961\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003422945737838745\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.769465446472168e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.9405028373003e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013531479518860579\n",
      "  reference_perf/forward/total_duration_max_s: 0.01371273398399353\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.10833333333333334\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.43333333333333296\n",
      "  reward/evaluate_response/avg_total_reward: 0.2708333333333331\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.27220804951768457\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3636237371545243\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.6\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 10.399999999999991\n",
      "  rl_trainer/avg_grpo_loss: 0.054575640708208084\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004369858652353287\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004369858652353287\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004707071930170059\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004707071930170059\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.591212177183479\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.591212177183479\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5902992482297122\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5902992482297122\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34649440459907055\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34649440459907055\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01052073109894991\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01052073109894991\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10901581821963191\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10901581821963191\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4660335569642484\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4660335569642484\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.271648645401001\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.271648645401001\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 40, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:30 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:30 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:31 INFO\u001b[0m Pushing weights for policy version 42\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:33 INFO\u001b[0m Completed weights push in 2.46 seconds\n",
      "[0] INFO 10-16 19:42:34 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 41[0] \u001b[34m[Generator-0/1] 2025-10-16 19:42:34 INFO\u001b[0m Weight update completed (now v41)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 42\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 42 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011669821105897427\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006679189391434193\n",
      "  dataset/sample/avg_sample_len: 440.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 505.125\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4041.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.99355810546875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.99355810546875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005419520139694214\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005419520139694214\n",
      "  generator_perf/generate/total_duration_avg_s: 1.994281497478485\n",
      "  generator_perf/generate/total_duration_max_s: 1.994281497478485\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.129212513566017e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.129212513566017e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012027942575514317\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012027942575514317\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9994776449166238\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9994776449166238\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07452643290162086\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07452643290162086\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007186021190136671\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007186021190136671\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1282274830155075\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1282274830155075\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.475245416164398e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.475245416164398e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4630978531204164\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4630978531204164\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.496494619175792\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.496494619175792\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4705363940447569\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4705363940447569\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.44708279659971595\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.44708279659971595\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1157699930481613\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1157699930481613\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013559311628341675\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013559311628341675\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012868389021605253\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012868389021605253\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00032770587131381035\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00032770587131381035\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.714098319411278e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.714098319411278e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013411079999059439\n",
      "  reference_perf/forward/total_duration_max_s: 0.013411079999059439\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.21250000000000002\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.8\n",
      "  reward/evaluate_response/avg_total_reward: 0.50625\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.29764702249476643\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3464101615137753\n",
      "  reward/evaluate_response/sum_MathReward_reward: 1.7000000000000002\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 6.4\n",
      "  rl_trainer/avg_grpo_loss: 0.049327749758958817\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00048079434782266617\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00048079434782266617\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004787980578839779\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004787980578839779\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.461146794259548\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.461146794259548\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.460184022784233\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.460184022784233\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3471354888752103\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3471354888752103\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010489875916391611\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010489875916391611\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10997519921511412\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10997519921511412\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46760290302336216\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46760290302336216\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.555980675853789\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.555980675853789\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 41, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:36 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:42:39 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:42:39 INFO\u001b[0m Weight update completed (now v42)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:42 INFO\u001b[0m Pushing weights for policy version 43\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:44 INFO\u001b[0m Completed weights push in 2.65 seconds\n",
      "Dropping weights @ version 42\n",
      "WandbBackend: Logged 96 metrics at global_step 43\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 43 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9811320754716981\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.3852299429677625e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005702259950339794\n",
      "  dataset/sample/avg_sample_len: 511.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 509.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12216.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.164309651692708\n",
      "  generator_perf/generate/generate/duration_max_s: 5.397224609375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006225706736246744\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000713375985622406\n",
      "  generator_perf/generate/total_duration_avg_s: 4.165025513033072\n",
      "  generator_perf/generate/total_duration_max_s: 5.397989249359816\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.2609249552090965e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.483899101614952e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011847582645714283\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011995499953627586\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.170315192391475\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.403748136013746\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0748322056606412\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07525723706930876\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007546425020943086\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007683377712965012\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.302376910112798\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.534423020668328\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.201661795377731e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.201661795377731e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.6524579278193414\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.6524579278193414\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.498505869414657\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.498505869414657\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4687717901542783\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4687717901542783\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.1281186491250992e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.1281186491250992e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.377248761244118\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.377248761244118\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00015792002280553183\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001951023004949093\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.016471164611478645\n",
      "  reference_perf/forward/forward/duration_max_s: 0.02154028369113803\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0004175833115975062\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.000470748171210289\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.76416452229023e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.421305730938911e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01713667220125596\n",
      "  reference_perf/forward/total_duration_max_s: 0.022303594276309013\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.1375000000000001\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.4333333333333333\n",
      "  reward/evaluate_response/avg_total_reward: 0.2854166666666664\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.17984368212422694\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3636237371545239\n",
      "  reward/evaluate_response/sum_MathReward_reward: 3.300000000000002\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 10.399999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.042786501348018646\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004367041401565075\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004367041401565075\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00045539578422904015\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00045539578422904015\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.650864507071674\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.650864507071674\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.64996972726658\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.64996972726658\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3440779959782958\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3440779959782958\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01065937103703618\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01065937103703618\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11059968220070004\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11059968220070004\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4653397351503372\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4653397351503372\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2891582399606705\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2891582399606705\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 42, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:46 INFO\u001b[0m Pushing weights for policy version 44\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:48 INFO\u001b[0m Completed weights push in 2.51 seconds\n",
      "[0] INFO 10-16 19:42:49 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 43\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:42:49 INFO\u001b[0m Weight update completed (now v43)\n",
      "WandbBackend: Logged 96 metrics at global_step 44\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 44 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011264466835806768\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006381841376423836\n",
      "  dataset/sample/avg_sample_len: 729.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 2.0016279296875\n",
      "  generator_perf/generate/generate/duration_max_s: 2.0016279296875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006862720251083374\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006862720251083374\n",
      "  generator_perf/generate/total_duration_avg_s: 2.0025028737187385\n",
      "  generator_perf/generate/total_duration_max_s: 2.0025028737187385\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.504908040165901e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.504908040165901e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012751761823892593\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012751761823892593\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 2.007641459815204\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 2.007641459815204\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07451008819043636\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07451008819043636\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006851051934063435\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006851051934063435\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1370877609588206\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1370877609588206\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.963018000125885e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.963018000125885e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.510382462758571\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.510382462758571\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.603063221089542\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.603063221089542\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46793026430532336\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46793026430532336\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.511327673215419\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.511327673215419\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.113415353000164\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.113415353000164\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013811467215418816\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013811467215418816\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01296062720939517\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01296062720939517\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003332099877297878\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003332099877297878\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.719872519373894e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.719872519373894e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013511065859347582\n",
      "  reference_perf/forward/total_duration_max_s: 0.013511065859347582\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.05\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.125\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.05\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.4\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.047099657356739044\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005498160608112812\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005498160608112812\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004970147274434566\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004970147274434566\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.508097195997834\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.508097195997834\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5070475302636623\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5070475302636623\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34442097833380103\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34442097833380103\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010606730822473764\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010606730822473764\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10967152705416083\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10967152705416083\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46470257407054305\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46470257407054305\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.6346927150152624\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.6346927150152624\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 43, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:51 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:42:54 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:42:54 INFO\u001b[0m Weight update completed (now v44)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:57 INFO\u001b[0m Pushing weights for policy version 45\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:42:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:42:59 INFO\u001b[0m Completed weights push in 2.54 seconds\n",
      "Dropping weights @ version 44\n",
      "WandbBackend: Logged 96 metrics at global_step 45\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 45 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9854202401372213\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9708404802744426\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.639440690477689e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006215851753950119\n",
      "  dataset/sample/avg_sample_len: 553.6666666666666\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 493.4166666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11842.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.202408325195313\n",
      "  generator_perf/generate/generate/duration_max_s: 5.54920703125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007514240145683289\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000854848027229309\n",
      "  generator_perf/generate/total_duration_avg_s: 4.203278085211913\n",
      "  generator_perf/generate/total_duration_max_s: 5.550181367278099\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.926921635866165e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.836784839630127e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011926319760580857\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012208549305796623\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.208473560400307\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.555882234126329\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07432914276917775\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07465032720938325\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007184951566159725\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007321999873965979\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.337820707044254\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.685440990142524\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 3.8067810237407684e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 3.8067810237407684e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.545129792764783\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.545129792764783\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.498926233965904\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.498926233965904\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4687500409781933\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4687500409781933\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.538824290037155e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.538824290037155e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.485024830326438\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.485024830326438\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013870062927405039\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014619668945670128\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013528991645822922\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01431318512186408\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033978714297215146\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003444841131567955\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.959843302766482e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.07163305580616e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.014089368283748627\n",
      "  reference_perf/forward/total_duration_max_s: 0.01486098999157548\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.29583333333333334\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5\n",
      "  reward/evaluate_response/avg_total_reward: 0.3979166666666667\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.45228969944298114\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207418\n",
      "  reward/evaluate_response/sum_MathReward_reward: 7.1\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 12.0\n",
      "  rl_trainer/avg_grpo_loss: 0.025608733296394348\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004183966666460037\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004183966666460037\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00046445801854133606\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00046445801854133606\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.54340456193313\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.54340456193313\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5425190231762826\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5425190231762826\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3449786030687392\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3449786030687392\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010721920989453793\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010721920989453793\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11037209490314126\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11037209490314126\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46607456682249904\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46607456682249904\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2657341677695513\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2657341677695513\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 44, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:00 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:00 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:01 INFO\u001b[0m Pushing weights for policy version 46\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:03 INFO\u001b[0m Completed weights push in 2.51 seconds\n",
      "[0] INFO 10-16 19:43:04 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:43:04 INFO\u001b[0m Weight update completed (now v45)\n",
      "Dropping weights @ version 45\n",
      "WandbBackend: Logged 96 metrics at global_step 46\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 46 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.875\n",
      "  buffer/sample/count_sample_requests: 8.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.0001501995138823986\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007111448794603348\n",
      "  dataset/sample/avg_sample_len: 430.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 370.625\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 2965.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.553515869140625\n",
      "  generator_perf/generate/generate/duration_max_s: 1.553515869140625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005650240182876587\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005650240182876587\n",
      "  generator_perf/generate/total_duration_avg_s: 1.554266429156065\n",
      "  generator_perf/generate/total_duration_max_s: 1.554266429156065\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.590814933180809e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.590814933180809e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001329217106103897\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001329217106103897\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.5597219136543572\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.5597219136543572\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07439869083464146\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07439869083464146\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006685119122266769\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006685119122266769\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 1.6891257809475064\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 1.6891257809475064\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.12879341840744e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.12879341840744e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5132939480245113\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5132939480245113\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.130268464796245\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.130268464796245\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4643915263004601\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4643915263004601\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.44223433593288064\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.44223433593288064\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 0.7103412477299571\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 0.7103412477299571\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014233682304620743\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014233682304620743\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012922405265271664\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012922405265271664\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033499812707304955\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033499812707304955\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.594376802444458e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.594376802444458e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013478130102157593\n",
      "  reference_perf/forward/total_duration_max_s: 0.013478130102157593\n",
      "  reward/evaluate_response/avg_MathReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 1.0\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.05078551545739174\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004890961572527885\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004890961572527885\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00046240026131272316\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00046240026131272316\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5110603072680533\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5110603072680533\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5101055786944926\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5101055786944926\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3408239227719605\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3408239227719605\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010600010864436626\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010600010864436626\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11010540137067437\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11010540137067437\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4615317350253463\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4615317350253463\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.581849389243871\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.581849389243871\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 45, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:06 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:43:09 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:43:09 INFO\u001b[0m Weight update completed (now v46)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:11 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:11 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:11 INFO\u001b[0m Pushing weights for policy version 47\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:14 INFO\u001b[0m Completed weights push in 2.49 seconds\n",
      "Dropping weights @ version 46\n",
      "WandbBackend: Logged 96 metrics at global_step 47\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 47 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9884696016771488\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9769392033542976\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.890396297783465e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006290236487984657\n",
      "  dataset/sample/avg_sample_len: 471.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 503.8333333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12092.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.160176228841146\n",
      "  generator_perf/generate/generate/duration_max_s: 5.43215283203125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005829866727193197\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005917440056800842\n",
      "  generator_perf/generate/total_duration_avg_s: 4.160851780847957\n",
      "  generator_perf/generate/total_duration_max_s: 5.432791776038706\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.664754331111908e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.568789154291153e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011998343591888745\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012376420199871063\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.1658071731217206\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.437803625129163\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07422135102873047\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07428841199725866\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007788532879203558\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.008368028793483973\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.298477305565029\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.567233109846711\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.631001502275467e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.631001502275467e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.488099044188857\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.488099044188857\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.340795380994678\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.340795380994678\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4661233089864254\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4661233089864254\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.194475382566452e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.194475382566452e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.386544323991984\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.386544323991984\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001327314724524816\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013676565140485764\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013175087670485178\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013735247775912285\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033606526752312976\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003408920019865036\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.738607625166576e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.861899212002754e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013723266310989857\n",
      "  reference_perf/forward/total_duration_max_s: 0.014283508993685246\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.22499999999999998\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5999999999999996\n",
      "  reward/evaluate_response/avg_total_reward: 0.4124999999999998\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3992179855667828\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.39999999999999997\n",
      "  reward/evaluate_response/sum_MathReward_reward: 5.3999999999999995\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 14.399999999999991\n",
      "  rl_trainer/avg_grpo_loss: 0.06004679575562477\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005172011442482471\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005172011442482471\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004648109897971153\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004648109897971153\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4862766503356397\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4862766503356397\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.485290224198252\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.485290224198252\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3428465430624783\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3428465430624783\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010554980020970106\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010554980020970106\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10998016223311424\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10998016223311424\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4633840932510793\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4633840932510793\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2563309064134955\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2563309064134955\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 46, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:15 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:15 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:16 INFO\u001b[0m Pushing weights for policy version 48\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:18 INFO\u001b[0m Completed weights push in 2.47 seconds\n",
      "[0] INFO 10-16 19:43:18 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:43:18 INFO\u001b[0m Weight update completed (now v47)\n",
      "Dropping weights @ version 47\n",
      "WandbBackend: Logged 96 metrics at global_step 48\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 48 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9230769230769231\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010294116173799221\n",
      "  buffer_perf/sample/total_duration_max_s: 0.000623106025159359\n",
      "  dataset/sample/avg_sample_len: 431.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.97527392578125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.97527392578125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006796159744262695\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006796159744262695\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9761425977498293\n",
      "  generator_perf/generate/total_duration_max_s: 1.9761425977498293\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.3054653108119965e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.3054653108119965e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011409330181777477\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011409330181777477\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9812931241467595\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9812931241467595\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07432578224688768\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07432578224688768\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007084305863827467\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007084305863827467\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.110430136322975\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.110430136322975\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.186069756746292e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.186069756746292e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4719469058327377\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4719469058327377\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.61243304098025\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.61243304098025\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4696782580576837\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4696782580576837\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4526375140994787\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4526375140994787\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2181630530394614\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2181630530394614\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013779476284980774\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013779476284980774\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012883018236607313\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012883018236607313\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003293459303677082\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003293459303677082\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.492769509553909e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.492769509553909e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013427876867353916\n",
      "  reference_perf/forward/total_duration_max_s: 0.013427876867353916\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.30000000000000004\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207416\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.000000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.04010419920086861\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005323891527950764\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005323891527950764\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0005050948821008205\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0005050948821008205\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4697745642624795\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4697745642624795\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.468733826186508\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.468733826186508\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3457990251481533\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3457990251481533\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010665753856301308\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010665753856301308\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10999555280432105\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10999555280432105\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4664636538363993\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4664636538363993\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5465713338926435\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5465713338926435\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 47, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:20 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:43:24 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:43:24 INFO\u001b[0m Weight update completed (now v48)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:26 INFO\u001b[0m Pushing weights for policy version 49\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:28 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:29 INFO\u001b[0m Completed weights push in 2.44 seconds\n",
      "Dropping weights @ version 48\n",
      "WandbBackend: Logged 96 metrics at global_step 49\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 49 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9824797843665768\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9649595687331536\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.0246036564176144e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007492918521165848\n",
      "  dataset/sample/avg_sample_len: 445.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 477.2083333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11453.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.154680257161458\n",
      "  generator_perf/generate/generate/duration_max_s: 5.3713173828125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005998079975446065\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006632959842681885\n",
      "  generator_perf/generate/total_duration_avg_s: 4.155393270491312\n",
      "  generator_perf/generate/total_duration_max_s: 5.371985670838505\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.4333051492770515e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.4547952711582184e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012329206801950932\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012800740078091621\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.160351415164769\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.377074231859297\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07416332435483734\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07431450299918652\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007412037036071221\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00787045992910862\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.290344989858568\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.507543997839093\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.408881068229675e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.408881068229675e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4400549731217325\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4400549731217325\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.295242412015796\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.295242412015796\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.47122986195608974\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.47122986195608974\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.2632069885730743e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.2632069885730743e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.383928289171308\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.383928289171308\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001374306157231331\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014179572463035583\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.015330516888449589\n",
      "  reference_perf/forward/forward/duration_max_s: 0.018835837952792645\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034073522935311\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034994399175047874\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.41757282614708e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 0.00010018516331911087\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01589492584268252\n",
      "  reference_perf/forward/total_duration_max_s: 0.01940648863092065\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.4375\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.9333333333333332\n",
      "  reward/evaluate_response/avg_total_reward: 0.6854166666666667\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4357106264483343\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.22110831935702688\n",
      "  reward/evaluate_response/sum_MathReward_reward: 10.5\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 22.4\n",
      "  rl_trainer/avg_grpo_loss: 3.4745099544525146\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004327208735048771\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004327208735048771\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004889722913503647\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004889722913503647\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4382804399356246\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4382804399356246\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.437355893664062\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.437355893664062\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.349071079865098\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.349071079865098\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.0105690429918468\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.0105690429918468\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10861462587490678\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10861462587490678\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4682568935677409\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4682568935677409\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.252168796956539\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.252168796956539\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 48, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:30 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:30 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:31 INFO\u001b[0m Pushing weights for policy version 50\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:33 INFO\u001b[0m Completed weights push in 2.39 seconds\n",
      "[0] INFO 10-16 19:43:34 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 49[0] \u001b[34m[Generator-0/1] 2025-10-16 19:43:34 INFO\u001b[0m Weight update completed (now v49)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 50\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 50 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8711111111111112\n",
      "  buffer/sample/count_sample_requests: 15.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011752707262833914\n",
      "  buffer_perf/sample/total_duration_max_s: 0.000755571760237217\n",
      "  dataset/sample/avg_sample_len: 551.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 502.25\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4018.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 2.04999755859375\n",
      "  generator_perf/generate/generate/duration_max_s: 2.04999755859375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005221440196037292\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005221440196037292\n",
      "  generator_perf/generate/total_duration_avg_s: 2.0507624866068364\n",
      "  generator_perf/generate/total_duration_max_s: 2.0507624866068364\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.516728222370148e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.516728222370148e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0013063931837677956\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013063931837677956\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 2.056664417963475\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 2.056664417963475\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07453033467754722\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07453033467754722\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007785656023770571\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007785656023770571\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1875398722477257\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1875398722477257\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.662906914949417e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.662906914949417e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.3900254890322685\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.3900254890322685\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.7883679321967065\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.7883679321967065\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4675941509194672\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4675941509194672\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5071968152187765\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5071968152187765\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.4235434420406818\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.4235434420406818\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014331098645925522\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014331098645925522\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012885165866464376\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012885165866464376\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003262711688876152\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003262711688876152\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.599592208862305e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.599592208862305e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013432645238935947\n",
      "  reference_perf/forward/total_duration_max_s: 0.013432645238935947\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.32500000000000007\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.7000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.5125\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3897114317029974\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207416\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.6000000000000005\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 5.6000000000000005\n",
      "  rl_trainer/avg_grpo_loss: 0.048900216817855835\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00047587882727384567\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00047587882727384567\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004727761261165142\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004727761261165142\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.3877790486440063\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.3877790486440063\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.386827176902443\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.386827176902443\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3446370717138052\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3446370717138052\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010475159157067537\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010475159157067537\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10890787793323398\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10890787793323398\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4640228799544275\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4640228799544275\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5931419571861625\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5931419571861625\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 49, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:36 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:43:39 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:43:39 INFO\u001b[0m Weight update completed (now v50)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:42 INFO\u001b[0m Pushing weights for policy version 51\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:44 INFO\u001b[0m Completed weights push in 2.44 seconds\n",
      "Dropping weights @ version 50\n",
      "WandbBackend: Logged 96 metrics at global_step 51\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 51 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9824797843665768\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9649595687331536\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.211245432496071e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005779541097581387\n",
      "  dataset/sample/avg_sample_len: 591.3333333333334\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.188687825520834\n",
      "  generator_perf/generate/generate/duration_max_s: 5.51081689453125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007529386679331462\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0008111360073089599\n",
      "  generator_perf/generate/total_duration_avg_s: 4.189556689520677\n",
      "  generator_perf/generate/total_duration_max_s: 5.511709150545299\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.5332515835762024e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.715798422694206e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001152389372388522\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011903699487447739\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.194399745358775\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.516571330837905\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07441845334445436\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07462360290810466\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007168973019967477\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00740811275318265\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.324283462638657\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.64499046979472\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.3888576328754425e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.3888576328754425e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4422638188116252\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4422638188116252\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.396202703937888\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.396202703937888\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4676826689392328\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4676826689392328\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.7163343727588654e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.7163343727588654e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.486232582945377\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.486232582945377\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014241008708874384\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00015925895422697067\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013311249669641256\n",
      "  reference_perf/forward/forward/duration_max_s: 0.014249986037611961\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00036821654066443443\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0004387078806757927\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.169375360012054e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.088870137929916e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013905601731191078\n",
      "  reference_perf/forward/total_duration_max_s: 0.014940875582396984\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09166666666666669\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.23333333333333348\n",
      "  reward/evaluate_response/avg_total_reward: 0.1625\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.02763853991962836\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.15986105077709054\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.2000000000000006\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 5.600000000000003\n",
      "  rl_trainer/avg_grpo_loss: 0.7329907417297363\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004190029576420784\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004190029576420784\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004864931106567383\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004864931106567383\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.440436060074717\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.440436060074717\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4395277271978557\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4395277271978557\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34401516197249293\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34401516197249293\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010561298113316298\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010561298113316298\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10990432370454073\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10990432370454073\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46448279405012727\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46448279405012727\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2504856386221945\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2504856386221945\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 50, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:46 INFO\u001b[0m Pushing weights for policy version 52\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:48 INFO\u001b[0m Completed weights push in 2.49 seconds\n",
      "[0] INFO 10-16 19:43:49 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:43:49 INFO\u001b[0m Weight update completed (now v51)\n",
      "Dropping weights @ version 51\n",
      "WandbBackend: Logged 96 metrics at global_step 52\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 52 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9230769230769231\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00013340117696386116\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007184157148003578\n",
      "  dataset/sample/avg_sample_len: 495.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9667957763671875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9667957763671875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007142720222473144\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007142720222473144\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9676920643895865\n",
      "  generator_perf/generate/total_duration_max_s: 1.9676920643895865\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.767114296555519e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.767114296555519e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012281970120966434\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012281970120966434\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.973333841189742\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.973333841189742\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07449872698634863\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07449872698634863\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006896692793816328\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006896692793816328\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.102674919180572\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.102674919180572\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.201902240514755e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.201902240514755e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4931946671567857\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4931946671567857\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.711140044033527\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.711140044033527\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46918504359200597\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46918504359200597\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5309469201602042\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5309469201602042\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.217805856373161\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.217805856373161\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013928581029176712\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013928581029176712\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012861763127148151\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012861763127148151\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033197179436683655\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033197179436683655\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.724296301603317e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.724296301603317e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013412466738373041\n",
      "  reference_perf/forward/total_duration_max_s: 0.013412466738373041\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.03567441925406456\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004781549796462059\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004781549796462059\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.000471324659883976\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.000471324659883976\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4911466548219323\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4911466548219323\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.490192755125463\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.490192755125463\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34590211883187294\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34590211883187294\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010668165050446987\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010668165050446987\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10972065525129437\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10972065525129437\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4662937060929835\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4662937060929835\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.642128671053797\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.642128671053797\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 51, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:51 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:43:54 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:43:54 INFO\u001b[0m Weight update completed (now v52)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:57 INFO\u001b[0m Pushing weights for policy version 53\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:43:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:43:59 INFO\u001b[0m Completed weights push in 2.44 seconds\n",
      "Dropping weights @ version 52\n",
      "WandbBackend: Logged 96 metrics at global_step 53\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 53 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9854202401372213\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9708404802744426\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.124676784148087e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005596177652478218\n",
      "  dataset/sample/avg_sample_len: 608.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.1747067871093755\n",
      "  generator_perf/generate/generate/duration_max_s: 5.46889453125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006578133304913839\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007474880218505859\n",
      "  generator_perf/generate/total_duration_avg_s: 4.175455299106738\n",
      "  generator_perf/generate/total_duration_max_s: 5.469521859228611\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.0674971640110016e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.354584962129593e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012341202236711979\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012965206988155842\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.180638294822226\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.475350492168218\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07426516556491454\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07435615779832006\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006932935677468777\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0071472711861133575\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.309246856408815\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.6048094388097525\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.305969923734665e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.305969923734665e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.442446568980813\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.442446568980813\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.295374677050859\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.295374677050859\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4688352760858834\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4688352760858834\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.5344005078077316e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.5344005078077316e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.384071278851479\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.384071278851479\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013291727130611738\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013553304597735405\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012804342899471521\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012856286019086838\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033188875143726665\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003340919502079487\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.818810020883878e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.990002632141113e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013349317479878664\n",
      "  reference_perf/forward/total_duration_max_s: 0.013404901139438152\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.05833333333333334\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.20000000000000007\n",
      "  reward/evaluate_response/avg_total_reward: 0.12916666666666668\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.049300664859163484\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 1.4000000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.800000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.04406358674168587\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005343747325241566\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005343747325241566\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048794830217957497\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048794830217957497\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4404758368618786\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4404758368618786\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4394504809752107\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4394504809752107\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3453320600092411\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3453320600092411\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010626524686813354\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010626524686813354\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1099929129704833\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1099929129704833\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46595378080382943\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46595378080382943\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2603283589705825\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2603283589705825\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 52, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:00 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:00 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:01 INFO\u001b[0m Pushing weights for policy version 54\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:03 INFO\u001b[0m Completed weights push in 2.40 seconds\n",
      "[0] INFO 10-16 19:44:04 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:44:04 INFO\u001b[0m Weight update completed (now v53)\n",
      "Dropping weights @ version 53\n",
      "WandbBackend: Logged 96 metrics at global_step 54\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 54 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9230769230769231\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010259911561241516\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006533539853990078\n",
      "  dataset/sample/avg_sample_len: 469.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.969138671875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.969138671875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006530560255050659\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006530560255050659\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9699739038944244\n",
      "  generator_perf/generate/total_duration_max_s: 1.9699739038944244\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.764227196574211e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.764227196574211e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001200506929308176\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001200506929308176\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9751101429574192\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9751101429574192\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0745651088654995\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0745651088654995\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006945088971406221\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006945088971406221\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1043192809447646\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1043192809447646\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.203764885663986e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.203764885663986e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4032349810004234\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4032349810004234\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.627596985083073\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.627596985083073\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4687945069745183\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4687945069745183\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5405580080114305\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5405580080114305\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2150020664557815\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2150020664557815\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013837730512022972\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013837730512022972\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012818348594009876\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012818348594009876\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003467588685452938\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003467588685452938\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.717730477452278e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.717730477452278e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013383259065449238\n",
      "  reference_perf/forward/total_duration_max_s: 0.013383259065449238\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.025\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.1125\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.04330127018922194\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.2\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.03643161058425903\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004923040978610516\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004923040978610516\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004737270064651966\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004737270064651966\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4013419672846794\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4013419672846794\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4003733112476766\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4003733112476766\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34539423091337085\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34539423091337085\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010490634944289923\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010490634944289923\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10974804172292352\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10974804172292352\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46563576394692063\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46563576394692063\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5509482230991125\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5509482230991125\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 53, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:06 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:44:09 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:44:09 INFO\u001b[0m Weight update completed (now v54)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:11 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:11 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:11 INFO\u001b[0m Pushing weights for policy version 55\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:14 INFO\u001b[0m Completed weights push in 2.45 seconds\n",
      "Dropping weights @ version 54\n",
      "WandbBackend: Logged 96 metrics at global_step 55\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 55 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.56144119390886e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006125504150986671\n",
      "  dataset/sample/avg_sample_len: 530.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 499.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11976.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.127169108072916\n",
      "  generator_perf/generate/generate/duration_max_s: 5.358908203125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000609557330608368\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006934080123901367\n",
      "  generator_perf/generate/total_duration_avg_s: 4.127875668069969\n",
      "  generator_perf/generate/total_duration_max_s: 5.359651947136968\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.616775696476301e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.5631080865859985e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001244438501695792\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012680497020483017\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.132979746131848\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.365134495776147\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07425726888080438\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07444320479407907\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007421655580401421\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007715508341789246\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.262834158260375\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.496085717808455\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.591885954141617e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.591885954141617e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4521179981529713\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4521179981529713\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.194251371081918\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.194251371081918\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46369343623518944\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46369343623518944\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.74008309841156e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.74008309841156e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.278415561653674\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.278415561653674\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013239666198690733\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001349220983684063\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01286323725556334\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012929686810821295\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033215216050545376\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033339159563183784\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.737458993991216e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.768720388412476e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013407254746804634\n",
      "  reference_perf/forward/total_duration_max_s: 0.013477373868227005\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.24999999999999992\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.49999999999999956\n",
      "  reward/evaluate_response/avg_total_reward: 0.37499999999999983\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.38729833462074165\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207416\n",
      "  reward/evaluate_response/sum_MathReward_reward: 5.999999999999998\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 11.99999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.05096232518553734\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004290519282221794\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004290519282221794\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004727579653263092\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004727579653263092\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4501104447990656\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4501104447990656\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.449205534067005\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.449205534067005\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34177248319610953\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34177248319610953\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010668051894754171\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010668051894754171\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10847230069339275\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10847230069339275\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46091555897146463\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46091555897146463\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2403930192813277\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2403930192813277\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 54, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:15 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:15 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:15 INFO\u001b[0m Pushing weights for policy version 56\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:18 INFO\u001b[0m Completed weights push in 2.42 seconds\n",
      "[0] INFO 10-16 19:44:18 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:44:18 INFO\u001b[0m Weight update completed (now v55)\n",
      "Dropping weights @ version 55\n",
      "WandbBackend: Logged 96 metrics at global_step 56\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 56 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9\n",
      "  buffer/sample/count_sample_requests: 10.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00012715714983642102\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006671976298093796\n",
      "  dataset/sample/avg_sample_len: 472.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 303.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 2424.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.6162373046875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.6162373046875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006203520298004151\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006203520298004151\n",
      "  generator_perf/generate/total_duration_avg_s: 1.617039448723197\n",
      "  generator_perf/generate/total_duration_max_s: 1.617039448723197\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.0137750804424286e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.0137750804424286e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012504970654845238\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012504970654845238\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.6224665236659348\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.6224665236659348\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0743951122276485\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0743951122276485\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.00760352797806263\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00760352797806263\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 1.7529741111211479\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 1.7529741111211479\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.003996193408966e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.003996193408966e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.424394164700061\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.424394164700061\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.305616862140596\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.305616862140596\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46398314321413636\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46398314321413636\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5032405853271484\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5032405853271484\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 0.9139919308945537\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 0.9139919308945537\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001359023153781891\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001359023153781891\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012772456742823124\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012772456742823124\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033103907480835915\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033103907480835915\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.847417145967484e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.847417145967484e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013319644145667553\n",
      "  reference_perf/forward/total_duration_max_s: 0.013319644145667553\n",
      "  reward/evaluate_response/avg_MathReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 1.0\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.06877453625202179\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004893220029771328\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004893220029771328\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004695812240242958\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004695812240242958\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.42239045817405\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.42239045817405\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4214286897331476\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4214286897331476\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3420431511476636\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3420431511476636\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010368580929934978\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010368580929934978\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10787541279569268\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10787541279569268\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4602894480340183\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4602894480340183\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5313041917979717\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5313041917979717\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 55, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:20 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:44:23 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:44:23 INFO\u001b[0m Weight update completed (now v56)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:25 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:26 INFO\u001b[0m Pushing weights for policy version 57\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:27 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:29 INFO\u001b[0m Completed weights push in 3.09 seconds\n",
      "Dropping weights @ version 56\n",
      "WandbBackend: Logged 96 metrics at global_step 57\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 57 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9817610062893082\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9635220125786164\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.269951086390663e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005781189538538456\n",
      "  dataset/sample/avg_sample_len: 441.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 508.5\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12204.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.130761678059896\n",
      "  generator_perf/generate/generate/duration_max_s: 5.36327197265625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005674453179041545\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000609503984451294\n",
      "  generator_perf/generate/total_duration_avg_s: 4.1314240247085685\n",
      "  generator_perf/generate/total_duration_max_s: 5.363899428647011\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.9364987363417946e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.5538956075906754e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012216855150957902\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012449929490685463\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.136749877904852\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.36969101568684\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07428840594366193\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07440669788047671\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0074984740155438585\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00822887010872364\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.267033720544229\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.498767707962543\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.686880856752396e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.686880856752396e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 3.088354446925223\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 3.088354446925223\n",
      "  main_perf/continuous_training/total_duration_avg_s: 11.01114574028179\n",
      "  main_perf/continuous_training/total_duration_max_s: 11.01114574028179\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4644918870180845\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4644918870180845\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.564016565680504e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.564016565680504e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.458277367055416\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.458277367055416\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013265727708737055\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013750791549682617\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012862978813548883\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012888291385024786\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003324986125032107\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033619673922657967\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.452055191000302e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.602712139487267e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01340477354824543\n",
      "  reference_perf/forward/total_duration_max_s: 0.013430801685899496\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.1708333333333333\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.49999999999999983\n",
      "  reward/evaluate_response/avg_total_reward: 0.3354166666666665\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.25079733961020295\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207416\n",
      "  reward/evaluate_response/sum_MathReward_reward: 4.1\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 11.999999999999996\n",
      "  rl_trainer/avg_grpo_loss: 0.08154816925525665\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00042867008596658707\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00042867008596658707\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00045743491500616074\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00045743491500616074\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 3.0864607067778707\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 3.0864607067778707\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 3.0855717631056905\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 3.0855717631056905\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34219844825565815\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34219844825565815\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010370336938649416\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010370336938649416\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10856300592422485\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10856300592422485\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46113392198458314\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46113392198458314\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2471081828698516\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2471081828698516\n",
      "==============================\n",
      "\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:30 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "Dropped weights @ version 56, took 0.45 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:30 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:30 INFO\u001b[0m Pushing weights for policy version 58\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:33 INFO\u001b[0m Completed weights push in 2.50 seconds\n",
      "[0] INFO 10-16 19:44:33 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 57\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:44:33 INFO\u001b[0m Weight update completed (now v57)\n",
      "WandbBackend: Logged 96 metrics at global_step 58\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 58 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8333333333333333\n",
      "  buffer/sample/count_sample_requests: 6.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00020294799469411373\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007157051004469395\n",
      "  dataset/sample/avg_sample_len: 493.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 489.625\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3917.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9768929443359375\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9768929443359375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006788480281829834\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006788480281829834\n",
      "  generator_perf/generate/total_duration_avg_s: 1.977827856361866\n",
      "  generator_perf/generate/total_duration_max_s: 1.977827856361866\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.1930081099271774e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.1930081099271774e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012228330597281456\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012228330597281456\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9846355952322483\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9846355952322483\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07440825086086988\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07440825086086988\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.010453493800014257\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.010453493800014257\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1174103510566056\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1174103510566056\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.139969289302826e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.139969289302826e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5068806051276624\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5068806051276624\n",
      "  main_perf/continuous_training/total_duration_avg_s: 3.893787288106978\n",
      "  main_perf/continuous_training/total_duration_max_s: 3.893787288106978\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46467567328363657\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46467567328363657\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4130688928999007\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4130688928999007\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 0.5091545428149402\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 0.5091545428149402\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013706600293517113\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013706600293517113\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012933745048940182\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012933745048940182\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00032657012343406677\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00032657012343406677\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.44527205824852e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.44527205824852e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013474114704877138\n",
      "  reference_perf/forward/total_duration_max_s: 0.013474114704877138\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.32500000000000007\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.7000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.5125\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3897114317029973\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207416\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.6000000000000005\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 5.6000000000000005\n",
      "  rl_trainer/avg_grpo_loss: 0.03235486149787903\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004718657582998276\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004718657582998276\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004936209879815578\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004936209879815578\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5044325315393507\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5044325315393507\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.50346413301304\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.50346413301304\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3422040631994605\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3422040631994605\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01041236286982894\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01041236286982894\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10897278133779764\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10897278133779764\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4615914053283632\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4615914053283632\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5410188580863178\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5410188580863178\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 57, took 0.46 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:35 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:44:38 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:44:38 INFO\u001b[0m Weight update completed (now v58)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:40 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:40 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:41 INFO\u001b[0m Pushing weights for policy version 59\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:42 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:44 INFO\u001b[0m Completed weights push in 2.56 seconds\n",
      "Dropping weights @ version 58\n",
      "WandbBackend: Logged 96 metrics at global_step 59\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 59 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9842767295597484\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9685534591194969\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.04960079450865e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005829497240483761\n",
      "  dataset/sample/avg_sample_len: 490.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 502.4166666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12058.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.133266886393229\n",
      "  generator_perf/generate/generate/duration_max_s: 5.36826513671875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006767573157946269\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007448959946632386\n",
      "  generator_perf/generate/total_duration_avg_s: 4.134049051710715\n",
      "  generator_perf/generate/total_duration_max_s: 5.369098352715373\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.646872937679291e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.839291796088219e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001149988267570734\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011998452246189117\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.139382972226788\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.374826163053513\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0744843917588393\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0747441602870822\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007417292799800634\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007617066614329815\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.270078526654591\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.504718516021967\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.922039806842804e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.922039806842804e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.558385082986206\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.558385082986206\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.401632259134203\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.401632259134203\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4655962339602411\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4655962339602411\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 3.178790211677551e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 3.178790211677551e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.377612186130136\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.377612186130136\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001378939487040043\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014842068776488304\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012880220077931881\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013011051341891289\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003691230279703935\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00043469294905662537\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.127465844154358e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.114900603890419e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01347060656795899\n",
      "  reference_perf/forward/total_duration_max_s: 0.013687422033399343\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.1666666666666667\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.46666666666666634\n",
      "  reward/evaluate_response/avg_total_reward: 0.31666666666666643\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.31841621957571326\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.37712361663282534\n",
      "  reward/evaluate_response/sum_MathReward_reward: 4.000000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 11.199999999999992\n",
      "  rl_trainer/avg_grpo_loss: 0.05607976019382477\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004271669313311577\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004271669313311577\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004830569960176945\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004830569960176945\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5562484660185874\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5562484660185874\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.55533376801759\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.55533376801759\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34215397108346224\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34215397108346224\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010509449057281017\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010509449057281017\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11022192100062966\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11022192100062966\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4628880280070007\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4628880280070007\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.252416456118226\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.252416456118226\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 58, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:44 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:45 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:45 INFO\u001b[0m Pushing weights for policy version 60\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:48 INFO\u001b[0m Completed weights push in 2.56 seconds\n",
      "[0] INFO 10-16 19:44:48 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 59[0] \u001b[34m[Generator-0/1] 2025-10-16 19:44:48 INFO\u001b[0m Weight update completed (now v59)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 60\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 60 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00012859566292415062\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006772470660507679\n",
      "  dataset/sample/avg_sample_len: 535.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 496.625\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3973.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.955164306640625\n",
      "  generator_perf/generate/generate/duration_max_s: 1.955164306640625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005914559960365296\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005914559960365296\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9559326586425305\n",
      "  generator_perf/generate/total_duration_max_s: 1.9559326586425305\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.6182889491319656e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.6182889491319656e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.003495032899081707\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.003495032899081707\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.96098522702232\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.96098522702232\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0742036011070013\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0742036011070013\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007075786124914885\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007075786124914885\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.094973726198077\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.094973726198077\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.7460198402404785e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.7460198402404785e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5627045407891273\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5627045407891273\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.399581779260188\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.399581779260188\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.47294545406475663\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.47294545406475663\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.24915598100051284\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.24915598100051284\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1147689772769809\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1147689772769809\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013775238767266273\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013775238767266273\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012929558753967285\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012929558753967285\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034183869138360023\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034183869138360023\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.853424176573753e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.853424176573753e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.0134897087700665\n",
      "  reference_perf/forward/total_duration_max_s: 0.0134897087700665\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.32500000000000007\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.8\n",
      "  reward/evaluate_response/avg_total_reward: 0.5625\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3897114317029974\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3464101615137753\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.6000000000000005\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 6.4\n",
      "  rl_trainer/avg_grpo_loss: 0.05131644755601883\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005318019539117813\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005318019539117813\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048705097287893295\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048705097287893295\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.560670331120491\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.560670331120491\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.559648270253092\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.559648270253092\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34990075463429093\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34990075463429093\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010423070285469294\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010423070285469294\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10908019682392478\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10908019682392478\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4694062969647348\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4694062969647348\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.452704248018563\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.452704248018563\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 59, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:50 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:44:53 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:44:53 INFO\u001b[0m Weight update completed (now v60)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:55 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:55 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:56 INFO\u001b[0m Pushing weights for policy version 61\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:57 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:58 INFO\u001b[0m Completed weights push in 2.42 seconds\n",
      "Dropping weights @ version 60\n",
      "WandbBackend: Logged 96 metrics at global_step 61\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 61 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9903846153846154\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9807692307692308\n",
      "  buffer/sample/count_sample_requests: 73.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.52739625066927e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005552456714212894\n",
      "  dataset/sample/avg_sample_len: 435.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.092199666341146\n",
      "  generator_perf/generate/generate/duration_max_s: 5.27168603515625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006623679995536805\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007078400254249572\n",
      "  generator_perf/generate/total_duration_avg_s: 4.092955783672631\n",
      "  generator_perf/generate/total_duration_max_s: 5.272436435181648\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.270587573448817e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.699220880866051e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012448611669242382\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001299101859331131\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.097755312143515\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.277444007340819\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07410368090495467\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07426133984699845\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007574893689403932\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.008672920055687428\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.227223782179256\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.407376038841903\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.619825631380081e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.619825631380081e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.422051045112312\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.422051045112312\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.168444653972983\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.168444653972983\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4687798391096294\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4687798391096294\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.8781982362270355e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.8781982362270355e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.27758821984753\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.27758821984753\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013482989743351936\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013875681906938553\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012963586331655582\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013297910336405039\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033556406075755757\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003436100669205189\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.689325138926506e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.848674431443214e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013512917794287205\n",
      "  reference_perf/forward/total_duration_max_s: 0.013855683151632547\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09166666666666669\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.3999999999999999\n",
      "  reward/evaluate_response/avg_total_reward: 0.24583333333333324\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.02763853991962836\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3464101615137756\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.2000000000000006\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 9.599999999999998\n",
      "  rl_trainer/avg_grpo_loss: 0.038962751626968384\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00041381223127245903\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00041381223127245903\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004715300165116787\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004715300165116787\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4203102802857757\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4203102802857757\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4194217757321894\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4194217757321894\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3456690963357687\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3456690963357687\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010628529824316502\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010628529824316502\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10980866104364395\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10980866104364395\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46610833099111915\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46610833099111915\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.223043820820749\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.223043820820749\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 60, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:44:59 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:44:59 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:00 INFO\u001b[0m Pushing weights for policy version 62\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:02 INFO\u001b[0m Completed weights push in 2.45 seconds\n",
      "[0] INFO 10-16 19:45:03 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:45:03 INFO\u001b[0m Weight update completed (now v61)\n",
      "Dropping weights @ version 61\n",
      "WandbBackend: Logged 96 metrics at global_step 62\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 62 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011985589905331533\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006834007799625397\n",
      "  dataset/sample/avg_sample_len: 614.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 357.375\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 2859.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.7944552001953125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.7944552001953125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000590399980545044\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000590399980545044\n",
      "  generator_perf/generate/total_duration_avg_s: 1.7952302721738815\n",
      "  generator_perf/generate/total_duration_max_s: 1.7952302721738815\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.821876063942909e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.821876063942909e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011807652190327644\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011807652190327644\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.7999880937859416\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.7999880937859416\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07466210005804896\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07466210005804896\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006831757258623838\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006831757258623838\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 1.9297986011952162\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 1.9297986011952162\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.390960723161697e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.390960723161697e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4515524809248745\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4515524809248745\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.514531617052853\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.514531617052853\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46511357091367245\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46511357091367245\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4830682319588959\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4830682319588959\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1147897439077497\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1147897439077497\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001356382854282856\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001356382854282856\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012844257056713104\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012844257056713104\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003271601162850857\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003271601162850857\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.7027827501297e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.7027827501297e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013386314269155264\n",
      "  reference_perf/forward/total_duration_max_s: 0.013386314269155264\n",
      "  reward/evaluate_response/avg_MathReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 1.0\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.06009340286254883\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004896651953458786\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004896651953458786\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047679292038083076\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047679292038083076\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.449553419370204\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.449553419370204\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4485840811394155\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4485840811394155\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34272384410724044\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34272384410724044\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010439739096909761\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010439739096909761\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10884069511666894\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10884069511666894\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4620066019706428\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4620066019706428\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.542201977223158\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.542201977223158\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 61, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:05 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:45:08 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:45:08 INFO\u001b[0m Weight update completed (now v62)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:10 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:10 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:10 INFO\u001b[0m Pushing weights for policy version 63\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:12 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:13 INFO\u001b[0m Completed weights push in 2.53 seconds\n",
      "Dropping weights @ version 62\n",
      "WandbBackend: Logged 96 metrics at global_step 63\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 63 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9811320754716981\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.123793915518232e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005514598451554775\n",
      "  dataset/sample/avg_sample_len: 497.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.1902011718750005\n",
      "  generator_perf/generate/generate/duration_max_s: 5.37988037109375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006852053403854371\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007435200214385986\n",
      "  generator_perf/generate/total_duration_avg_s: 4.190993854548783\n",
      "  generator_perf/generate/total_duration_max_s: 5.380667475115508\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.4409575164318085e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.4520944356918335e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012358577611545722\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013009849935770035\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.195925380724172\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.385654244106263\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07428683262939255\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07434758078306913\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007274529741456111\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007489222101867199\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.325148109036188\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.515109071973711\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.658941179513931e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.658941179513931e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.530165676958859\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.530165676958859\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.388177839107811\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.388177839107811\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4710266091860831\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4710266091860831\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.6767997294664383e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.6767997294664383e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.38696254696697\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.38696254696697\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013602633650104204\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001394413411617279\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013402069918811321\n",
      "  reference_perf/forward/forward/duration_max_s: 0.014541451819241047\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00036272577320535976\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0004088878631591797\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.046906441450119e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.926307782530785e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013983406902601322\n",
      "  reference_perf/forward/total_duration_max_s: 0.015179418958723545\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.05833333333333334\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.20000000000000007\n",
      "  reward/evaluate_response/avg_total_reward: 0.12916666666666668\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.049300664859163484\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 1.4000000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.800000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.032522059977054596\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000756001565605402\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000756001565605402\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0008692080155014992\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0008692080155014992\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.528125945944339\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.528125945944339\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5264956443570554\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5264956443570554\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34665613900870085\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34665613900870085\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01135764829814434\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01135764829814434\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10940912365913391\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10940912365913391\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4674262311309576\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4674262311309576\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.257298670709133\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.257298670709133\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 62, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:15 INFO\u001b[0m Pushing weights for policy version 64\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:17 INFO\u001b[0m Completed weights push in 2.42 seconds\n",
      "[0] INFO 10-16 19:45:18 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 63[0] \u001b[34m[Generator-0/1] 2025-10-16 19:45:18 INFO\u001b[0m Weight update completed (now v63)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 64\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 64 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9285714285714286\n",
      "  buffer/sample/count_sample_requests: 14.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010807642580143042\n",
      "  buffer_perf/sample/total_duration_max_s: 0.000652907881885767\n",
      "  dataset/sample/avg_sample_len: 538.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9755313720703125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9755313720703125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005888000130653381\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005888000130653381\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9763135800808669\n",
      "  generator_perf/generate/total_duration_max_s: 1.9763135800808669\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.889722913503647e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.889722913503647e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012124092318117619\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012124092318117619\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.981780047994107\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.981780047994107\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07424037158489227\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07424037158489227\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0075582051649689674\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0075582051649689674\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1112741800025105\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1112741800025105\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.512257874011993e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.512257874011993e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4224962759763002\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4224962759763002\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.700265601743013\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.700265601743013\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4684987408109009\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4684987408109009\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.49301726184785366\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.49301726184785366\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.3162468019872904\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.3162468019872904\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.000136583112180233\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.000136583112180233\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012887308839708567\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012887308839708567\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034079793840646744\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034079793840646744\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.813703268766403e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.813703268766403e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01344497175887227\n",
      "  reference_perf/forward/total_duration_max_s: 0.01344497175887227\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.4\n",
      "  reward/evaluate_response/avg_total_reward: 0.25000000000000006\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.34641016151377546\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 3.2\n",
      "  rl_trainer/avg_grpo_loss: 0.03487606346607208\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004882737994194031\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004882737994194031\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004829978570342064\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004829978570342064\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.420648732688278\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.420648732688278\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4196745580993593\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4196745580993593\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3443756317719817\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3443756317719817\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010600132402032614\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010600132402032614\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1103928186930716\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1103928186930716\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4653722350485623\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4653722350485623\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5633579050190747\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5633579050190747\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 63, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:20 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:45:23 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:45:23 INFO\u001b[0m Weight update completed (now v64)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:25 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:25 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:26 INFO\u001b[0m Pushing weights for policy version 65\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:27 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:28 INFO\u001b[0m Completed weights push in 2.55 seconds\n",
      "Dropping weights @ version 64\n",
      "WandbBackend: Logged 96 metrics at global_step 65\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 65 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9811320754716981\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.318727847692129e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005662101320922375\n",
      "  dataset/sample/avg_sample_len: 541.6666666666666\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.165146362304688\n",
      "  generator_perf/generate/generate/duration_max_s: 5.40438916015625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006764480074246725\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007006080150604248\n",
      "  generator_perf/generate/total_duration_avg_s: 4.165915236975998\n",
      "  generator_perf/generate/total_duration_max_s: 5.405137288171798\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.7161167711019516e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.867790266871452e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001223190687596798\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001299381721764803\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.170947858287643\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.4107551872730255\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07428900509451826\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07466517621651292\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007313675247132778\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007451742887496948\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.300637192558497\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.541062502656132\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.845205694437027e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.845205694437027e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5481226542033255\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5481226542033255\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.392172235995531\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.392172235995531\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4679982797242701\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4679982797242701\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.2205989807844162e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.2205989807844162e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.376022050157189\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.376022050157189\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013808036843935648\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014527281746268272\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013429927174001932\n",
      "  reference_perf/forward/forward/duration_max_s: 0.014058212749660015\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.000337498572965463\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003519686870276928\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.847246403495471e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.311914280056953e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013986099977046251\n",
      "  reference_perf/forward/total_duration_max_s: 0.014635647647082806\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.07500000000000002\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.20000000000000007\n",
      "  reward/evaluate_response/avg_total_reward: 0.1375\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.04330127018922193\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 1.8000000000000005\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.800000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.027912095189094543\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00041447998955845833\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00041447998955845833\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004553147591650486\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004553147591650486\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5461788889952004\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5461788889952004\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5453039961867034\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5453039961867034\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34380538715049624\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34380538715049624\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010646066628396511\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010646066628396511\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1104001090861857\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1104001090861857\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46485333796590567\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46485333796590567\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2711920044384897\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2711920044384897\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 64, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:30 INFO\u001b[0m Pushing weights for policy version 66\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:32 INFO\u001b[0m Completed weights push in 2.50 seconds\n",
      "[0] INFO 10-16 19:45:33 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 65[0] \u001b[34m[Generator-0/1] 2025-10-16 19:45:33 INFO\u001b[0m Weight update completed (now v65)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 66\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 66 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9230769230769231\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010263887592233144\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006297859363257885\n",
      "  dataset/sample/avg_sample_len: 472.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9898760986328126\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9898760986328126\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007132800221443176\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007132800221443176\n",
      "  generator_perf/generate/total_duration_avg_s: 1.990792354658246\n",
      "  generator_perf/generate/total_duration_max_s: 1.990792354658246\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.084695294499397e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.084695294499397e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012503382749855518\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012503382749855518\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.996624362654984\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.996624362654984\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07449190132319927\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07449190132319927\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006847694981843233\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006847694981843233\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1276818332262337\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1276818332262337\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.8852525651454926e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.8852525651454926e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5042323619127274\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5042323619127274\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.605164987966418\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.605164987966418\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46938650216907263\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46938650216907263\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4151337770745158\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4151337770745158\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2164051989093423\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2164051989093423\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013590510934591293\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013590510934591293\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012851520907133818\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012851520907133818\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003461642190814018\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003461642190814018\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.867114618420601e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.867114618420601e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013414411339908838\n",
      "  reference_perf/forward/total_duration_max_s: 0.013414411339908838\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.6000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.35000000000000003\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3999999999999999\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.800000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.03505304455757141\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004979860968887806\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004979860968887806\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048567214980721474\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048567214980721474\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5021743113175035\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5021743113175035\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.501187144778669\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.501187144778669\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.346617525909096\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.346617525909096\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010479315184056759\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010479315184056759\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10903822910040617\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10903822910040617\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4661374827846885\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4661374827846885\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.550886342767626\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.550886342767626\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 65, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:35 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:45:38 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:45:38 INFO\u001b[0m Weight update completed (now v66)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:40 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:40 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:41 INFO\u001b[0m Pushing weights for policy version 67\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:42 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:43 INFO\u001b[0m Completed weights push in 2.55 seconds\n",
      "Dropping weights @ version 66\n",
      "WandbBackend: Logged 96 metrics at global_step 67\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 67 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9842767295597484\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9685534591194969\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 7.183537692637057e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006119427271187305\n",
      "  dataset/sample/avg_sample_len: 531.3333333333334\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 496.875\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11925.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.146386759440104\n",
      "  generator_perf/generate/generate/duration_max_s: 5.36797021484375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006422186493873597\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006801599860191346\n",
      "  generator_perf/generate/total_duration_avg_s: 4.147119666088373\n",
      "  generator_perf/generate/total_duration_max_s: 5.368660166826099\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.3800024539232254e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.10229729115963e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012391641115148861\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012732939794659615\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.152162433601916\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.374550862703472\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0744015802629292\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07459870493039489\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007366418683280547\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007941764313727617\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.282071550842375\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.506031604018062\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.258938133716583e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.258938133716583e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.555906016845256\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.555906016845256\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.417400836013258\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.417400836013258\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4692385490052402\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4692385490052402\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.6223173588514328e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.6223173588514328e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.392233844846487\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.392233844846487\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014374436189730963\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001644650474190712\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013213773258030415\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013934232760220766\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003533773124217987\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003923061303794384\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.076149970293045e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.87792557477951e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013794045895338058\n",
      "  reference_perf/forward/total_duration_max_s: 0.014582213945686817\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.3249999999999998\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.6666666666666664\n",
      "  reward/evaluate_response/avg_total_reward: 0.49583333333333357\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3897114317029974\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.39440531887330776\n",
      "  reward/evaluate_response/sum_MathReward_reward: 7.7999999999999945\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 15.999999999999993\n",
      "  rl_trainer/avg_grpo_loss: 0.05539461970329285\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004378766752779484\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004378766752779484\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.000461457297205925\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.000461457297205925\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5540889017283916\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5540889017283916\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5531857018359005\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5531857018359005\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3466356359422207\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3466356359422207\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010489210952073336\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010489210952073336\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10897887637838721\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10897887637838721\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4661060320213437\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4661060320213437\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2622231640852988\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2622231640852988\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 66, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:44 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:44 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:45 INFO\u001b[0m Pushing weights for policy version 68\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:47 INFO\u001b[0m Completed weights push in 2.47 seconds\n",
      "[0] INFO 10-16 19:45:48 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 67[0] \u001b[34m[Generator-0/1] 2025-10-16 19:45:48 INFO\u001b[0m Weight update completed (now v67)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 68\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 68 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011041515972465277\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006347321905195713\n",
      "  dataset/sample/avg_sample_len: 562.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9682235107421875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9682235107421875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006710079908370972\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006710079908370972\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9690814307332039\n",
      "  generator_perf/generate/total_duration_max_s: 1.9690814307332039\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.227932706475258e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.227932706475258e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011710161343216896\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011710161343216896\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9744408717378974\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9744408717378974\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07429241994395852\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07429241994395852\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007525160908699036\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007525160908699036\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1045650597661734\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1045650597661734\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.867091774940491e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.867091774940491e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4738295059651136\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4738295059651136\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.513889791909605\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.513889791909605\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4696138007566333\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4696138007566333\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.45521373208612204\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.45521373208612204\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1152243819087744\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1152243819087744\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013779010623693466\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013779010623693466\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012938736006617546\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012938736006617546\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003386521711945534\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003386521711945534\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.985206320881844e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.985206320881844e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013497288338840008\n",
      "  reference_perf/forward/total_duration_max_s: 0.013497288338840008\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.15000000000000005\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.03777006268501282\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004935478791594505\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004935478791594505\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004901271313428879\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004901271313428879\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4718495830893517\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4718495830893517\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.470863034017384\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.470863034017384\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3460984621196985\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3460984621196985\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010543636977672577\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010543636977672577\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10993513511493802\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10993513511493802\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46657969523221254\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46657969523221254\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5501579572446644\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5501579572446644\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 67, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:50 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:45:53 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:45:53 INFO\u001b[0m Weight update completed (now v68)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:55 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:55 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:56 INFO\u001b[0m Pushing weights for policy version 69\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:57 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:58 INFO\u001b[0m Completed weights push in 2.50 seconds\n",
      "Dropping weights @ version 68\n",
      "WandbBackend: Logged 96 metrics at global_step 69\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 69 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9836182336182335\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.967236467236467\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.795891871054967e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005606706254184246\n",
      "  dataset/sample/avg_sample_len: 451.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 508.0416666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12193.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.17255908203125\n",
      "  generator_perf/generate/generate/duration_max_s: 5.3785390625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005963519910971324\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007066879868507385\n",
      "  generator_perf/generate/total_duration_avg_s: 4.173246612690389\n",
      "  generator_perf/generate/total_duration_max_s: 5.379285814486444\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.8077899565299354e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.353987216949463e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011923126876354218\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012138290330767632\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.1780952756914\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.384090655017644\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07428979547694325\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07433534832671285\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007420405590285857\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007720935624092817\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.307819444841395\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.513839810155332\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.052184522151947e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.052184522151947e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.506393843796104\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.506393843796104\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.461450561881065\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.461450561881065\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46848658192902803\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46848658192902803\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.6001053154468536e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.6001053154468536e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.486546807922423\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.486546807922423\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013305976366003355\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013485178351402283\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013442559943844875\n",
      "  reference_perf/forward/forward/duration_max_s: 0.014050378929823637\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034694978967309\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003562341444194317\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.721222937107086e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.910188287496567e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.014002219308167696\n",
      "  reference_perf/forward/total_duration_max_s: 0.014617628883570433\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.12083333333333336\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.3999999999999999\n",
      "  reward/evaluate_response/avg_total_reward: 0.2604166666666666\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.18703646406219535\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3464101615137756\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.900000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 9.599999999999998\n",
      "  rl_trainer/avg_grpo_loss: 0.041542455554008484\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00041740015149116516\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00041740015149116516\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00046126171946525574\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00046126171946525574\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.504589300137013\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.504589300137013\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.503707940224558\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.503707940224558\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34463629964739084\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34463629964739084\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010623641312122345\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010623641312122345\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11054930277168751\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11054930277168751\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4658112577162683\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4658112577162683\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.3584313062019646\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.3584313062019646\n",
      "==============================\n",
      "\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:45:59 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "Dropped weights @ version 68, took 0.44 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:59 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:45:59 INFO\u001b[0m Pushing weights for policy version 70\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:02 INFO\u001b[0m Completed weights push in 2.43 seconds\n",
      "[0] INFO 10-16 19:46:02 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 69[0] \u001b[34m[Generator-0/1] 2025-10-16 19:46:02 INFO\u001b[0m Weight update completed (now v69)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 70\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 70 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8333333333333333\n",
      "  buffer/sample/count_sample_requests: 6.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00019701927279432616\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006700139492750168\n",
      "  dataset/sample/avg_sample_len: 502.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 303.75\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 2430.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.350066162109375\n",
      "  generator_perf/generate/generate/duration_max_s: 1.350066162109375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005186560153961181\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005186560153961181\n",
      "  generator_perf/generate/total_duration_avg_s: 1.3507572021186351\n",
      "  generator_perf/generate/total_duration_max_s: 1.3507572021186351\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.672406405210495e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.672406405210495e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0013207350857555866\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013207350857555866\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.3572647362016141\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.3572647362016141\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07453872915357351\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07453872915357351\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.010392007883638144\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.010392007883638144\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 1.4898750022985041\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 1.4898750022985041\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.622619599103928e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.622619599103928e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.435652614105493\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.435652614105493\n",
      "  main_perf/continuous_training/total_duration_avg_s: 3.925378018990159\n",
      "  main_perf/continuous_training/total_duration_max_s: 3.925378018990159\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46520127123221755\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46520127123221755\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5144087420776486\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5144087420776486\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 0.5101065495982766\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 0.5101065495982766\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013791490346193314\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013791490346193314\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012873122002929449\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012873122002929449\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003363140858709812\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003363140858709812\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.73472711443901e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.73472711443901e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013426842167973518\n",
      "  reference_perf/forward/total_duration_max_s: 0.013426842167973518\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.8875\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 0.94375\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.2976470224947665\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 7.1\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.06375646591186523\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005667665973305702\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005667665973305702\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048342300578951836\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048342300578951836\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4333198037929833\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4333198037929833\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.432266440242529\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.432266440242529\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3419943400658667\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3419943400658667\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010507815051823854\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010507815051823854\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10907392390072346\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10907392390072346\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46158136101439595\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46158136101439595\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5468242499046028\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5468242499046028\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 69, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:04 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:46:07 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:46:07 INFO\u001b[0m Weight update completed (now v70)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:09 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:10 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:10 INFO\u001b[0m Pushing weights for policy version 71\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:12 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:12 INFO\u001b[0m Completed weights push in 2.39 seconds\n",
      "Dropping weights @ version 70\n",
      "WandbBackend: Logged 96 metrics at global_step 71\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 71 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9856902356902357\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9713804713804715\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.040739973386129e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005782661028206348\n",
      "  dataset/sample/avg_sample_len: 487.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 511.7083333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12281.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.206356363932292\n",
      "  generator_perf/generate/generate/duration_max_s: 5.37455078125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006001920104026795\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000637664020061493\n",
      "  generator_perf/generate/total_duration_avg_s: 4.2070995746031405\n",
      "  generator_perf/generate/total_duration_max_s: 5.375210077263415\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.0623825043439865e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.480406641960144e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012124823406338692\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012297886423766613\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.21231582807377\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.380552109796554\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07451289581755798\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07476312620565295\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0075146472081542015\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.008270933758467436\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.3437888184562325\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.51035722810775\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.708766937255859e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.708766937255859e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.3965306342579424\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.3965306342579424\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.348699773196131\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.348699773196131\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4668426071293652\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4668426071293652\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.239784225821495e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.239784225821495e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.485295822843909\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.485295822843909\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00015205563977360725\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00019541336223483086\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.015853863209486008\n",
      "  reference_perf/forward/forward/duration_max_s: 0.021598414983600378\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00038354890421032906\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00047138892114162445\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.199022461970647e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.280676022171974e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.016474205845346052\n",
      "  reference_perf/forward/total_duration_max_s: 0.022361147683113813\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.10833333333333338\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.4333333333333334\n",
      "  reward/evaluate_response/avg_total_reward: 0.2708333333333333\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.1913040047208166\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.36362373715452373\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.600000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 10.400000000000002\n",
      "  rl_trainer/avg_grpo_loss: 1.2366431951522827\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004179449751973152\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004179449751973152\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004497729241847992\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004497729241847992\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.394622399006039\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.394622399006039\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.393751333002001\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.393751333002001\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3445088011212647\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3445088011212647\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01052002515643835\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01052002515643835\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10886739287525415\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10886739287525415\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4638983909972012\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4638983909972012\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2699261042289436\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2699261042289436\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 70, took 0.47 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:14 INFO\u001b[0m Pushing weights for policy version 72\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:17 INFO\u001b[0m Completed weights push in 2.56 seconds\n",
      "[0] INFO 10-16 19:46:18 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 71[0] \u001b[34m[Generator-0/1] 2025-10-16 19:46:18 INFO\u001b[0m Weight update completed (now v71)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 72\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 72 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9375\n",
      "  buffer/sample/count_sample_requests: 16.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010043001384474337\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006704856641590595\n",
      "  dataset/sample/avg_sample_len: 444.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 2.09317919921875\n",
      "  generator_perf/generate/generate/duration_max_s: 2.09317919921875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006758080124855041\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006758080124855041\n",
      "  generator_perf/generate/total_duration_avg_s: 2.0941462712287904\n",
      "  generator_perf/generate/total_duration_max_s: 2.0941462712287904\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.915427416563034e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.915427416563034e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012218207120895386\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012218207120895386\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 2.0994117772206664\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 2.0994117772206664\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07462399266660213\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07462399266660213\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007135522086173296\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007135522086173296\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.2302010441198945\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.2302010441198945\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.915986210107803e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.915986210107803e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5648332010023296\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5648332010023296\n",
      "  main_perf/continuous_training/total_duration_avg_s: 5.1321194702759385\n",
      "  main_perf/continuous_training/total_duration_max_s: 5.1321194702759385\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4709108299575746\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4709108299575746\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5741220531053841\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5741220531053841\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.5222388398833573\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.5222388398833573\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014390284195542336\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014390284195542336\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012957581784576178\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012957581784576178\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003411509096622467\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003411509096622467\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.243415504693985e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.243415504693985e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013527459930628538\n",
      "  reference_perf/forward/total_duration_max_s: 0.013527459930628538\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.30000000000000004\n",
      "  reward/evaluate_response/avg_total_reward: 0.20000000000000007\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.2645751311064591\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 2.4000000000000004\n",
      "  rl_trainer/avg_grpo_loss: 0.042261309921741486\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004823170602321625\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004823170602321625\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004970720037817955\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004970720037817955\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5627122530713677\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5627122530713677\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5617267256602645\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5617267256602645\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34824769804254174\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34824769804254174\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010531739797443151\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010531739797443151\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10897944495081902\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10897944495081902\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4677610187791288\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4677610187791288\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.781797513831407\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.781797513831407\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 71, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:20 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:46:23 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:46:23 INFO\u001b[0m Weight update completed (now v72)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:25 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:25 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:25 INFO\u001b[0m Pushing weights for policy version 73\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:27 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:28 INFO\u001b[0m Completed weights push in 2.57 seconds\n",
      "Dropping weights @ version 72\n",
      "WandbBackend: Logged 96 metrics at global_step 73\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 73 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9884696016771488\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9769392033542976\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 4.915767852720377e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005612177774310112\n",
      "  dataset/sample/avg_sample_len: 570.3333333333334\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.222037109375\n",
      "  generator_perf/generate/generate/duration_max_s: 5.61951513671875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007552106777826945\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0009291520118713379\n",
      "  generator_perf/generate/total_duration_avg_s: 4.222887498717755\n",
      "  generator_perf/generate/total_duration_max_s: 5.6204884807318445\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.259132305781046e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.770420491695404e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012210309505462646\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012714737094938755\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.227890751324594\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.626064893323928\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07429989287629724\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07447497686371207\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007075296714901924\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00744664017111063\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.3566485497479635\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.755393483676016\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.0228478610515594e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.0228478610515594e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.570952413138002\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.570952413138002\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.416080388240516\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.416080388240516\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.47006278298795223\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.47006278298795223\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.5215016901493073e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.5215016901493073e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.375043686944991\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.375043686944991\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013480630392829576\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001366790384054184\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012935080875953039\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013158197049051523\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003382874031861623\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034269504249095917\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.868946219484012e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.099107071757317e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013488933288802704\n",
      "  reference_perf/forward/total_duration_max_s: 0.013715815730392933\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.08333333333333336\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.20000000000000007\n",
      "  reward/evaluate_response/avg_total_reward: 0.1416666666666667\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.03726779962499651\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.0000000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.800000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.027938000857830048\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00043203169479966164\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00043203169479966164\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004963940009474754\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004963940009474754\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5691437628120184\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5691437628120184\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5682120909914374\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5682120909914374\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.346704482100904\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.346704482100904\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010519593022763729\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010519593022763729\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10984079074114561\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10984079074114561\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4670673357322812\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4670673357322812\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2575766290538013\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2575766290538013\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 72, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:30 INFO\u001b[0m Pushing weights for policy version 74\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:32 INFO\u001b[0m Completed weights push in 2.46 seconds\n",
      "[0] INFO 10-16 19:46:33 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 73[0] \u001b[34m[Generator-0/1] 2025-10-16 19:46:33 INFO\u001b[0m Weight update completed (now v73)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 74\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 74 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010860660889496405\n",
      "  buffer_perf/sample/total_duration_max_s: 0.000607282854616642\n",
      "  dataset/sample/avg_sample_len: 477.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9762347412109376\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9762347412109376\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006926079988479614\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006926079988479614\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9771108372062445\n",
      "  generator_perf/generate/total_duration_max_s: 1.9771108372062445\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.558824002742767e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.558824002742767e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012160059995949268\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012160059995949268\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.982142607215792\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.982142607215792\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07463285606354475\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07463285606354475\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0070322537794709206\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0070322537794709206\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1110990620218217\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1110990620218217\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.790257662534714e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.790257662534714e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.459174391813576\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.459174391813576\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.533335938118398\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.533335938118398\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46812670724466443\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46812670724466443\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4905615719035268\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4905615719035268\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1154623660258949\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1154623660258949\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013691280037164688\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013691280037164688\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012903866823762655\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012903866823762655\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003335769288241863\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003335769288241863\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.970817387104034e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.970817387104034e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013456187676638365\n",
      "  reference_perf/forward/total_duration_max_s: 0.013456187676638365\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.025\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.11249999999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.04330127018922194\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.2\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.040419094264507294\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00048581836745142937\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00048581836745142937\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004834868013858795\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004834868013858795\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4572617444209754\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4572617444209754\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4562883540056646\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4562883540056646\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3443915108218789\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3443915108218789\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010654441080987453\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010654441080987453\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10978735191747546\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10978735191747546\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46483577881008387\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46483577881008387\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5693468311801553\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5693468311801553\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 73, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:35 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:46:38 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:46:38 INFO\u001b[0m Weight update completed (now v74)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:40 INFO\u001b[0m Pushing weights for policy version 75\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:43 INFO\u001b[0m Completed weights push in 2.60 seconds\n",
      "Dropping weights @ version 74\n",
      "WandbBackend: Logged 96 metrics at global_step 75\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 75 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9895833333333334\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9791666666666667\n",
      "  buffer/sample/count_sample_requests: 69.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.2894904291716173e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006058490835130215\n",
      "  dataset/sample/avg_sample_len: 472.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 399.75\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 9594.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 3.890020589192708\n",
      "  generator_perf/generate/generate/duration_max_s: 5.4001591796875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006010026733080546\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006637120246887207\n",
      "  generator_perf/generate/total_duration_avg_s: 3.890713303864002\n",
      "  generator_perf/generate/total_duration_max_s: 5.4008341557085515\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.4870966424544655e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.07342629134655e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001204209712644418\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012503047473728657\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 3.8964307780067124\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.406740196049213\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07428338037182887\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07438834430649877\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0076982686296105385\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00797562813386321\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.026835054469605\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.537383002229035\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.14019450545311e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.14019450545311e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.59758925717324\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.59758925717324\n",
      "  main_perf/continuous_training/total_duration_avg_s: 9.937464344780892\n",
      "  main_perf/continuous_training/total_duration_max_s: 9.937464344780892\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46237486274912953\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46237486274912953\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.7475802451372147e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.7475802451372147e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 6.877475352026522\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 6.877475352026522\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013341599454482397\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013747205957770348\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012872445397078991\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012913891114294529\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003396390626827876\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034402403980493546\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.406497995058696e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.707905024290085e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01342160782466332\n",
      "  reference_perf/forward/total_duration_max_s: 0.013474380131810904\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.6541666666666667\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.7666666666666666\n",
      "  reward/evaluate_response/avg_total_reward: 0.7104166666666667\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.44719418476640427\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.363623737154524\n",
      "  reward/evaluate_response/sum_MathReward_reward: 15.7\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 18.4\n",
      "  rl_trainer/avg_grpo_loss: 0.07227727025747299\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00043407920747995377\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00043407920747995377\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048271799460053444\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048271799460053444\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5957348132506013\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5957348132506013\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.594815131742507\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.594815131742507\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3407349777407944\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3407349777407944\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010443821083754301\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010443821083754301\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10825565690174699\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10825565690174699\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.45943645667284727\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.45943645667284727\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.260250787716359\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.260250787716359\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 74, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:44 INFO\u001b[0m Pushing weights for policy version 76\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:46 INFO\u001b[0m Completed weights push in 2.48 seconds\n",
      "[0] INFO 10-16 19:46:47 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 75\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:46:47 INFO\u001b[0m Weight update completed (now v75)\n",
      "WandbBackend: Logged 96 metrics at global_step 76\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 76 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8888888888888888\n",
      "  buffer/sample/count_sample_requests: 9.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00014418425659338632\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007209400646388531\n",
      "  dataset/sample/avg_sample_len: 438.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 493.875\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3951.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.98827685546875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.98827685546875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006197760105133057\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006197760105133057\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9890820714831352\n",
      "  generator_perf/generate/total_duration_max_s: 1.9890820714831352\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.765895962715149e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 3.765895962715149e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012504570186138153\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012504570186138153\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9941544979810715\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9941544979810715\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.074742266908288\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.074742266908288\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0074059548787772655\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0074059548787772655\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.124178704805672\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.124178704805672\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.379319190979004e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.379319190979004e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.485140782315284\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.485140782315284\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.255011308938265\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.255011308938265\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4669961538165808\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4669961538165808\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.49034070270136\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.49034070270136\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 0.8125244537368417\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 0.8125244537368417\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013393256813287735\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013393256813287735\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01279671024531126\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01279671024531126\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003353790380060673\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003353790380060673\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.576495409011841e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.576495409011841e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013344197999686003\n",
      "  reference_perf/forward/total_duration_max_s: 0.013344197999686003\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.325\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.9\n",
      "  reward/evaluate_response/avg_total_reward: 0.6124999999999998\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3897114317029973\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.26457513110645897\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.6\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 7.2\n",
      "  rl_trainer/avg_grpo_loss: 0.056630611419677734\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004842611961066723\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004842611961066723\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004794117994606495\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004794117994606495\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.4829425211064517\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.4829425211064517\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4819757002405822\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4819757002405822\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3442742759361863\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3442742759361863\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010552611202001572\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010552611202001572\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10903628170490265\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10903628170490265\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4638657527975738\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4638657527975738\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5785516230389476\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5785516230389476\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 75, took 0.46 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:49 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:46:52 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:46:52 INFO\u001b[0m Weight update completed (now v76)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:55 INFO\u001b[0m Pushing weights for policy version 77\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:57 INFO\u001b[0m Completed weights push in 2.69 seconds\n",
      "Dropping weights @ version 76\n",
      "WandbBackend: Logged 96 metrics at global_step 77\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 77 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9811320754716981\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.70963734690402e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005780747160315514\n",
      "  dataset/sample/avg_sample_len: 489.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 479.9583333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11519.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.180742350260417\n",
      "  generator_perf/generate/generate/duration_max_s: 5.42192138671875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006620800097783406\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007712640166282654\n",
      "  generator_perf/generate/total_duration_avg_s: 4.18151544893533\n",
      "  generator_perf/generate/total_duration_max_s: 5.422655850715935\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.858391816417376e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.722783342003822e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012470221457382042\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012641903012990952\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.186927140224725\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.427982106804848\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07440768321976066\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07463458040729165\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007314495742321014\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0075810314156115055\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.317034405345718\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.558154092635959\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.242174327373505e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.242174327373505e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.6914910851046443\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.6914910851046443\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.541943647898734\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.541943647898734\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4694955488666892\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4694955488666892\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.005789428949356e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.005789428949356e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.380929321050644\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.380929321050644\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013980688527226448\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014992523938417435\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012969595535347858\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01305944798514247\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003729743572572867\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0004433100111782551\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.311433096726735e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.25939530134201e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013567652242879072\n",
      "  reference_perf/forward/total_duration_max_s: 0.013747173361480236\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.3625\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5\n",
      "  reward/evaluate_response/avg_total_reward: 0.4312500000000001\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4090767042988393\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207418\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.7\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 12.0\n",
      "  rl_trainer/avg_grpo_loss: 0.06244862452149391\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004297853447496891\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004297853447496891\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004595927894115448\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004595927894115448\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.689698220230639\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.689698220230639\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.688805801793933\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.688805801793933\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34608556097373366\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34608556097373366\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010573170147836208\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010573170147836208\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11007532896474004\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11007532896474004\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46673665288835764\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46673665288835764\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.284967666026205\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.284967666026205\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 76, took 0.46 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:46:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:59 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:46:59 INFO\u001b[0m Pushing weights for policy version 78\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:02 INFO\u001b[0m Completed weights push in 2.56 seconds\n",
      "[0] INFO 10-16 19:47:02 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 77[0] \u001b[34m[Generator-0/1] 2025-10-16 19:47:02 INFO\u001b[0m Weight update completed (now v77)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 78\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 78 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.881118881118881\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011223866246067561\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007216348312795162\n",
      "  dataset/sample/avg_sample_len: 422.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 2.068544189453125\n",
      "  generator_perf/generate/generate/duration_max_s: 2.068544189453125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007242239713668823\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007242239713668823\n",
      "  generator_perf/generate/total_duration_avg_s: 2.0694735974222422\n",
      "  generator_perf/generate/total_duration_max_s: 2.0694735974222422\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.4140109568834305e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.4140109568834305e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0013372525572776794\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013372525572776794\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 2.0753470743075013\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 2.0753470743075013\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07481048768386245\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07481048768386245\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007393143139779568\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007393143139779568\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.2066528908908367\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.2066528908908367\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.120877176523209e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.120877176523209e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5637331027537584\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5637331027537584\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.7024702788330615\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.7024702788330615\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46797237591817975\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46797237591817975\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.44470761017873883\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.44470761017873883\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2260485580191016\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2260485580191016\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014340411871671677\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014340411871671677\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013029427733272314\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013029427733272314\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034249015152454376\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034249015152454376\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.992517203092575e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.992517203092575e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013597317971289158\n",
      "  reference_perf/forward/total_duration_max_s: 0.013597317971289158\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.30000000000000004\n",
      "  reward/evaluate_response/avg_total_reward: 0.15000000000000002\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.264575131106459\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 2.4000000000000004\n",
      "  rl_trainer/avg_grpo_loss: 0.07086564600467682\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005918261595070362\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005918261595070362\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0005948389880359173\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0005948389880359173\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5617414112202823\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5617414112202823\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5605516829527915\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5605516829527915\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3446728107519448\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3446728107519448\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010674516204744577\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010674516204744577\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10909356595948339\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10909356595948339\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46444528084248304\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46444528084248304\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.6865038950927556\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.6865038950927556\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 77, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:04 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:47:07 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:47:07 INFO\u001b[0m Weight update completed (now v78)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:09 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:09 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:10 INFO\u001b[0m Pushing weights for policy version 79\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:11 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:12 INFO\u001b[0m Completed weights push in 2.48 seconds\n",
      "Dropping weights @ version 78\n",
      "WandbBackend: Logged 96 metrics at global_step 79\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 79 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9884696016771488\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9769392033542976\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.43682968173478e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006142621859908104\n",
      "  dataset/sample/avg_sample_len: 466.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 469.6666666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11272.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.1953129475911455\n",
      "  generator_perf/generate/generate/duration_max_s: 5.5110234375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000587338666121165\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006183040142059326\n",
      "  generator_perf/generate/total_duration_avg_s: 4.19599400359268\n",
      "  generator_perf/generate/total_duration_max_s: 5.5116289094761015\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.8986559957265854e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.2832067012786865e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012246809589366119\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013165581040084362\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.2007921054027975\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.5166417439468205\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07415309765686591\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07430164981633425\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007368164447446664\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007753101177513599\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.3305605587859946\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.645206982269883\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.6030618250370026e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.6030618250370026e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.485430314671248\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.485430314671248\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.336801914032549\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.336801914032549\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46777358232066035\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46777358232066035\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.885509118437767e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.885509118437767e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.383571656886488\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.383571656886488\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001334304300447305\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013561267405748367\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012813539244234562\n",
      "  reference_perf/forward/forward/duration_max_s: 0.0128350630402565\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033115362748503685\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003348700702190399\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.451030736168225e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.563689723610878e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013354833082606396\n",
      "  reference_perf/forward/total_duration_max_s: 0.013378518167883158\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.7000000000000002\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.9333333333333332\n",
      "  reward/evaluate_response/avg_total_reward: 0.8166666666666669\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.42426406871192823\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.22110831935702688\n",
      "  reward/evaluate_response/sum_MathReward_reward: 16.800000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 22.4\n",
      "  rl_trainer/avg_grpo_loss: 0.049500029534101486\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004232930950820446\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004232930950820446\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004769228398799896\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004769228398799896\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.483704447746277\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.483704447746277\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.482801069971174\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.482801069971174\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3449261230416596\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3449261230416596\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010694387834519148\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010694387834519148\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10947313206270337\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10947313206270337\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4650957649573684\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4650957649573684\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2696494148112833\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2696494148112833\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 78, took 0.42 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:14 INFO\u001b[0m Pushing weights for policy version 80\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:17 INFO\u001b[0m Completed weights push in 2.56 seconds\n",
      "[0] INFO 10-16 19:47:17 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 79\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:47:17 INFO\u001b[0m Weight update completed (now v79)\n",
      "WandbBackend: Logged 96 metrics at global_step 80\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 80 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9230769230769231\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00012224776527056328\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006776242516934872\n",
      "  dataset/sample/avg_sample_len: 453.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.98995068359375\n",
      "  generator_perf/generate/generate/duration_max_s: 1.98995068359375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006207360029220581\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006207360029220581\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9907585235983134\n",
      "  generator_perf/generate/total_duration_max_s: 1.9907585235983134\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.877995863556862e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.877995863556862e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012445850297808647\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012445850297808647\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9958719750866294\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9958719750866294\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07468403782695532\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07468403782695532\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006834574043750763\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006834574043750763\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.125270856078714\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.125270856078714\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.8782676458358765e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.8782676458358765e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5640472481027246\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5640472481027246\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.661723107099533\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.661723107099533\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4686461826786399\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4686461826786399\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4130802149884403\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4130802149884403\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2159400093369186\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2159400093369186\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001388280652463436\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001388280652463436\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01290637906640768\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01290637906640768\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003347909078001976\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003347909078001976\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.818825542926788e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.818825542926788e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013460365124046803\n",
      "  reference_perf/forward/total_duration_max_s: 0.013460365124046803\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0625\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.13125\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.04841229182759273\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.5\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.05017164349555969\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005156258121132851\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005156258121132851\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004803263582289219\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004803263582289219\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.561820031143725\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.561820031143725\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.560818202793598\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.560818202793598\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34398986818268895\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34398986818268895\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010680607985705137\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010680607985705137\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1104903700761497\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1104903700761497\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46516422601416707\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46516422601416707\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.583575828000903\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.583575828000903\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 79, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:19 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:47:22 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:47:22 INFO\u001b[0m Weight update completed (now v80)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:24 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:24 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:25 INFO\u001b[0m Pushing weights for policy version 81\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:28 INFO\u001b[0m Completed weights push in 2.60 seconds\n",
      "Dropping weights @ version 80\n",
      "WandbBackend: Logged 96 metrics at global_step 81\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 81 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9817610062893082\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9635220125786164\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 7.171169351282958e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005520349368453026\n",
      "  dataset/sample/avg_sample_len: 553.3333333333334\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 467.0833333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11210.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.123291300455729\n",
      "  generator_perf/generate/generate/duration_max_s: 5.4055185546875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006884373227755229\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007972800135612487\n",
      "  generator_perf/generate/total_duration_avg_s: 4.124090585776915\n",
      "  generator_perf/generate/total_duration_max_s: 5.406189722660929\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.342664033174515e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.9353111535310745e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012981458567082882\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001458305399864912\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.129535051528364\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.4119125586003065\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07423185945178072\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07446906808763742\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007374418588976066\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.008077953942120075\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.2594611349826055\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.541200030129403\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.475004971027374e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.475004971027374e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.597409608773887\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.597409608773887\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.455231450032443\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.455231450032443\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46840670984238386\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46840670984238386\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.178596332669258e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.178596332669258e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.389385335147381\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.389385335147381\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001334724947810173\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013638334348797798\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012862199917435646\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01289919763803482\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033248340090115863\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033773016184568405\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.693888619542122e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.093565702438354e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013407244036595026\n",
      "  reference_perf/forward/total_duration_max_s: 0.013445985969156027\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.4000000000000001\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5\n",
      "  reward/evaluate_response/avg_total_reward: 0.45\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.42426406871192845\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207418\n",
      "  reward/evaluate_response/sum_MathReward_reward: 9.600000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 12.0\n",
      "  rl_trainer/avg_grpo_loss: 0.13559497892856598\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004208730533719063\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004208730533719063\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004659169353544712\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004659169353544712\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5956038306467235\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5956038306467235\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5947141819633543\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5947141819633543\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3449195441789925\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3449195441789925\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01058591203764081\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01058591203764081\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10999865084886551\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10999865084886551\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46550630731508136\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46550630731508136\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2509301211684942\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2509301211684942\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 80, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:28 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:29 INFO\u001b[0m Pushing weights for policy version 82\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:32 INFO\u001b[0m Completed weights push in 2.56 seconds\n",
      "[0] INFO 10-16 19:47:32 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 81[0] \u001b[34m[Generator-0/1] 2025-10-16 19:47:32 INFO\u001b[0m Weight update completed (now v81)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 82\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 82 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9090909090909092\n",
      "  buffer/sample/count_sample_requests: 11.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00012036285955797543\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007116599008440971\n",
      "  dataset/sample/avg_sample_len: 534.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.97576220703125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.97576220703125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006783360242843628\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006783360242843628\n",
      "  generator_perf/generate/total_duration_avg_s: 1.976627743050456\n",
      "  generator_perf/generate/total_duration_max_s: 1.976627743050456\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.2883679270744324e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.2883679270744324e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011116350069642067\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011116350069642067\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9820447470992804\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9820447470992804\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07441626489162445\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07441626489162445\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006822603289037943\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006822603289037943\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1102338982746005\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1102338982746005\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.227047950029373e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.227047950029373e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.56585306301713\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.56585306301713\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.447355387732387\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.447355387732387\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4638924589380622\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4638924589380622\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.40054856101050973\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.40054856101050973\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.017052455805242\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.017052455805242\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001358487643301487\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001358487643301487\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012932228855788708\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012932228855788708\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003338051028549671\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003338051028549671\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.307995110750198e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.307995110750198e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013477152679115534\n",
      "  reference_perf/forward/total_duration_max_s: 0.013477152679115534\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.0561407208442688\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00048503000289201736\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00048503000289201736\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047356728464365005\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047356728464365005\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.563763832207769\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.563763832207769\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.56280200695619\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.56280200695619\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34156490629538894\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34156490629538894\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010424411855638027\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010424411855638027\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10900828614830971\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10900828614830971\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4610000173561275\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4610000173561275\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.6174211888574064\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.6174211888574064\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 81, took 0.47 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:34 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:47:37 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:47:37 INFO\u001b[0m Weight update completed (now v82)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:40 INFO\u001b[0m Pushing weights for policy version 83\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:42 INFO\u001b[0m Completed weights push in 2.53 seconds\n",
      "Dropping weights @ version 82\n",
      "WandbBackend: Logged 96 metrics at global_step 83\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 83 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9865229110512128\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.575104025368755e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005638338625431061\n",
      "  dataset/sample/avg_sample_len: 480.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.200651163736979\n",
      "  generator_perf/generate/generate/duration_max_s: 5.5085771484375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006406826575597128\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007381119728088379\n",
      "  generator_perf/generate/total_duration_avg_s: 4.201396561062585\n",
      "  generator_perf/generate/total_duration_max_s: 5.509292572427541\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.078494384884834e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.3761061280965805e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0013043791987001896\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0014767111279070377\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.20665870870774\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.515080862678587\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.074523298535496\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07488012965768576\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0076229617310067015\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007872637826949358\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.337859831595172\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.647153314203024\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.0959566831588745e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.0959566831588745e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5337702240794897\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5337702240794897\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.403305348940194\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.403305348940194\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46982312155887485\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46982312155887485\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.4516990631818771e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.4516990631818771e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.3996903211809695\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.3996903211809695\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014285681148370108\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001532682217657566\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012934996280819178\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013107366859912872\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003381621402998765\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00033970410004258156\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.870265593131383e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.078617975115776e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013496804982423782\n",
      "  reference_perf/forward/total_duration_max_s: 0.013679132331162691\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.10000000000000003\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.2666666666666667\n",
      "  reward/evaluate_response/avg_total_reward: 0.18333333333333326\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.22110831935702668\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.400000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 6.400000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.038109567016363144\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00042515993118286133\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00042515993118286133\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00046309689059853554\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00046309689059853554\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.531866448931396\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.531866448931396\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.530975158326328\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.530975158326328\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3475191439501941\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3475191439501941\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010626959148794413\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010626959148794413\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10894457483664155\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10894457483664155\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4670928381383419\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4670928381383419\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.305251867044717\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.305251867044717\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 82, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:44 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:44 INFO\u001b[0m Pushing weights for policy version 84\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:47 INFO\u001b[0m Completed weights push in 2.49 seconds\n",
      "[0] INFO 10-16 19:47:47 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 83[0] \u001b[34m[Generator-0/1] 2025-10-16 19:47:47 INFO\u001b[0m Weight update completed (now v83)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 84\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 84 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9230769230769231\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010417380298559483\n",
      "  buffer_perf/sample/total_duration_max_s: 0.000655696727335453\n",
      "  dataset/sample/avg_sample_len: 529.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 424.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3392.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9484150390625\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9484150390625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.00054339200258255\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.00054339200258255\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9491432310640813\n",
      "  generator_perf/generate/total_duration_max_s: 1.9491432310640813\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.13782724738121e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.13782724738121e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012656799517571926\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012656799517571926\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9543213238939643\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9543213238939643\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07434022566303611\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07434022566303611\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0073915752582252026\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0073915752582252026\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.084377867169678\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.084377867169678\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.6049244701862335e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.6049244701862335e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.492101482115686\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.492101482115686\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.633448214735836\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.633448214735836\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46849321387708187\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46849321387708187\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.45775071484968066\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.45775071484968066\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2150932480581105\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2150932480581105\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013953633606433868\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013953633606433868\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012934737838804722\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012934737838804722\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003349892795085907\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003349892795085907\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.581384852528572e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.581384852528572e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013487527146935463\n",
      "  reference_perf/forward/total_duration_max_s: 0.013487527146935463\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.55\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 0.7749999999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.44999999999999984\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 4.4\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.045588377863168716\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000479050911962986\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000479050911962986\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004896810278296471\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004896810278296471\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.489545715972781\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.489545715972781\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4885735800489783\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4885735800489783\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34445549501106143\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34445549501106143\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010627313982695341\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010627313982695341\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11029948107898235\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11029948107898235\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46538555808365345\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46538555808365345\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.579648563172668\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.579648563172668\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 83, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:49 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:47:52 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:47:52 INFO\u001b[0m Weight update completed (now v84)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:55 INFO\u001b[0m Pushing weights for policy version 85\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:58 INFO\u001b[0m Completed weights push in 2.64 seconds\n",
      "Dropping weights @ version 84\n",
      "WandbBackend: Logged 96 metrics at global_step 85\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 85 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9811320754716981\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.219691130961921e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005867430008947849\n",
      "  dataset/sample/avg_sample_len: 545.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 509.75\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12234.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.165477376302084\n",
      "  generator_perf/generate/generate/duration_max_s: 5.4181083984375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000734335978825887\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0008013759851455689\n",
      "  generator_perf/generate/total_duration_avg_s: 4.166304960280657\n",
      "  generator_perf/generate/total_duration_max_s: 5.418898094411939\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.353739157319069e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 3.687804564833641e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012649440517028172\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013130716979503632\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.171453442269315\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.424652105662972\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07434892173235615\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07467806525528431\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007256317728509505\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.0074156210757792\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.3012333282579975\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.555868241004646\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.696900188922882e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.696900188922882e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.6406721849925816\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.6406721849925816\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.488483313005418\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.488483313005418\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.47080313181504607\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.47080313181504607\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.3646280169487e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.3646280169487e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.376973824109882\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.376973824109882\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013325332353512445\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013482198119163513\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01292398494357864\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013002316001802683\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003398459715147813\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003517237491905689\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.776667674382527e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.962482050061226e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013476996837804714\n",
      "  reference_perf/forward/total_duration_max_s: 0.013547765091061592\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.12500000000000003\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.3333333333333334\n",
      "  reward/evaluate_response/avg_total_reward: 0.22916666666666652\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.18540496217739158\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.2981423969999719\n",
      "  reward/evaluate_response/sum_MathReward_reward: 3.000000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.000000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.05458555370569229\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00041312677785754204\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00041312677785754204\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004955478943884373\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004955478943884373\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.638616168871522\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.638616168871522\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.6377011900767684\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.6377011900767684\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34706946602091193\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34706946602091193\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010624927934259176\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010624927934259176\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11033020680770278\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11033020680770278\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4680268559604883\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4680268559604883\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2683589826337993\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2683589826337993\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 84, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:47:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:59 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:47:59 INFO\u001b[0m Pushing weights for policy version 86\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:02 INFO\u001b[0m Completed weights push in 2.61 seconds\n",
      "[0] INFO 10-16 19:48:02 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 85[0] \u001b[34m[Generator-0/1] 2025-10-16 19:48:02 INFO\u001b[0m Weight update completed (now v85)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 86\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 86 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010864343494176865\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006650383584201336\n",
      "  dataset/sample/avg_sample_len: 523.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.97451708984375\n",
      "  generator_perf/generate/generate/duration_max_s: 1.97451708984375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005711680054664612\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005711680054664612\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9752719378471375\n",
      "  generator_perf/generate/total_duration_max_s: 1.9752719378471375\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.52469103038311e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.52469103038311e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011332263238728046\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011332263238728046\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9802607889287174\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9802607889287174\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07444872194901109\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07444872194901109\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006813203915953636\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006813203915953636\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1091640051454306\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1091640051454306\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.180947482585907e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.180947482585907e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.609241273254156\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.609241273254156\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.594337105285376\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.594337105285376\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4700702209956944\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4700702209956944\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.3994345869868994\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.3994345869868994\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1155811729840934\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1155811729840934\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013893796131014824\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013893796131014824\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012952637858688831\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012952637858688831\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003275158815085888\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003275158815085888\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.489517495036125e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.489517495036125e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01350589282810688\n",
      "  reference_perf/forward/total_duration_max_s: 0.01350589282810688\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.4\n",
      "  reward/evaluate_response/avg_total_reward: 0.25000000000000006\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.34641016151377546\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 3.2\n",
      "  rl_trainer/avg_grpo_loss: 0.039569586515426636\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005100341513752937\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005100341513752937\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048584770411252975\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048584770411252975\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6072561950422823\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6072561950422823\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.606256581377238\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.606256581377238\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34630024526268244\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34630024526268244\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010501815006136894\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010501815006136894\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10953204799443483\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10953204799443483\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4663361581042409\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4663361581042409\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.667698896024376\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.667698896024376\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 85, took 0.47 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:04 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:48:07 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:48:07 INFO\u001b[0m Weight update completed (now v86)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:09 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:10 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:10 INFO\u001b[0m Pushing weights for policy version 87\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:12 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:13 INFO\u001b[0m Completed weights push in 2.61 seconds\n",
      "Dropping weights @ version 86\n",
      "WandbBackend: Logged 96 metrics at global_step 87\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 87 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9856902356902357\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 2.0824915824915826\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.7983969648679096e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005920468829572201\n",
      "  dataset/sample/avg_sample_len: 496.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 506.25\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12150.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.222795735677082\n",
      "  generator_perf/generate/generate/duration_max_s: 5.57575390625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006708266735076904\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007737280130386353\n",
      "  generator_perf/generate/total_duration_avg_s: 4.2235653250180185\n",
      "  generator_perf/generate/total_duration_max_s: 5.576427538242191\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.879144787788391e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.95370477437973e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011673239059746265\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012772828340530396\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.228840070776641\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.582193122245371\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07444504369050264\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07510276604443789\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007489369561274846\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.008332822937518358\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.359203118054817\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.716462123207748\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.181172698736191e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.181172698736191e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.608109642751515\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.608109642751515\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.581627277191728\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.581627277191728\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4706997172906995\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4706997172906995\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.4035031199455261e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.4035031199455261e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.502797699999064\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.502797699999064\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014488787079850832\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00016135675832629204\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013052337026844421\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013233947101980448\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003478362535436948\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00039538415148854256\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.593445479869843e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.65529291331768e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013623063762982687\n",
      "  reference_perf/forward/total_duration_max_s: 0.01387929730117321\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.20416666666666658\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.43333333333333296\n",
      "  reward/evaluate_response/avg_total_reward: 0.31874999999999964\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.30204741165732374\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3636237371545243\n",
      "  reward/evaluate_response/sum_MathReward_reward: 4.899999999999998\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 10.399999999999991\n",
      "  rl_trainer/avg_grpo_loss: 0.04717943072319031\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004139957018196583\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004139957018196583\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004617120139300823\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004617120139300823\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6061699050478637\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6061699050478637\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.6052909553982317\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.6052909553982317\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34696927201002836\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34696927201002836\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010530284605920315\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010530284605920315\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10988822439685464\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10988822439685464\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46739004272967577\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46739004272967577\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2970894323661923\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2970894323661923\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 86, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:14 INFO\u001b[0m Pushing weights for policy version 88\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:17 INFO\u001b[0m Completed weights push in 2.52 seconds\n",
      "[0] INFO 10-16 19:48:17 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:48:17 INFO\u001b[0m Weight update completed (now v87)\n",
      "Dropping weights @ version 87\n",
      "WandbBackend: Logged 96 metrics at global_step 88\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 88 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8388888888888888\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00012063037138432264\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007004239596426487\n",
      "  dataset/sample/avg_sample_len: 457.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 428.5\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3428.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.950264892578125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.950264892578125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005130239725112915\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005130239725112915\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9509638365507125\n",
      "  generator_perf/generate/total_duration_max_s: 1.9509638365507125\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.655309021472931e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.655309021472931e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011314661242067814\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011314661242067814\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9561865949071944\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9561865949071944\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07456943672150373\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07456943672150373\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007200198248028755\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007200198248028755\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.0852277390658855\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.0852277390658855\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.254281520843506e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.254281520843506e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5213239789009094\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5213239789009094\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.363268750719726\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.363268750719726\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4670508997514844\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4670508997514844\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.2535638581030071\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.2535638581030071\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1213212180882692\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1213212180882692\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013916194438934326\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013916194438934326\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012851485051214695\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012851485051214695\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003394372761249542\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003394372761249542\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.738173007965088e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.738173007965088e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013409612234681845\n",
      "  reference_perf/forward/total_duration_max_s: 0.013409612234681845\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.7749999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.9\n",
      "  reward/evaluate_response/avg_total_reward: 0.8374999999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3897114317029975\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.26457513110645897\n",
      "  reward/evaluate_response/sum_MathReward_reward: 6.199999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 7.2\n",
      "  rl_trainer/avg_grpo_loss: 0.04047660529613495\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000514104962348938\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000514104962348938\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047649815678596497\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047649815678596497\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.519185394048691\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.519185394048691\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5181917040608823\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5181917040608823\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34379044314846396\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34379044314846396\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010552026797086\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010552026797086\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10941845923662186\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10941845923662186\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4637637082487345\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4637637082487345\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.468873196747154\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.468873196747154\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 87, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:19 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:48:22 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:48:22 INFO\u001b[0m Weight update completed (now v88)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:24 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:25 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:25 INFO\u001b[0m Pushing weights for policy version 89\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:28 INFO\u001b[0m Completed weights push in 2.60 seconds\n",
      "Dropping weights @ version 88\n",
      "WandbBackend: Logged 96 metrics at global_step 89\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 89 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9811320754716981\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.764018970768194e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005711079575121403\n",
      "  dataset/sample/avg_sample_len: 508.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.129805826822916\n",
      "  generator_perf/generate/generate/duration_max_s: 5.30049462890625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005904960135618845\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006768640279769898\n",
      "  generator_perf/generate/total_duration_avg_s: 4.130489197501292\n",
      "  generator_perf/generate/total_duration_max_s: 5.301152804914862\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.092309003074964e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.128467455506325e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012247626048823197\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.00127884978428483\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.135743379127234\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.306463511195034\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07447010713318984\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0746305463835597\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007139162626117468\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00765601871535182\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.265941052697599\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.436023507732898\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.375819116830826e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.375819116830826e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.601559293922037\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.601559293922037\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.44296877970919\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.44296877970919\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46713850321248174\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46713850321248174\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.9316095858812332e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.9316095858812332e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.374244008678943\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.374244008678943\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013646126414338747\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013913586735725403\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013317833033700785\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013755911961197853\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033845240250229836\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003414102829992771\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.861767128109932e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 0.00011185416951775551\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013883653096854687\n",
      "  reference_perf/forward/total_duration_max_s: 0.014314502943307161\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.07083333333333335\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.3333333333333334\n",
      "  reward/evaluate_response/avg_total_reward: 0.20208333333333328\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0454529671443155\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.2981423969999719\n",
      "  reward/evaluate_response/sum_MathReward_reward: 1.7000000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.000000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.03936159610748291\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00042119715362787247\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00042119715362787247\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00045817065984010696\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00045817065984010696\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5996309728361666\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5996309728361666\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.598748495336622\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.598748495336622\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3428543619811535\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3428543619811535\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010660333093255758\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010660333093255758\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1104374979622662\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1104374979622662\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4639585060067475\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4639585060067475\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.280043814331293\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.280043814331293\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 88, took 0.46 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:29 INFO\u001b[0m Pushing weights for policy version 90\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:32 INFO\u001b[0m Completed weights push in 2.59 seconds\n",
      "[0] INFO 10-16 19:48:32 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 89[0] \u001b[34m[Generator-0/1] 2025-10-16 19:48:32 INFO\u001b[0m Weight update completed (now v89)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 90\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 90 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.881118881118881\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.0001311747428889458\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007735099643468857\n",
      "  dataset/sample/avg_sample_len: 374.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 474.75\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3798.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 2.0120367431640624\n",
      "  generator_perf/generate/generate/duration_max_s: 2.0120367431640624\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007127680182456971\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007127680182456971\n",
      "  generator_perf/generate/total_duration_avg_s: 2.012942887187004\n",
      "  generator_perf/generate/total_duration_max_s: 2.012942887187004\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.439987242221832e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.439987242221832e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011472511105239391\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011472511105239391\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 2.018733717035502\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 2.018733717035502\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07481819903478026\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07481819903478026\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007313739974051714\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007313739974051714\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1491401731036603\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1491401731036603\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.670117050409317e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.670117050409317e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5967690548859537\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5967690548859537\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.713881598319858\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.713881598319858\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.469392784871161\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.469392784871161\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.42342468723654747\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.42342468723654747\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2242860342375934\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2242860342375934\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014409096911549568\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014409096911549568\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013171306811273098\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013171306811273098\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003405320458114147\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003405320458114147\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.95251689851284e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.95251689851284e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013737570028752089\n",
      "  reference_perf/forward/total_duration_max_s: 0.013737570028752089\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.6625000000000001\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 0.8312499999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4357106264483342\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 5.300000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.048590660095214844\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00048299646005034447\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00048299646005034447\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004720417782664299\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004720417782664299\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.594640697352588\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.594640697352588\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5936827841214836\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5936827841214836\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3462578868493438\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3462578868493438\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010574481915682554\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010574481915682554\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.1092420150525868\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.1092420150525868\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46607689186930656\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46607689186930656\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.6994074410758913\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.6994074410758913\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 89, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:33 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:48:37 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:48:37 INFO\u001b[0m Weight update completed (now v90)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:39 INFO\u001b[0m Pushing weights for policy version 91\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:42 INFO\u001b[0m Completed weights push in 2.66 seconds\n",
      "Dropping weights @ version 90\n",
      "WandbBackend: Logged 96 metrics at global_step 91\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 91 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9833091436865021\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9666182873730043\n",
      "  buffer/sample/count_sample_requests: 66.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.773680533197793e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005966550670564175\n",
      "  dataset/sample/avg_sample_len: 425.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 429.8333333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 10316.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 3.927431722005208\n",
      "  generator_perf/generate/generate/duration_max_s: 5.07794287109375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0005641813278198242\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0005908799767494202\n",
      "  generator_perf/generate/total_duration_avg_s: 3.928107754000773\n",
      "  generator_perf/generate/total_duration_max_s: 5.078686359107494\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.7767069190740585e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 6.280327215790749e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012377453967928886\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012771212495863438\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 3.933428931826105\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.083904623053968\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07430951499069731\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0744190807454288\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.0073019349947571754\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007646393030881882\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.066735952937354\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.21360120922327\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 7.20098614692688e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 7.20098614692688e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.6617702352814376\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.6617702352814376\n",
      "  main_perf/continuous_training/total_duration_avg_s: 9.716127295978367\n",
      "  main_perf/continuous_training/total_duration_max_s: 9.716127295978367\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4651297419331968\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4651297419331968\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.617156133055687e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.617156133055687e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 6.589189596008509\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 6.589189596008509\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013322367643316588\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001360769383609295\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01294229474539558\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01305896695703268\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033509964123368263\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003395448438823223\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.933611050248146e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.024415001273155e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01349200742940108\n",
      "  reference_perf/forward/total_duration_max_s: 0.013602517079561949\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.38333333333333314\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.633333333333333\n",
      "  reward/evaluate_response/avg_total_reward: 0.5083333333333335\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.43748015828022296\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.39860869143671335\n",
      "  reward/evaluate_response/sum_MathReward_reward: 9.199999999999996\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 15.199999999999992\n",
      "  rl_trainer/avg_grpo_loss: 0.038462381809949875\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00042923586443066597\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00042923586443066597\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004558190703392029\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004558190703392029\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6599098569713533\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6599098569713533\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.6590219270437956\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.6590219270437956\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3424658142030239\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3424658142030239\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010517790913581848\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010517790913581848\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10897927265614271\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10897927265614271\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46196539606899023\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46196539606899023\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.2654716726392508\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.2654716726392508\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 90, took 0.48 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:44 INFO\u001b[0m Pushing weights for policy version 92\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:46 INFO\u001b[0m Completed weights push in 2.51 seconds\n",
      "[0] INFO 10-16 19:48:47 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 91[0] \u001b[34m[Generator-0/1] 2025-10-16 19:48:47 INFO\u001b[0m Weight update completed (now v91)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 92\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 92 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8452380952380951\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011925628253569205\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006701163947582245\n",
      "  dataset/sample/avg_sample_len: 467.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9986243896484375\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9986243896484375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006452159881591797\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006452159881591797\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9994473016411065\n",
      "  generator_perf/generate/total_duration_max_s: 1.9994473016411065\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.7170091420412064e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.7170091420412064e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012114578858017921\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012114578858017921\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 2.0049971151165664\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 2.0049971151165664\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07489335723221302\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07489335723221302\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006813996937125921\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006813996937125921\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1342712701298296\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1342712701298296\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.751142114400864e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.751142114400864e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.511026047170162\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.511026047170162\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.564743886701763\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.564743886701763\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46858308697119355\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46858308697119355\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4622083557769656\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4622083557769656\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1229173326864839\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1229173326864839\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00019930070266127586\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00019930070266127586\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.02167631220072508\n",
      "  reference_perf/forward/forward/duration_max_s: 0.02167631220072508\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0004719868302345276\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0004719868302345276\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 0.00010312115773558617\n",
      "  reference_perf/forward/to_device/duration_max_s: 0.00010312115773558617\n",
      "  reference_perf/forward/total_duration_avg_s: 0.022453802172094584\n",
      "  reference_perf/forward/total_duration_max_s: 0.022453802172094584\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.6000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.35000000000000003\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3999999999999999\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.800000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.06016969680786133\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005125133320689201\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005125133320689201\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0005483217537403107\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0005483217537403107\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5087975319474936\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5087975319474936\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5077337929978967\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5077337929978967\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3443080969154835\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3443080969154835\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01064002700150013\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01064002700150013\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11034643417224288\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11034643417224288\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4652970931492746\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4652970931492746\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.665732851717621\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.665732851717621\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 91, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:49 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:48:52 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:48:52 INFO\u001b[0m Weight update completed (now v92)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:55 INFO\u001b[0m Pushing weights for policy version 93\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:57 INFO\u001b[0m Completed weights push in 2.56 seconds\n",
      "Dropping weights @ version 92\n",
      "WandbBackend: Logged 96 metrics at global_step 93\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 93 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9886831275720164\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9826572604350379\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.220916743079821e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005929078906774521\n",
      "  dataset/sample/avg_sample_len: 447.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 480.25\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11526.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.220319824218749\n",
      "  generator_perf/generate/generate/duration_max_s: 5.54490869140625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006278186639149983\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007239999771118164\n",
      "  generator_perf/generate/total_duration_avg_s: 4.221046202883125\n",
      "  generator_perf/generate/total_duration_max_s: 5.545551283434033\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.684063752492269e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.91999089717865e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011646019605298836\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001199894119054079\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.226625092327595\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.552256168797612\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0744292619638145\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07475444301962852\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007414742062489192\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007904048077762127\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.356026632556071\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.682157943956554\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.799105226993561e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.799105226993561e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5635303882882\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5635303882882\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.521849416196346\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.521849416196346\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46391223883256316\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46391223883256316\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.0845793187618256e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.0845793187618256e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.49437760328874\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.49437760328874\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013684558992584547\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014655804261565208\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013058974252392849\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013093681074678898\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034198490902781487\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003509228117763996\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.071803798278172e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.1612728536129e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01362071450178822\n",
      "  reference_perf/forward/total_duration_max_s: 0.013661913108080626\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.3249999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.6666666666666664\n",
      "  reward/evaluate_response/avg_total_reward: 0.4958333333333334\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.38971143170299727\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3944053188733079\n",
      "  reward/evaluate_response/sum_MathReward_reward: 7.799999999999997\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 15.999999999999995\n",
      "  rl_trainer/avg_grpo_loss: 0.05601208284497261\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004217959940433502\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004217959940433502\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00045738276094198227\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00045738276094198227\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.561753632966429\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.561753632966429\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5608705673366785\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5608705673366785\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3422131328843534\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3422131328843534\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010482922196388245\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010482922196388245\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10844628280028701\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10844628280028701\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4611442112363875\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4611442112363875\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.352753798943013\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.352753798943013\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 92, took 0.47 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:48:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:48:59 INFO\u001b[0m Pushing weights for policy version 94\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:01 INFO\u001b[0m Completed weights push in 2.73 seconds\n",
      "[0] INFO 10-16 19:49:02 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:49:02 INFO\u001b[0m Weight update completed (now v93)\n",
      "Dropping weights @ version 93\n",
      "WandbBackend: Logged 96 metrics at global_step 94\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 94 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011258894422401984\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006952397525310516\n",
      "  dataset/sample/avg_sample_len: 562.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 483.75\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3870.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.98343359375\n",
      "  generator_perf/generate/generate/duration_max_s: 1.98343359375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006257920265197754\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006257920265197754\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9842421377748252\n",
      "  generator_perf/generate/total_duration_max_s: 1.9842421377748252\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.0372444093227386e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.0372444093227386e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011776918545365334\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011776918545365334\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9899283680133522\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9899283680133522\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07470282074064016\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07470282074064016\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007180862128734589\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007180862128734589\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.119389098137617\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.119389098137617\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.732050001621246e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.732050001621246e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.732014342211187\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.732014342211187\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.57076430786401\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.57076430786401\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46791122760623693\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46791122760623693\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.25629847310483456\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.25629847310483456\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1145320171490312\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1145320171490312\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00015020277351140976\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00015020277351140976\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.0132965799421072\n",
      "  reference_perf/forward/forward/duration_max_s: 0.0132965799421072\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003431732766330242\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003431732766330242\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.914192974567413e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.914192974567413e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013871381990611553\n",
      "  reference_perf/forward/total_duration_max_s: 0.013871381990611553\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.43750000000000006\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.8\n",
      "  reward/evaluate_response/avg_total_reward: 0.6187499999999999\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.43571062644833425\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3464101615137753\n",
      "  reward/evaluate_response/sum_MathReward_reward: 3.5000000000000004\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 6.4\n",
      "  rl_trainer/avg_grpo_loss: 0.06557133793830872\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004978561773896217\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004978561773896217\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00048753712326288223\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00048753712326288223\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.729968181345612\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.729968181345612\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.7289799959398806\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.7289799959398806\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34326351806521416\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34326351806521416\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010555162094533443\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010555162094533443\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11053954903036356\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11053954903036356\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.464360652025789\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.464360652025789\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.591003523673862\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.591003523673862\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 93, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:04 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:49:07 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:49:07 INFO\u001b[0m Weight update completed (now v94)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:09 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:09 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:10 INFO\u001b[0m Pushing weights for policy version 95\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:11 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:12 INFO\u001b[0m Completed weights push in 2.67 seconds\n",
      "Dropping weights @ version 94\n",
      "WandbBackend: Logged 96 metrics at global_step 95\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 95 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9907407407407407\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 2.0185185185185186\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.0995339105526606e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005840021185576916\n",
      "  dataset/sample/avg_sample_len: 498.6666666666667\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 485.625\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11655.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.188197062174479\n",
      "  generator_perf/generate/generate/duration_max_s: 5.46775390625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007080959876378377\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007921919822692871\n",
      "  generator_perf/generate/total_duration_avg_s: 4.1890009234957395\n",
      "  generator_perf/generate/total_duration_max_s: 5.468526898257434\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.2778595040241875e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 6.785988807678223e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011893333867192268\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012230160646140575\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.19485296929876\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.47445043316111\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0745265952621897\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07496925676241517\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007668353461970885\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00893268920481205\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.3339619459584355\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.631644340232015\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 3.83937731385231e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 3.83937731385231e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.6697103013284504\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.6697103013284504\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.637801331933588\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.637801331933588\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4684144230559468\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4684144230559468\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.717265695333481e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.717265695333481e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.4996528178453445\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.4996528178453445\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001369921180109183\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014200294390320778\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01315799526249369\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013698272407054901\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00033909811948736507\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003497712314128876\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.897646476825078e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.161971345543861e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013715420694400867\n",
      "  reference_perf/forward/total_duration_max_s: 0.014274067245423794\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.2666666666666666\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.46666666666666673\n",
      "  reward/evaluate_response/avg_total_reward: 0.3666666666666667\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3782268572636739\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3771236166328253\n",
      "  reward/evaluate_response/sum_MathReward_reward: 6.399999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 11.200000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.029826737940311432\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00042981794103980064\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00042981794103980064\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004602968692779541\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004602968692779541\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.668120802845806\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.668120802845806\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.6672275299206376\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.6672275299206376\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3455334887839854\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3455334887839854\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010550764854997396\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010550764854997396\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10973922209814191\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10973922209814191\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4658255656249821\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4658255656249821\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.350647277664393\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.350647277664393\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 94, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:14 INFO\u001b[0m Pushing weights for policy version 96\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:16 INFO\u001b[0m Completed weights push in 2.55 seconds\n",
      "[0] INFO 10-16 19:49:17 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 95[0] \u001b[34m[Generator-0/1] 2025-10-16 19:49:17 INFO\u001b[0m Weight update completed (now v95)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 96\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 96 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9090909090909092\n",
      "  buffer/sample/count_sample_requests: 11.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.0001421005211093209\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006960597820580006\n",
      "  dataset/sample/avg_sample_len: 640.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 442.625\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3541.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.970972900390625\n",
      "  generator_perf/generate/generate/duration_max_s: 1.970972900390625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007035199999809265\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007035199999809265\n",
      "  generator_perf/generate/total_duration_avg_s: 1.971856132388115\n",
      "  generator_perf/generate/total_duration_max_s: 1.971856132388115\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.7064851969480515e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.7064851969480515e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011693229898810387\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011693229898810387\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9771082061342895\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9771082061342895\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07456696638837457\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07456696638837457\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007131011690944433\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007131011690944433\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.10628256900236\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.10628256900236\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.126930773258209e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.126930773258209e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.555249030236155\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.555249030236155\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.492008151020855\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.492008151020855\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4644367420114577\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4644367420114577\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.45733702182769775\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.45733702182769775\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.0149737009778619\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.0149737009778619\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013943901285529137\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013943901285529137\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013258266262710094\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013258266262710094\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003318069502711296\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003318069502711296\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.921596989035606e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.921596989035606e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013810652308166027\n",
      "  reference_perf/forward/total_duration_max_s: 0.013810652308166027\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.8875\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 0.94375\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.2976470224947665\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 7.1\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.05106218159198761\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005655642598867416\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005655642598867416\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004953476600348949\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004953476600348949\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.55248068831861\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.55248068831861\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5514161391183734\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5514161391183734\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3420908860862255\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3420908860862255\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01046130619943142\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01046130619943142\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10878260573372245\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10878260573372245\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4613415664061904\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4613415664061904\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.6309828320518136\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.6309828320518136\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 95, took 0.46 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:19 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:49:22 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:49:22 INFO\u001b[0m Weight update completed (now v96)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:24 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:24 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:25 INFO\u001b[0m Pushing weights for policy version 97\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:27 INFO\u001b[0m Completed weights push in 2.65 seconds\n",
      "Dropping weights @ version 96\n",
      "WandbBackend: Logged 96 metrics at global_step 97\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 97 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9907407407407407\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9867724867724865\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 7.294429466128349e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006040469743311405\n",
      "  dataset/sample/avg_sample_len: 457.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 507.125\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12171.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.247974283854166\n",
      "  generator_perf/generate/generate/duration_max_s: 5.5116015625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0008245226542154949\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.001075935959815979\n",
      "  generator_perf/generate/total_duration_avg_s: 4.248908843842646\n",
      "  generator_perf/generate/total_duration_max_s: 5.512780986458063\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.7167686969041824e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.9762969613075256e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012004513603945572\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012698331847786903\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.254097762517631\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.518600167706609\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07449968733514349\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07490341691300273\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007344908391435941\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00748026929795742\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.384030420177926\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.65052489284426\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 3.918074071407318e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 3.918074071407318e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.655605514999479\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.655605514999479\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.61569913988933\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.61569913988933\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46961431903764606\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46961431903764606\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.1945685148239136e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.1945685148239136e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.490449604112655\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.490449604112655\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00014558869103590646\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001635197550058365\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013114630710333586\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013236312195658684\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00035673876603444416\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00038893288001418114\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.676139016946156e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.551597759127617e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013706101415057978\n",
      "  reference_perf/forward/total_duration_max_s: 0.013820420019328594\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.17083333333333336\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5333333333333332\n",
      "  reward/evaluate_response/avg_total_reward: 0.35208333333333325\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.25079733961020295\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3944053188733078\n",
      "  reward/evaluate_response/sum_MathReward_reward: 4.1000000000000005\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 12.799999999999997\n",
      "  rl_trainer/avg_grpo_loss: 0.05513908714056015\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0007051038555800915\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0007051038555800915\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0008759801276028156\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0008759801276028156\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6532950452528894\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6532950452528894\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.6517109042033553\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.6517109042033553\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.343647135887295\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.343647135887295\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010811495129019022\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010811495129019022\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11069641076028347\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11069641076028347\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46515800803899765\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46515800803899765\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.350363376084715\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.350363376084715\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 96, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:28 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:29 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:29 INFO\u001b[0m Pushing weights for policy version 98\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:32 INFO\u001b[0m Completed weights push in 2.45 seconds\n",
      "[0] INFO 10-16 19:49:32 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 97[0] \u001b[34m[Generator-0/1] 2025-10-16 19:49:32 INFO\u001b[0m Weight update completed (now v97)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 98\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 98 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00012081194048126538\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006208540871739388\n",
      "  dataset/sample/avg_sample_len: 698.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9714349365234376\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9714349365234376\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000614080011844635\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000614080011844635\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9722343925386667\n",
      "  generator_perf/generate/total_duration_max_s: 1.9722343925386667\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.38871793448925e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.38871793448925e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012132422998547554\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012132422998547554\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.977323685772717\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.977323685772717\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.0750932558439672\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0750932558439672\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.006943275220692158\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.006943275220692158\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.107041527982801\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.107041527982801\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.970934242010117e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.970934242010117e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.4500662898644805\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.4500662898644805\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.5544799054041505\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.5544799054041505\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.472247714176774\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.472247714176774\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.5153017831034958\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.5153017831034958\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1168523030355573\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1168523030355573\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00015145214274525642\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00015145214274525642\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013242444023489952\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013242444023489952\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00044748419895768166\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00044748419895768166\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 9.491993114352226e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.491993114352226e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013938552234321833\n",
      "  reference_perf/forward/total_duration_max_s: 0.013938552234321833\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.075\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.28750000000000003\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.04330127018922195\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3872983346207416\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.6\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.000000000000001\n",
      "  rl_trainer/avg_grpo_loss: 0.04404626786708832\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004963269457221031\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004963269457221031\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.000495667103677988\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.000495667103677988\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.447884635068476\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.447884635068476\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.4468890479765832\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.4468890479765832\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34904788294807076\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34904788294807076\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010570543352514505\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010570543352514505\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10932080587372184\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10932080587372184\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4689423171803355\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4689423171803355\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5642121233977377\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5642121233977377\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 97, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:34 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:49:37 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:49:37 INFO\u001b[0m Weight update completed (now v98)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:40 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:40 INFO\u001b[0m Pushing weights for policy version 99\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:43 INFO\u001b[0m Completed weights push in 2.61 seconds\n",
      "Dropping weights @ version 98\n",
      "WandbBackend: Logged 96 metrics at global_step 99\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 99 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9836182336182335\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.967236467236467\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.387346734603245e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005996674299240112\n",
      "  dataset/sample/avg_sample_len: 512.6666666666666\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 499.7083333333333\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 11993.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.180991577148437\n",
      "  generator_perf/generate/generate/duration_max_s: 5.43696533203125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006562773386637371\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0008121600151062012\n",
      "  generator_perf/generate/total_duration_avg_s: 4.181746318485588\n",
      "  generator_perf/generate/total_duration_max_s: 5.4378285640478135\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.37123249967893e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.456518217921257e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0013667394717534382\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0016564377583563328\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.186824396097411\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.443329992238432\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07437174223984282\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07475364487618208\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007209525133172671\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007302770856767893\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.316018474909167\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.573534004855901\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.6370550990104675e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.6370550990104675e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.6133941025473177\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.6133941025473177\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.569488250650465\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.569488250650465\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4662262103520334\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4662262103520334\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.5698373317718506e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.5698373317718506e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.489844111725688\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.489844111725688\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013409523914257684\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013690674677491188\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01301384624093771\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013144046999514103\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003350144252181053\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003402191214263439\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.959067200620969e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.122110739350319e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01356468303129077\n",
      "  reference_perf/forward/total_duration_max_s: 0.01369155291467905\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.22916666666666666\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.4666666666666664\n",
      "  reward/evaluate_response/avg_total_reward: 0.3479166666666665\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.3973654559162831\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3771236166328253\n",
      "  reward/evaluate_response/sum_MathReward_reward: 5.5\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 11.199999999999994\n",
      "  rl_trainer/avg_grpo_loss: 0.05384288728237152\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004354300908744335\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004354300908744335\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047051114961504936\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047051114961504936\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6115304022096097\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6115304022096097\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.6106180190108716\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.6106180190108716\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34320548409596086\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34320548409596086\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010609728284180164\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010609728284180164\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10971102956682444\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10971102956682444\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46352821914479136\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46352821914479136\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.325963490176946\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.325963490176946\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 98, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:44 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:44 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:44 INFO\u001b[0m Pushing weights for policy version 100\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:47 INFO\u001b[0m Completed weights push in 2.52 seconds\n",
      "[0] INFO 10-16 19:49:47 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:49:47 INFO\u001b[0m Weight update completed (now v99)\n",
      "Dropping weights @ version 99\n",
      "WandbBackend: Logged 96 metrics at global_step 100\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 100 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.871212121212121\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00011660166395207246\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006787208840250969\n",
      "  dataset/sample/avg_sample_len: 558.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9828262939453125\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9828262939453125\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007073919773101806\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007073919773101806\n",
      "  generator_perf/generate/total_duration_avg_s: 1.983716597929597\n",
      "  generator_perf/generate/total_duration_max_s: 1.983716597929597\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.796590656042099e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.796590656042099e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011996598914265633\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011996598914265633\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.989162104204297\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.989162104204297\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07453422108665109\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07453422108665109\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.00742507865652442\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.00742507865652442\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1187225319445133\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1187225319445133\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.860106855630875e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.860106855630875e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.522692393977195\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.522692393977195\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.584444627631456\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.584444627631456\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.467277925927192\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.467277925927192\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.47146217292174697\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.47146217292174697\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1230024648830295\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1230024648830295\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001383707858622074\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001383707858622074\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012948994990438223\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012948994990438223\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003346768207848072\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003346768207848072\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.06320458650589e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.06320458650589e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013504660688340664\n",
      "  reference_perf/forward/total_duration_max_s: 0.013504660688340664\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0875\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.14375000000000004\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.03307189138830741\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.05148043856024742\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004999106749892235\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004999106749892235\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00049542635679245\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00049542635679245\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.520433221012354\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.520433221012354\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5194344096817076\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5194344096817076\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34284434420987964\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34284434420987964\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01047878572717309\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01047878572717309\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11076755914837122\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11076755914837122\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4640937549993396\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4640937549993396\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.669712404254824\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.669712404254824\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 99, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:49 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:49:52 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:49:52 INFO\u001b[0m Weight update completed (now v100)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:55 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:55 INFO\u001b[0m Pushing weights for policy version 101\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:57 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:58 INFO\u001b[0m Completed weights push in 2.77 seconds\n",
      "Dropping weights @ version 100\n",
      "WandbBackend: Logged 96 metrics at global_step 101\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 101 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9811320754716981\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 5.086199254602999e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005687740631401539\n",
      "  dataset/sample/avg_sample_len: 493.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 503.5\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12084.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.203515584309897\n",
      "  generator_perf/generate/generate/duration_max_s: 5.50921337890625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0007075839837392171\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007570239901542663\n",
      "  generator_perf/generate/total_duration_avg_s: 4.20437347229446\n",
      "  generator_perf/generate/total_duration_max_s: 5.509999810878187\n",
      "  generator_perf/update_weights/avg_pending_requests: 0.0\n",
      "  generator_perf/update_weights/max_pending_requests: -inf\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.104338586330414e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.288003012537956e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012196369158724945\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012871939688920975\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.209691121863822\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.515614315867424\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07435661212851603\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07480426738038659\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.00741816870868206\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007515226025134325\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.339542970216523\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.64702242705971\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.12575900554657e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.12575900554657e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.7677623089402914\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.7677623089402914\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.606625011190772\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.606625011190772\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4662848562002182\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4662848562002182\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.9010156393051147e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.9010156393051147e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.372551363892853\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.372551363892853\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0001340853050351143\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013630790635943413\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.01299331042294701\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013036344200372696\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003353337136407693\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.000335554126650095\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 7.611435527602832e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 7.701106369495392e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013540994375944138\n",
      "  reference_perf/forward/total_duration_max_s: 0.013583558145910501\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.15833333333333335\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.5666666666666665\n",
      "  reward/evaluate_response/avg_total_reward: 0.3625\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.2564447092238186\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.39860869143671324\n",
      "  reward/evaluate_response/sum_MathReward_reward: 3.8000000000000007\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 13.599999999999998\n",
      "  rl_trainer/avg_grpo_loss: 0.057912543416023254\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00041761668398976326\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00041761668398976326\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00046789320185780525\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00046789320185780525\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.765629659872502\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.765629659872502\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.7647408838383853\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.7647408838383853\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3439266928471625\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3439266928471625\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010620423126965761\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010620423126965761\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10905165411531925\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10905165411531925\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46360077196732163\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46360077196732163\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.289368857163936\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.289368857163936\n",
      "==============================\n",
      "\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:49:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped weights @ version 100, took 0.51 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:49:59 INFO\u001b[0m Pushing weights for policy version 102\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:01 INFO\u001b[0m Completed weights push in 2.49 seconds\n",
      "[0] INFO 10-16 19:50:02 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:50:02 INFO\u001b[0m Weight update completed (now v101)\n",
      "Dropping weights @ version 101\n",
      "WandbBackend: Logged 96 metrics at global_step 102\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 102 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.8\n",
      "  buffer/sample/count_sample_requests: 5.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00023207776248455048\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007106349803507328\n",
      "  dataset/sample/avg_sample_len: 560.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 313.875\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 2511.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.4010987548828124\n",
      "  generator_perf/generate/generate/duration_max_s: 1.4010987548828124\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000574783980846405\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000574783980846405\n",
      "  generator_perf/generate/total_duration_avg_s: 1.4018693468570709\n",
      "  generator_perf/generate/total_duration_max_s: 1.4018693468570709\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.064718425273895e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.064718425273895e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0013051866553723812\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013051866553723812\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.4089125911705196\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.4089125911705196\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07834803173318505\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07834803173318505\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.011202940251678228\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.011202940251678228\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 1.5482164369896054\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 1.5482164369896054\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.8531219363212585e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.8531219363212585e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.497456004843116\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.497456004843116\n",
      "  main_perf/continuous_training/total_duration_avg_s: 3.8581931428052485\n",
      "  main_perf/continuous_training/total_duration_max_s: 3.8581931428052485\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46444368036463857\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46444368036463857\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4884388679638505\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4884388679638505\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 0.40784479677677155\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 0.40784479677677155\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013740500435233116\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013740500435233116\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013197089079767466\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013197089079767466\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003338512033224106\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003338512033224106\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.036382496356964e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.036382496356964e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013750747311860323\n",
      "  reference_perf/forward/total_duration_max_s: 0.013750747311860323\n",
      "  reward/evaluate_response/avg_MathReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 1.0\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 8.0\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.043927356600761414\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0007492299191653728\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0007492299191653728\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0005210624076426029\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0005210624076426029\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.494357854127884\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.494357854127884\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.493085033725947\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.493085033725947\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34218879509717226\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34218879509717226\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010467645712196827\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010467645712196827\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10796483093872666\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10796483093872666\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46062432089820504\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46062432089820504\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.6004400523379445\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.6004400523379445\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 101, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:04 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:50:07 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:50:07 INFO\u001b[0m Weight update completed (now v102)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:09 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:09 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:10 INFO\u001b[0m Pushing weights for policy version 103\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:11 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:12 INFO\u001b[0m Completed weights push in 2.54 seconds\n",
      "Dropping weights @ version 102\n",
      "WandbBackend: Logged 96 metrics at global_step 103\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 103 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9872727272727272\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9866666666666664\n",
      "  buffer/sample/count_sample_requests: 76.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 8.987585131667162e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.000585456844419241\n",
      "  dataset/sample/avg_sample_len: 518.6666666666666\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.236457153320313\n",
      "  generator_perf/generate/generate/duration_max_s: 5.4736494140625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006445013284683228\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007015680074691773\n",
      "  generator_perf/generate/total_duration_avg_s: 4.2371967479834955\n",
      "  generator_perf/generate/total_duration_max_s: 5.474376710053534\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 3.859400749206543e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.764001980423927e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012601350123683612\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0013593891635537148\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.2424136297777295\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.480220751836896\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07446333005403478\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.0748413996770978\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007414117455482483\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007879744283854961\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.37350638397038\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.613173152320087\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.920642822980881e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.920642822980881e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5385367260314524\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5385367260314524\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.621068381238729\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.621068381238729\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.46812804928049445\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.46812804928049445\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.8619000911712646e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.8619000911712646e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.614375886972994\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.614375886972994\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00015230445812145868\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.0001813787966966629\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.015012084972113371\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01887660101056099\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003580326835314433\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00039039645344018936\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.353715141614278e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 9.354483336210251e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.015608185747017464\n",
      "  reference_perf/forward/total_duration_max_s: 0.019497867673635483\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.06250000000000001\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.20000000000000007\n",
      "  reward/evaluate_response/avg_total_reward: 0.13125\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.04841229182759273\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 1.5000000000000002\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 4.800000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.03387074917554855\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004124087281525135\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004124087281525135\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004887660034000874\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004887660034000874\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.53668368794024\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.53668368794024\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.535779652185738\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.535779652185738\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3452841299585998\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3452841299585998\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01067297300323844\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01067297300323844\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10952371498569846\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10952371498569846\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46548305405303836\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46548305405303836\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.402815844863653\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.402815844863653\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 102, took 0.46 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:13 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:14 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:14 INFO\u001b[0m Pushing weights for policy version 104\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:17 INFO\u001b[0m Completed weights push in 2.60 seconds\n",
      "[0] INFO 10-16 19:50:17 [block_pool.py:321] Successfully reset prefix cache\n",
      "Dropping weights @ version 103[0] \u001b[34m[Generator-0/1] 2025-10-16 19:50:17 INFO\u001b[0m Weight update completed (now v103)\n",
      "\n",
      "WandbBackend: Logged 96 metrics at global_step 104\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 104 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.881118881118881\n",
      "  buffer/sample/count_sample_requests: 13.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00014519451472621696\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0007302733138203621\n",
      "  dataset/sample/avg_sample_len: 424.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.988489013671875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.988489013671875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006545280218124389\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006545280218124389\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9893413656949996\n",
      "  generator_perf/generate/total_duration_max_s: 1.9893413656949996\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.0315167754888535e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.0315167754888535e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0011848369613289833\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0011848369613289833\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9955280721187592\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9955280721187592\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07465108996257186\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07465108996257186\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007302437908947468\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007302437908947468\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1261450150050223\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1261450150050223\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.4638291001319885e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.4638291001319885e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.60515079414472\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.60515079414472\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.552657934837043\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.552657934837043\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4674729788675904\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4674729788675904\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.25461137806996703\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.25461137806996703\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.2254150877706707\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.2254150877706707\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013564806431531906\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013564806431531906\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013243477791547775\n",
      "  reference_perf/forward/forward/duration_max_s: 0.013243477791547775\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034493114799261093\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00034493114799261093\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.125603199005127e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.125603199005127e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013807371258735657\n",
      "  reference_perf/forward/total_duration_max_s: 0.013807371258735657\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.09999999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.19999999999999998\n",
      "  reward/evaluate_response/avg_total_reward: 0.15000000000000005\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 1.862645149230957e-09\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 3.725290298461914e-09\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 1.5999999999999999\n",
      "  rl_trainer/avg_grpo_loss: 0.0395427942276001\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0005017109215259552\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0005017109215259552\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004681362770497799\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004681362770497799\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6032273680903018\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6032273680903018\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.602253805845976\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.602253805845976\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34428761526942253\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34428761526942253\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010608145967125893\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010608145967125893\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10952108399942517\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10952108399942517\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4644199782051146\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4644199782051146\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.5365828876383603\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.5365828876383603\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 103, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:19 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:50:22 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:50:22 INFO\u001b[0m Weight update completed (now v104)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:24 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:24 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:24 INFO\u001b[0m Pushing weights for policy version 105\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:26 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:27 INFO\u001b[0m Completed weights push in 2.49 seconds\n",
      "Dropping weights @ version 104\n",
      "WandbBackend: Logged 96 metrics at global_step 105\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 105 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 2.0943396226415096\n",
      "  buffer/sample/count_sample_requests: 71.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 7.72726538420563e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006498252041637897\n",
      "  dataset/sample/avg_sample_len: 451.3333333333333\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 430.9166666666667\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 10342.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.070046630859374\n",
      "  generator_perf/generate/generate/duration_max_s: 5.131865234375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000610122670729955\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0007080960273742675\n",
      "  generator_perf/generate/total_duration_avg_s: 4.0707530521936715\n",
      "  generator_perf/generate/total_duration_max_s: 5.132582514345646\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.022972037394842e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.5104028433561325e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012658548851807911\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.001352251973003149\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.0759358870175975\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.138019429054111\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07441693839306633\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07495008129626513\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007474574726074934\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007881784345954657\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.20652917213738\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.26927485037595\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.494097083806992e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.494097083806992e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.496221421752125\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.496221421752125\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.048805052880198\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.048805052880198\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4624985349364579\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4624985349364579\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 1.6822945326566696e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 1.6822945326566696e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.09006085107103\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.09006085107103\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013530906289815903\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00014189910143613815\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.013070167973637581\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01310808677226305\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00034568194920818013\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003699129447340965\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.185300976037979e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.939998224377632e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013635239563882351\n",
      "  reference_perf/forward/total_duration_max_s: 0.013699422124773264\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.6624999999999999\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 0.8312500000000003\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.4357106264483345\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 15.899999999999997\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 24.0\n",
      "  rl_trainer/avg_grpo_loss: 0.0820392370223999\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000435663852840662\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000435663852840662\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.00047433003783226013\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.00047433003783226013\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.494373347144574\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.494373347144574\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.493460197933018\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.493460197933018\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3410086650401354\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3410086650401354\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.01044066995382309\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.01044066995382309\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10828701918944716\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10828701918944716\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4597386699169874\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4597386699169874\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.3185175033286214\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.3185175033286214\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 104, took 0.45 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:28 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:28 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:29 INFO\u001b[0m Pushing weights for policy version 106\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:31 INFO\u001b[0m Completed weights push in 2.62 seconds\n",
      "[0] INFO 10-16 19:50:32 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:50:32 INFO\u001b[0m Weight update completed (now v105)\n",
      "Dropping weights @ version 105\n",
      "WandbBackend: Logged 96 metrics at global_step 106\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 106 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9000000000000001\n",
      "  buffer/sample/count_sample_requests: 14.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00010653388952570302\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006964700296521187\n",
      "  dataset/sample/avg_sample_len: 522.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 474.375\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 3795.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9689893798828124\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9689893798828124\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006357120275497436\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006357120275497436\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9698189159035682\n",
      "  generator_perf/generate/total_duration_max_s: 1.9698189159035682\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 5.043577402830124e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.043577402830124e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012013781815767288\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012013781815767288\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9751232457347214\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9751232457347214\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07468307111412287\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07468307111412287\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007138997316360474\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007138997316360474\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1038668039254844\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1038668039254844\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 5.1143579185009e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 5.1143579185009e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.6181208482012153\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.6181208482012153\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.669509252067655\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.669509252067655\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4712232328020036\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4712232328020036\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.25289825163781643\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.25289825163781643\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.3272574143484235\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.3272574143484235\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013596098870038986\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013596098870038986\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012788380961865187\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012788380961865187\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003453092649579048\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003453092649579048\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.170399814844131e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.170399814844131e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.013353381305932999\n",
      "  reference_perf/forward/total_duration_max_s: 0.013353381305932999\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.8875\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 1.0\n",
      "  reward/evaluate_response/avg_total_reward: 0.94375\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.2976470224947665\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.0\n",
      "  reward/evaluate_response/sum_MathReward_reward: 7.1\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 8.0\n",
      "  rl_trainer/avg_grpo_loss: 0.06446902453899384\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.00048014894127845764\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.00048014894127845764\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004959781654179096\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004959781654179096\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.6158683048561215\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.6158683048561215\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.6148894517682493\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.6148894517682493\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3461545570753515\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3461545570753515\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010622615925967693\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010622615925967693\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11056680977344513\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11056680977344513\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4673465578816831\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4673465578816831\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.547607629094273\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.547607629094273\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 105, took 0.43 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:34 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:50:37 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:50:37 INFO\u001b[0m Weight update completed (now v106)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:39 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:40 INFO\u001b[0m Pushing weights for policy version 107\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:41 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:42 INFO\u001b[0m Completed weights push in 2.60 seconds\n",
      "Dropping weights @ version 106\n",
      "WandbBackend: Logged 96 metrics at global_step 107\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 107 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9836182336182335\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.967236467236467\n",
      "  buffer/sample/count_sample_requests: 75.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 6.385939195752144e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0005684578791260719\n",
      "  dataset/sample/avg_sample_len: 519.3333333333334\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.179631062825521\n",
      "  generator_perf/generate/generate/duration_max_s: 5.42541015625\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006437013347943624\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0006600639820098877\n",
      "  generator_perf/generate/total_duration_avg_s: 4.180379414826631\n",
      "  generator_perf/generate/total_duration_max_s: 5.426103596262633\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.227055857578913e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 5.982397124171257e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.001264559415479501\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0014018788933753967\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.185920166006933\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.432562408037484\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07459183782339096\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07471935637295246\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007712432959427436\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.008630801923573017\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.31921969121322\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.566342247184366\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.571862518787384e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.571862518787384e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.6002463339827955\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.6002463339827955\n",
      "  main_perf/continuous_training/total_duration_avg_s: 10.567180814221501\n",
      "  main_perf/continuous_training/total_duration_max_s: 10.567180814221501\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4701211042702198\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4701211042702198\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.0285136997699738e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.0285136997699738e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.4967852658592165\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.4967852658592165\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00016131391748785973\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00017404183745384216\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.015087033932407698\n",
      "  reference_perf/forward/forward/duration_max_s: 0.01835939008742571\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00036967142174641293\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0004331129603087902\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 9.037197257081668e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 0.00010571395978331566\n",
      "  reference_perf/forward/total_duration_avg_s: 0.015711085715641577\n",
      "  reference_perf/forward/total_duration_max_s: 0.019051605835556984\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.10000000000000003\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.39999999999999997\n",
      "  reward/evaluate_response/avg_total_reward: 0.24999999999999986\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.0\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.3464101615137755\n",
      "  reward/evaluate_response/sum_MathReward_reward: 2.400000000000001\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 9.6\n",
      "  rl_trainer/avg_grpo_loss: 0.1445576250553131\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004184618592262268\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004184618592262268\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004646643064916134\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004646643064916134\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5984485489316285\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5984485489316285\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5975624909624457\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5975624909624457\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34602455189451575\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34602455189451575\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010596530046314001\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010596530046314001\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11017680214717984\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11017680214717984\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46680007176473737\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46680007176473737\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.3115010131150484\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.3115010131150484\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 106, took 0.46 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:43 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:44 INFO\u001b[0m Pushing weights for policy version 108\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:46 INFO\u001b[0m Completed weights push in 2.57 seconds\n",
      "[0] INFO 10-16 19:50:47 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:50:47 INFO\u001b[0m Weight update completed (now v107)\n",
      "Dropping weights @ version 107\n",
      "WandbBackend: Logged 96 metrics at global_step 108\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 108 ===\n",
      "  buffer/add/count_episodes_added: 8.0\n",
      "  buffer/evict/avg_policy_age: 1.0\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9166666666666667\n",
      "  buffer/sample/count_sample_requests: 12.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 0.00012942620863517126\n",
      "  buffer_perf/sample/total_duration_max_s: 0.000685298815369606\n",
      "  dataset/sample/avg_sample_len: 461.0\n",
      "  dataset/sample/count_samples_generated: 1.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 1.0\n",
      "  generator/generate/count_sequences_completed: 8.0\n",
      "  generator/generate/sum_tokens_generated: 4096.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 1.9724012451171875\n",
      "  generator_perf/generate/generate/duration_max_s: 1.9724012451171875\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.000643999993801117\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.000643999993801117\n",
      "  generator_perf/generate/total_duration_avg_s: 1.9732326051145792\n",
      "  generator_perf/generate/total_duration_max_s: 1.9732326051145792\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 1.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.6531204134225845e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 4.6531204134225845e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012919651344418526\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012919651344418526\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 1.9796179477125406\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 1.9796179477125406\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.07447786768898368\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.07447786768898368\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.007006223313510418\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.007006223313510418\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 2.1083845398388803\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 2.1083845398388803\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.684086889028549e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.684086889028549e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 2.5691145923919976\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 2.5691145923919976\n",
      "  main_perf/continuous_training/total_duration_avg_s: 4.583301831968129\n",
      "  main_perf/continuous_training/total_duration_max_s: 4.583301831968129\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.470861769746989\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.470861769746989\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 0.4234146196395159\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 0.4234146196395159\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 1.1199028491973877\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 1.1199028491973877\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.00013768905773758888\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.00013768905773758888\n",
      "  reference_perf/forward/count_forward_passes: 1.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.012923080939799547\n",
      "  reference_perf/forward/forward/duration_max_s: 0.012923080939799547\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.0003378908149898052\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.0003378908149898052\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 8.404115214943886e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 8.404115214943886e-05\n",
      "  reference_perf/forward/total_duration_avg_s: 0.01348472898826003\n",
      "  reference_perf/forward/total_duration_max_s: 0.01348472898826003\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.0875\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.4\n",
      "  reward/evaluate_response/avg_total_reward: 0.24375000000000005\n",
      "  reward/evaluate_response/count_MathReward_calls: 8.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 8.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.03307189138830741\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.34641016151377546\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 3.2\n",
      "  rl_trainer/avg_grpo_loss: 0.03730802237987518\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.000505140982568264\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.000505140982568264\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0004778117872774601\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0004778117872774601\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 2.5670519717969\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 2.5670519717969\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 2.5660652141086757\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 2.5660652141086757\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.3470976431854069\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.3470976431854069\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010590611957013607\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010590611957013607\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.11002400983124971\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.11002400983124971\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.4677144819870591\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.4677144819870591\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.6517946058884263\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.6517946058884263\n",
      "==============================\n",
      "\n",
      "Dropped weights @ version 107, took 0.44 seconds\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:49 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] INFO 10-16 19:50:52 [block_pool.py:321] Successfully reset prefix cache\n",
      "[0] \u001b[34m[Generator-0/1] 2025-10-16 19:50:52 INFO\u001b[0m Weight update completed (now v108)\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:54 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:55 INFO\u001b[0m Pushing weights for policy version 109\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:56 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:58 INFO\u001b[0m Completed weights push in 3.41 seconds\n",
      "Dropping weights @ version 108\n",
      "WandbBackend: Logged 96 metrics at global_step 109\n",
      "=== [global_logger_2nwJ_r0] - METRICS STEP 109 ===\n",
      "  buffer/add/count_episodes_added: 24.0\n",
      "  buffer/evict/avg_policy_age: 0.9905660377358491\n",
      "  buffer/evict/max_policy_age: 1.0\n",
      "  buffer/evict/sum_episodes_evicted: 16.0\n",
      "  buffer/sample/avg_data_utilization: 1.9811320754716981\n",
      "  buffer/sample/count_sample_requests: 74.0\n",
      "  buffer_perf/sample/total_duration_avg_s: 8.4217033676199e-05\n",
      "  buffer_perf/sample/total_duration_max_s: 0.0006482847966253757\n",
      "  dataset/sample/avg_sample_len: 573.0\n",
      "  dataset/sample/count_samples_generated: 3.0\n",
      "  generator/generate/avg_tokens_generated: 512.0\n",
      "  generator/generate/count_requests: 3.0\n",
      "  generator/generate/count_sequences_completed: 24.0\n",
      "  generator/generate/sum_tokens_generated: 12288.0\n",
      "  generator/update_weights/count_weight_updates: 1.0\n",
      "  generator_perf/generate/generate/duration_avg_s: 4.226416585286459\n",
      "  generator_perf/generate/generate/duration_max_s: 5.526677734375\n",
      "  generator_perf/generate/process_inputs/duration_avg_s: 0.0006505813399950663\n",
      "  generator_perf/generate/process_inputs/duration_max_s: 0.0008243200182914734\n",
      "  generator_perf/generate/total_duration_avg_s: 4.227172190623979\n",
      "  generator_perf/generate/total_duration_max_s: 5.527354214385152\n",
      "  generator_perf/update_weights/avg_pending_requests: 1.0\n",
      "  generator_perf/update_weights/max_pending_requests: 1.0\n",
      "  main/continuous_rollouts/count_rollout_iterations: 3.0\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_avg_s: 4.5287422835826874e-05\n",
      "  main_perf/continuous_rollouts/compute_logprobs/duration_max_s: 6.08968548476696e-05\n",
      "  main_perf/continuous_rollouts/data_loading/duration_avg_s: 0.0012253625318408012\n",
      "  main_perf/continuous_rollouts/data_loading/duration_max_s: 0.0012594470754265785\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_avg_s: 4.234218476650615\n",
      "  main_perf/continuous_rollouts/policy_generation/duration_max_s: 5.533199712168425\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_avg_s: 0.08895788295194507\n",
      "  main_perf/continuous_rollouts/reference_model_calculate_logprobs/duration_max_s: 0.11792936502024531\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_avg_s: 0.008276707958430052\n",
      "  main_perf/continuous_rollouts/reward_evaluation/duration_max_s: 0.010460061021149158\n",
      "  main_perf/continuous_rollouts/total_duration_avg_s: 4.386044451346\n",
      "  main_perf/continuous_rollouts/total_duration_max_s: 5.663404140155762\n",
      "  main_perf/continuous_training/drop_weights/duration_avg_s: 4.308763891458511e-06\n",
      "  main_perf/continuous_training/drop_weights/duration_max_s: 4.308763891458511e-06\n",
      "  main_perf/continuous_training/push_weights/duration_avg_s: 3.416241095867008\n",
      "  main_perf/continuous_training/push_weights/duration_max_s: 3.416241095867008\n",
      "  main_perf/continuous_training/total_duration_avg_s: 11.282689058221877\n",
      "  main_perf/continuous_training/total_duration_max_s: 11.282689058221877\n",
      "  main_perf/continuous_training/train_step/duration_avg_s: 0.4691151548177004\n",
      "  main_perf/continuous_training/train_step/duration_max_s: 0.4691151548177004\n",
      "  main_perf/continuous_training/update_weights/duration_avg_s: 2.1410174667835236e-05\n",
      "  main_perf/continuous_training/update_weights/duration_max_s: 2.1410174667835236e-05\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_avg_s: 7.39730265038088\n",
      "  main_perf/continuous_training/waiting_for_buffer/duration_max_s: 7.39730265038088\n",
      "  reference_perf/forward/avg_sequence_length: 1024.0\n",
      "  reference_perf/forward/compute_logprobs/duration_avg_s: 0.0012381691485643387\n",
      "  reference_perf/forward/compute_logprobs/duration_max_s: 0.003443772904574871\n",
      "  reference_perf/forward/count_forward_passes: 3.0\n",
      "  reference_perf/forward/forward/duration_avg_s: 0.027745068694154423\n",
      "  reference_perf/forward/forward/duration_max_s: 0.05722392676398158\n",
      "  reference_perf/forward/garbage_collection/duration_avg_s: 0.00037120701745152473\n",
      "  reference_perf/forward/garbage_collection/duration_max_s: 0.00040285708382725716\n",
      "  reference_perf/forward/memory_delta_end_start_avg_gb: 2.31842041015625\n",
      "  reference_perf/forward/memory_peak_max_gb: 11.931992053985596\n",
      "  reference_perf/forward/to_device/duration_avg_s: 9.991135448217392e-05\n",
      "  reference_perf/forward/to_device/duration_max_s: 0.0001290501095354557\n",
      "  reference_perf/forward/total_duration_avg_s: 0.029456743504852057\n",
      "  reference_perf/forward/total_duration_max_s: 0.061202529817819595\n",
      "  reward/evaluate_response/avg_MathReward_reward: 0.03333333333333333\n",
      "  reward/evaluate_response/avg_ThinkingReward_reward: 0.3000000000000001\n",
      "  reward/evaluate_response/avg_total_reward: 0.16666666666666666\n",
      "  reward/evaluate_response/count_MathReward_calls: 24.0\n",
      "  reward/evaluate_response/count_ThinkingReward_calls: 24.0\n",
      "  reward/evaluate_response/std_MathReward_reward: 0.047140452079103175\n",
      "  reward/evaluate_response/std_ThinkingReward_reward: 0.26457513110645897\n",
      "  reward/evaluate_response/sum_MathReward_reward: 0.7999999999999999\n",
      "  reward/evaluate_response/sum_ThinkingReward_reward: 7.200000000000002\n",
      "  rl_trainer/avg_grpo_loss: 0.031287435442209244\n",
      "  rl_trainer/count_training_steps: 1.0\n",
      "  rl_trainer/learning_rate: 0.001\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_avg_s: 0.0004339003935456276\n",
      "  rl_trainer_perf/push_weights/flatten_state_dict/duration_max_s: 0.0004339003935456276\n",
      "  rl_trainer_perf/push_weights/memory_delta_end_start_avg_gb: 0.0\n",
      "  rl_trainer_perf/push_weights/memory_peak_max_gb: 11.417872905731201\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_avg_s: 0.0006032707169651985\n",
      "  rl_trainer_perf/push_weights/to_hf/duration_max_s: 0.0006032707169651985\n",
      "  rl_trainer_perf/push_weights/total_duration_avg_s: 3.412335377186537\n",
      "  rl_trainer_perf/push_weights/total_duration_max_s: 3.412335377186537\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_avg_s: 3.411294287070632\n",
      "  rl_trainer_perf/push_weights/ts_save/duration_max_s: 3.411294287070632\n",
      "  rl_trainer_perf/step/forward_backward/duration_avg_s: 0.34563269279897213\n",
      "  rl_trainer_perf/step/forward_backward/duration_max_s: 0.34563269279897213\n",
      "  rl_trainer_perf/step/memory_delta_end_start_avg_gb: 0.00022172927856445312\n",
      "  rl_trainer_perf/step/memory_peak_max_gb: 31.65072727203369\n",
      "  rl_trainer_perf/step/optimizer_step/duration_avg_s: 0.010524803306907415\n",
      "  rl_trainer_perf/step/optimizer_step/duration_max_s: 0.010524803306907415\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_avg_s: 0.10954761877655983\n",
      "  rl_trainer_perf/step/save_checkpoint/duration_max_s: 0.10954761877655983\n",
      "  rl_trainer_perf/step/total_duration_avg_s: 0.46570741198956966\n",
      "  rl_trainer_perf/step/total_duration_max_s: 0.46570741198956966\n",
      "  worker_perf/update_weights/total_duration_avg_s: 3.3016789010725915\n",
      "  worker_perf/update_weights/total_duration_max_s: 3.3016789010725915\n",
      "==============================\n",
      "\n",
      "[0] \u001b[34m[ReferenceModel-0/1] 2025-10-16 19:50:58 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n",
      "Dropped weights @ version 108, took 0.51 seconds\n",
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:59 INFO\u001b[0m [GC] Performing periodic GC collection took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] /tmp/ipykernel_1858026/82490467.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[0] /tmp/ipykernel_1858026/82490467.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \u001b[34m[RLTrainer-0/1] 2025-10-16 19:50:59 INFO\u001b[0m Pushing weights for policy version 110\n"
     ]
    }
   ],
   "source": [
    "num_rollout_threads = 1\n",
    "num_training_threads = 1\n",
    "\n",
    "rollout_tasks = [\n",
    "    asyncio.create_task(continuous_rollouts()) for _ in range(num_rollout_threads)\n",
    "]\n",
    "training_task = asyncio.create_task(continuous_training())\n",
    "\n",
    "try:\n",
    "    await asyncio.gather(*rollout_tasks, training_task)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user\")\n",
    "    for rollout_task in rollout_tasks:\n",
    "        rollout_task.cancel()\n",
    "    training_task.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4603b80-1f25-49a1-920e-d24f38dfc687",
   "metadata": {},
   "source": [
    "## Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74e781-c253-4bd0-929f-bd4ad516ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "await mlogger.shutdown.call_one()\n",
    "await asyncio.sleep(2)\n",
    "\n",
    "await asyncio.gather(\n",
    "    DatasetActor.shutdown(dataloader),\n",
    "    policy.shutdown(),\n",
    "    RLTrainer.shutdown(trainer),\n",
    "    ReplayBuffer.shutdown(replay_buffer),\n",
    "    ComputeAdvantages.shutdown(compute_advantages),\n",
    "    ref_model.shutdown(),\n",
    "    reward_actor.shutdown(),\n",
    ")\n",
    "await shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forge",
   "language": "python",
   "name": "forge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
